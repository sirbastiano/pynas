{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Pynattas (old version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: assuming dependencies already in place. A guide for dependencies will be created on a later date. For now, make sure to have the latest compatible versions of:\n",
    "- pytorch and pytorch lightning, torchmetrics and torchvision, cuda\n",
    "- tensorflow and tensorboard\n",
    "- tqdm\n",
    "- datetime\n",
    "- matplotlib and numpy\n",
    "\n",
    "Solve any further incompatibilities as they are raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code with current configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: There are possible combinations of blocks that will crash the run. A saner block selection logic will be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard tensorboardX\n",
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynattas as pnas\n",
    "import torch\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Network Architecture Search ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chromosome pool:\n",
      "Architecture: Leo12k5s1p2arn1EPa2ELne5arn1EUf2mnearestES0ELeo12k5s1p2arn1EHSEE\n",
      "Chromosome: ['Leo12k5s1p2arn1', 'Pa2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 11489356 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo12k5s1p2arn1', 'Pa2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.45n1EPa2ELco12k5s1p2agn1EUf2mnearestES0ELDd0.45n1EHSEE\n",
      "Chromosome: ['LDd0.45n1', 'Pa2', 'Lco12k5s1p2agn1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 78880\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:26:23.171462612 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:26:23.176737903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:26:23.179149053 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:26:23.185322930 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 78.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "78.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "78.9 K    Total params\n",
      "0.316     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e59b939764f73a7717c04a22d2cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:28:58.038739736 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:28:58.040268398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:28:58.104436950 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:28:58.104460749 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e4623c725b489682d05da5d7fb63cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4358852505683899     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6065337061882019     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18106305599212646    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4358852505683899    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6065337061882019    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18106305599212646   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:29:03.136794353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:03.141194705 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:03.204408999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:03.204453937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f82ce0124d425882e17dc8ab95c9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.430162250995636     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6100411415100098     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18276728689670563    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.430162250995636    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6100411415100098    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18276728689670563   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.6100411415100098, 'test_mse': 0.18276728689670563, 'test_iou': 0.430162250995636}]\n",
      "MSE value is 0.18276728689670563\n",
      "IoU value is 0.430162250995636\n",
      "num_param value is 78880\n",
      "Training time: 155.50467920303345\n",
      "Fitness: 12.677491056678154\n",
      "********\n",
      "chromosome: ['LDd0.45n1', 'Pa2', 'Lco12k5s1p2agn1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS'], fitness: 12.677491056678154, IoU: 0.430162250995636, FPS: 424.46768536250244, Model Size: 78880\n",
      "\n",
      "Architecture: LDd0.24n1EPM2ELdo05arn1EPa2ELRr2agn1EPa2ELme3arn1EUf2mnearestES2ELRr2agn1EUf2mnearestES1ELdo05arn1EUf2mnearestES0ELDd0.24n1EHSEE\n",
      "Chromosome: ['LDd0.24n1', 'PM2', 'Ldo05arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LRr2agn1', 'Uf2mnearest', 'S1', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'LDd0.24n1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 671180\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:29:08.990745685 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:08.990900566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:08.991726055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:29:08.993184063 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 671 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "671 K     Trainable params\n",
      "0         Non-trainable params\n",
      "671 K     Total params\n",
      "2.685     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff84b943b994197bdbb2299f2352c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:36:01.930421318 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:01.935452576 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:01.996395401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:01.996442901 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec95aceb14024639bd765ef2e9878ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4433738887310028     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6708577275276184     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2278987467288971     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4433738887310028    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6708577275276184    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2278987467288971    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:36:12.501472327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:12.503606540 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:12.540408944 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:12.540458208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c56a97ad7684c60ba58b52591f66d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4431334435939789     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6902076601982117     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2377101480960846     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4431334435939789    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6902076601982117    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2377101480960846    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.6902076601982117, 'test_mse': 0.2377101480960846, 'test_iou': 0.4431334435939789}]\n",
      "MSE value is 0.2377101480960846\n",
      "IoU value is 0.4431334435939789\n",
      "num_param value is 671180\n",
      "Training time: 412.97500228881836\n",
      "Fitness: 11.839590494036724\n",
      "********\n",
      "chromosome: ['LDd0.24n1', 'PM2', 'Ldo05arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LRr2agn1', 'Uf2mnearest', 'S1', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'LDd0.24n1', 'HS'], fitness: 11.839590494036724, IoU: 0.4431334435939789, FPS: 194.3714812547415, Model Size: 671180\n",
      "\n",
      "Architecture: LDd0.38n1EPM2ELbo11k3s1p1arn1EPM2ELRr4arn1EUf2mnearestES1ELbo11k3s1p1arn1EUf2mnearestES0ELDd0.38n1EHSEE\n",
      "Chromosome: ['LDd0.38n1', 'PM2', 'Lbo11k3s1p1arn1', 'PM2', 'LRr4arn1', 'Uf2mnearest', 'S1', 'Lbo11k3s1p1arn1', 'Uf2mnearest', 'S0', 'LDd0.38n1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 7060186\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 17:36:23.932203012 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:23.933423268 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:23.988402103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 17:36:23.988444516 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 7.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "7.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.1 M     Total params\n",
      "28.241    Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5df69afbb14b7a82a4f2dca1397fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:11:15.381999738 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:11:15.416428235 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:11:15.435411068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:11:15.442429182 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3262da93d9b4ec19f4d42345634edb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.47447168827056885    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7061827182769775     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2555891275405884     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.47447168827056885   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7061827182769775    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2555891275405884    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:12:41.174700526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:12:41.176689223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:12:41.189111026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:12:41.193791986 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3005a7b30dc94b80bad3dcef7cfc7268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4663792848587036     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7135511040687561     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26074257493019104    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4663792848587036    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7135511040687561    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26074257493019104   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7135511040687561, 'test_mse': 0.26074257493019104, 'test_iou': 0.4663792848587036}]\n",
      "MSE value is 0.26074257493019104\n",
      "IoU value is 0.4663792848587036\n",
      "num_param value is 7060186\n",
      "Training time: 5692.484607219696\n",
      "Fitness: 5.535440197320986\n",
      "********\n",
      "chromosome: ['LDd0.38n1', 'PM2', 'Lbo11k3s1p1arn1', 'PM2', 'LRr4arn1', 'Uf2mnearest', 'S1', 'Lbo11k3s1p1arn1', 'Uf2mnearest', 'S0', 'LDd0.38n1', 'HS'], fitness: 5.535440197320986, IoU: 0.4663792848587036, FPS: 27.060730171070162, Model Size: 7060186\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo12arn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 89193\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:13:55.274188067 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:13:55.285177821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:13:55.298098755 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:13:55.301810977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 89.2 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "89.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.2 K    Total params\n",
      "0.357     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde7e0ff719e466499c0194553893353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:17:32.805888066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:32.815213199 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:32.815957398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:32.821596734 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a11aa9616b4b1787709f5d5a46280f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6997541189193726     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3267463147640228     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052691224962472916    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6997541189193726    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3267463147640228    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052691224962472916   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:17:38.093681850 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:38.099633367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:38.100527810 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:38.109402377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f6ee93e2904d678b76a9b716691474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.687991201877594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3276923596858978     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052793461829423904    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.687991201877594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3276923596858978    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052793461829423904   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3276923596858978, 'test_mse': 0.052793461829423904, 'test_iou': 0.687991201877594}]\n",
      "MSE value is 0.052793461829423904\n",
      "IoU value is 0.687991201877594\n",
      "num_param value is 89193\n",
      "Training time: 216.71831703186035\n",
      "Fitness: 16.28925825041511\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 16.28925825041511, IoU: 0.687991201877594, FPS: 341.983653322525, Model Size: 89193\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPM2ELdo08arn1EUf2mnearestES0ELco09k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Ldo08arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 72647946 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Ldo08arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne3arn1EPa2ELme6agn1EPM2ELco05k5s1p2arn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EHSEE\n",
      "Chromosome: ['Lne3arn1', 'Pa2', 'Lme6agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 46288\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:17:44.642983697 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:44.645016885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:44.732415723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:17:44.732459468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 46.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "46.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.3 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1194851c074372b325a3b60a4aefc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:22:07.442347948 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:07.447716840 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:07.449793649 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:07.451617192 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d69e49b1ab4009b98f412eef7f67d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6798798441886902     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3481135368347168     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07619483023881912    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6798798441886902    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3481135368347168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07619483023881912   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:22:15.097991568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:15.098714552 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:15.109059793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:15.111620424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20e1aa80cfa4dcd85e4fedab89c0d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6867817044258118     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34025266766548157    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0695311427116394     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6867817044258118    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34025266766548157   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0695311427116394    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34025266766548157, 'test_mse': 0.0695311427116394, 'test_iou': 0.6867817044258118}]\n",
      "MSE value is 0.0695311427116394\n",
      "IoU value is 0.6867817044258118\n",
      "num_param value is 46288\n",
      "Training time: 262.8057928085327\n",
      "Fitness: 16.171420413149413\n",
      "********\n",
      "chromosome: ['Lne3arn1', 'Pa2', 'Lme6agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'HS'], fitness: 16.171420413149413, IoU: 0.6867817044258118, FPS: 290.0671310816147, Model Size: 46288\n",
      "\n",
      "Architecture: Lme4agn1EPM2ELeo11k5s1p2agn1EPa2ELRr4arn1EPM2ELme6agn1EUf2mnearestES2ELRr4arn1EUf2mnearestES1ELeo11k5s1p2agn1EUf2mnearestES0ELme4agn1EHSEE\n",
      "Chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'LRr4arn1', 'PM2', 'Lme6agn1', 'Uf2mnearest', 'S2', 'LRr4arn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 14081161 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'LRr4arn1', 'PM2', 'Lme6agn1', 'Uf2mnearest', 'S2', 'LRr4arn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo05arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 31574\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:22:22.272875552 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:22.273657689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:22.324502520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:22:22.324502523 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.6 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.6 K    Total params\n",
      "0.126     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1c04fa87a1413db05fe9df317285a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:26:02.995660975 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:02.003358116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:02.004118117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:02.004763335 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dd25dc26c8441c990deba6e7168ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6799907684326172     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3141964375972748     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.046982068568468094    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6799907684326172    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3141964375972748    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.046982068568468094   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:26:08.152543329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:08.153447175 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:08.176947658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:08.185571643 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35abe3a91d5c4946a6d32723b780a816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6720260381698608     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31375807523727417    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04656176269054413    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6720260381698608    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31375807523727417   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04656176269054413   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.31375807523727417, 'test_mse': 0.04656176269054413, 'test_iou': 0.6720260381698608}]\n",
      "MSE value is 0.04656176269054413\n",
      "IoU value is 0.6720260381698608\n",
      "num_param value is 31574\n",
      "Training time: 219.7538561820984\n",
      "Fitness: 16.243784185283168\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 16.243784185283168, IoU: 0.6720260381698608, FPS: 350.84364294016615, Model Size: 31574\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELco04k5s1p2agn1EPa2ELbo09k5s1p2arn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELdo11agn1EHSEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 26116174 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPa2ELRr4arn1EPa2ELne6agn1EPa2ELco07k5s1p2arn1EUf2mnearestES2ELne6agn1EUf2mnearestES1ELRr4arn1EUf2mnearestES0ELco06k5s1p2arn1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'LRr4arn1', 'Pa2', 'Lne6agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 14471529 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'LRr4arn1', 'Pa2', 'Lne6agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPM2ELbo09k5s1p2agn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'PM2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 22638114 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'PM2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr4arn1EPM2ELRr2agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES2ELRr3arn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'PM2', 'LRr2agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 49266\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:26:14.554767479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:14.568800157 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:14.568819975 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:26:14.571549531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 49.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "49.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "49.3 K    Total params\n",
      "0.197     Total estimated model params size (MB)\n",
      "111       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0178eb8e47384a4fb2cac17952a8215f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:28:20.380859266 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:20.385556363 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:20.387140002 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:20.395917771 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970223372a954b478d37407595337594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6841673851013184     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3754676878452301     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07923808693885803    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6841673851013184    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3754676878452301    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07923808693885803   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:28:26.882418862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:26.882937764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:26.884334920 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:26.890975091 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c71ec9402f4f0b8783caadc96cf5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6821239590644836     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3732079863548279     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07837411761283875    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6821239590644836    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3732079863548279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07837411761283875   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3732079863548279, 'test_mse': 0.07837411761283875, 'test_iou': 0.6821239590644836}]\n",
      "MSE value is 0.07837411761283875\n",
      "IoU value is 0.6821239590644836\n",
      "num_param value is 49266\n",
      "Training time: 125.815358877182\n",
      "Fitness: 16.04519318732495\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'PM2', 'LRr2agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.04519318732495, IoU: 0.6821239590644836, FPS: 385.6503594545162, Model Size: 49266\n",
      "\n",
      "Architecture: Ldo06agn1EPM2ELdo11agn1EPa2ELco07k5s1p2agn1EPa2ELeo09k5s1p2agn1EUf2mnearestES2ELco07k5s1p2agn1EUf2mnearestES1ELdo11agn1EUf2mnearestES0ELdo06agn1EHSEE\n",
      "Chromosome: ['Ldo06agn1', 'PM2', 'Ldo11agn1', 'Pa2', 'Lco07k5s1p2agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco07k5s1p2agn1', 'Uf2mnearest', 'S1', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Ldo06agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 60758586 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo06agn1', 'PM2', 'Ldo11agn1', 'Pa2', 'Lco07k5s1p2agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco07k5s1p2agn1', 'Uf2mnearest', 'S1', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Ldo06agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPM2ELbo11k5s1p2agn1EUf2mnearestES0ELco09k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lbo11k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 109178118 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lbo11k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo11k3s1p1arn1EPa2ELDd0.31n1EPM2ELdo09agn1EUf2mnearestES1ELDd0.31n1EUf2mnearestES0ELeo11k3s1p1arn1EHSEE\n",
      "Chromosome: ['Leo11k3s1p1arn1', 'Pa2', 'LDd0.31n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'LDd0.31n1', 'Uf2mnearest', 'S0', 'Leo11k3s1p1arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.31}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.31}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 68170564 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo11k3s1p1arn1', 'Pa2', 'LDd0.31n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'LDd0.31n1', 'Uf2mnearest', 'S0', 'Leo11k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo12k5s1p2arn1EPa2ELne4arn1EUf2mnearestES0ELeo12k5s1p2arn1EHSEE\n",
      "Chromosome: ['Leo12k5s1p2arn1', 'Pa2', 'Lne4arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 11473984 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo12k5s1p2arn1', 'Pa2', 'Lne4arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo05arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 6932496\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 19:28:33.521138156 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:33.525841823 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:33.534593594 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 19:28:33.536478479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 6.9 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "6.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.9 M     Total params\n",
      "27.730    Total estimated model params size (MB)\n",
      "25        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d215f74177a5442691599b171b63ab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:51:14.307056623 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:51:14.307820677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:51:14.308765439 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:51:14.314133009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc97bbeae624aeeb4de9c1a68f8915b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6335407495498657     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49553847312927246    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14627334475517273    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6335407495498657    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49553847312927246   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14627334475517273   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:53:03.252770746 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:53:03.255840083 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:53:03.260944374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:53:03.264013340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee59e22d3f7241ed926d3f4a028b1976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.628583550453186     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4968811571598053     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14680251479148865    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.628583550453186    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4968811571598053    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14680251479148865   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4968811571598053, 'test_mse': 0.14680251479148865, 'test_iou': 0.628583550453186}]\n",
      "MSE value is 0.14680251479148865\n",
      "IoU value is 0.628583550453186\n",
      "num_param value is 6932496\n",
      "Training time: 4961.014169692993\n",
      "Fitness: 8.073236671672444\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: 8.073236671672444, IoU: 0.628583550453186, FPS: 21.288440805385363, Model Size: 6932496\n",
      "\n",
      "Architecture: LRr2arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:54:37.281082103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:54:37.282531274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:54:37.288843217 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:54:37.294290418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7879ee47a5b44a6e8504f8aa5bc7ca09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:57:18.756743653 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:18.760309678 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:18.763117089 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:18.771131653 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec361d7802b747c783a7afad48013007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7343714237213135     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32554152607917786    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05305716022849083    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7343714237213135    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32554152607917786   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05305716022849083   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:57:23.229299644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:23.229618245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:23.229734100 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:23.235398105 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0f49e25e8a4da5b2cd4bc76ec46eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7324221730232239     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3167007565498352     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.047851189970970154    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7324221730232239    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3167007565498352    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.047851189970970154   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3167007565498352, 'test_mse': 0.047851189970970154, 'test_iou': 0.7324221730232239}]\n",
      "MSE value is 0.047851189970970154\n",
      "IoU value is 0.7324221730232239\n",
      "num_param value is 51876\n",
      "Training time: 160.59887027740479\n",
      "Fitness: 16.81568556293982\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 16.81568556293982, IoU: 0.7324221730232239, FPS: 397.40193392046774, Model Size: 51876\n",
      "\n",
      "Architecture: Lme3agn1EPa2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['Lme3agn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 31574\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 20:57:28.387014268 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:28.391326613 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:28.395409208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 20:57:28.403226303 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.6 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.6 K    Total params\n",
      "0.126     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace5df6bfe3941d68ad56c97640cbf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:01:34.570481169 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:34.571331937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:34.574165588 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:34.577984622 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdda578e44f04df39832134ae62b9b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7370553612709045     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.30612912774086      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04343452304601669    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7370553612709045    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.30612912774086     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04343452304601669   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:01:41.839773309 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:41.846857793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:41.848808660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:41.852394425 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81adeba133442119d76effda2085900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.738274097442627     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3056669533252716     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04279475659132004    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.738274097442627    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3056669533252716    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04279475659132004   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3056669533252716, 'test_mse': 0.04279475659132004, 'test_iou': 0.738274097442627}]\n",
      "MSE value is 0.04279475659132004\n",
      "IoU value is 0.738274097442627\n",
      "num_param value is 31574\n",
      "Training time: 246.17386746406555\n",
      "Fitness: 16.94078174453494\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.94078174453494, IoU: 0.738274097442627, FPS: 345.6349811966443, Model Size: 31574\n",
      "\n",
      "Text file saved: ./logs/GA_logs/GA_generation_0.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 1 ***\n",
      "Architecture: LRr2arn1EPa2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:01:47.760153264 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:47.760153342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:47.763070977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:01:47.771049152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32df939b227f4cd6b838a10ba1cabb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:05:17.019487658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:17.021197082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:17.022152500 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:17.032050467 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03789f2804d549768ab81f5413841124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6913070678710938     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3427184820175171     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.058448486030101776    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6913070678710938    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3427184820175171    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.058448486030101776   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:05:23.276607471 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:23.282946805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:23.285567356 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:23.287464979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bdb165c954486da7c4704e97726b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6798516511917114     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3456474244594574     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05953768640756607    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6798516511917114    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3456474244594574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05953768640756607   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3456474244594574, 'test_mse': 0.05953768640756607, 'test_iou': 0.6798516511917114}]\n",
      "MSE value is 0.05953768640756607\n",
      "IoU value is 0.6798516511917114\n",
      "num_param value is 30994\n",
      "Training time: 210.25099349021912\n",
      "Fitness: 16.205601145916134\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.205601145916134, IoU: 0.6798516511917114, FPS: 347.36491173831485, Model Size: 30994\n",
      "\n",
      "Architecture: Lme3agn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lme3agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 52456\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:05:29.111148449 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:29.114855880 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:29.115805301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:05:29.122897461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 52.5 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "52.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.5 K    Total params\n",
      "0.210     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363d96af91af49fd83906e3cf92b1d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:08:22.834097885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:22.836542470 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:22.836562048 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:22.838683894 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a42db4f45ad4922941a14adef75915c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7634029388427734     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3194776177406311     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05347125604748726    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7634029388427734    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3194776177406311    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05347125604748726   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:08:27.467605461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:27.468527253 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:27.470399158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:27.471470224 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e808c3b62c8543e2a825cb3370ff5170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7619927525520325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3232019245624542     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05537475645542145    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7619927525520325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3232019245624542    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05537475645542145   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3232019245624542, 'test_mse': 0.05537475645542145, 'test_iou': 0.7619927525520325}]\n",
      "MSE value is 0.05537475645542145\n",
      "IoU value is 0.7619927525520325\n",
      "num_param value is 52456\n",
      "Training time: 172.6757276058197\n",
      "Fitness: 17.042778698477512\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 17.042778698477512, IoU: 0.7619927525520325, FPS: 378.5734303857622, Model Size: 52456\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo12arn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 89193\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:08:33.958127892 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:33.958227805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:33.959277536 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:08:33.962766805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 89.2 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "89.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.2 K    Total params\n",
      "0.357     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a85ca120ba548e58e67e3b3414ebcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:12:11.097101232 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:11.100017565 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:11.102597144 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:11.109156073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cf6d3d440d4f30a0d543277e2ddf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.670089602470398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3883613049983978     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0826970636844635     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.670089602470398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3883613049983978    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0826970636844635    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:12:17.458578749 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:17.459283189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:17.461362518 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:17.462158814 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fa402619ac4fae935782b5e1608558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6610190868377686     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39649394154548645    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08667002618312836    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6610190868377686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39649394154548645   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08667002618312836   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.39649394154548645, 'test_mse': 0.08667002618312836, 'test_iou': 0.6610190868377686}]\n",
      "MSE value is 0.08667002618312836\n",
      "IoU value is 0.6610190868377686\n",
      "num_param value is 89193\n",
      "Training time: 218.29113292694092\n",
      "Fitness: 15.723423406076998\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 15.723423406076998, IoU: 0.6610190868377686, FPS: 343.98759175618113, Model Size: 89193\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo05arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 31574\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:12:23.403353894 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:23.408070339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:23.409017495 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:12:23.416530099 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.6 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.6 K    Total params\n",
      "0.126     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252ed11267504b5cb73f0a1caab43706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:16:04.834736567 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:04.834811977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:04.834839018 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:04.843304650 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fc519ec5f64cdea9158c4e520fa2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6475904583930969     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33045142889022827    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054890625178813934    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6475904583930969    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33045142889022827   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054890625178813934   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:16:10.164160110 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:10.165326663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:10.166198538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:10.172062793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc825845d1f34553ad0f0f113341283b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6439453363418579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33136504888534546    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.055714379996061325    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6439453363418579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33136504888534546   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.055714379996061325   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.33136504888534546, 'test_mse': 0.055714379996061325, 'test_iou': 0.6439453363418579}]\n",
      "MSE value is 0.055714379996061325\n",
      "IoU value is 0.6439453363418579\n",
      "num_param value is 31574\n",
      "Training time: 220.41289377212524\n",
      "Fitness: 15.880138328042426\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 15.880138328042426, IoU: 0.6439453363418579, FPS: 340.5078346034475, Model Size: 31574\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPM2ELRr2agn1EPM2ELco05k5s1p2arn1EUf2mnearestES2ELRr3arn1EUf2mnearestES1ELRr2agn1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'PM2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 722722\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:16:16.144360292 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:16.144447355 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:16.146869804 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:16:16.149302488 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 722 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "722 K     Trainable params\n",
      "0         Non-trainable params\n",
      "722 K     Total params\n",
      "2.891     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d10de4db7fe49498fed892e79b050fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:31:03.155812598 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:03.156845849 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:03.156855945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:03.157983125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df311402397c4083b6d49a698d527cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5339035391807556     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46303778886795044    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16662009060382843    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5339035391807556    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46303778886795044   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16662009060382843   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:31:17.010493604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:17.011182821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:17.011853487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:17.019798913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdef83f1fc04bee97cd73d61e8e308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5513355135917664     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4614877998828888     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16192519664764404    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5513355135917664    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4614877998828888    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16192519664764404   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4614877998828888, 'test_mse': 0.16192519664764404, 'test_iou': 0.5513355135917664}]\n",
      "MSE value is 0.16192519664764404\n",
      "IoU value is 0.5513355135917664\n",
      "num_param value is 722722\n",
      "Training time: 887.0765483379364\n",
      "Fitness: 13.397039149705588\n",
      "********\n",
      "chromosome: ['Lco06k5s1p2arn1', 'PM2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'HS'], fitness: 13.397039149705588, IoU: 0.5513355135917664, FPS: 163.28560073709113, Model Size: 722722\n",
      "\n",
      "Architecture: LRr4arn1EPa2ELme6agn1EPM2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:31:29.363140346 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:29.364438122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:29.366667404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:31:29.371685013 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb1ace2149d4a7f869840322b695bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:34:55.493552245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:34:55.494928550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:34:55.497242966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:34:55.498645328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40a195e6cda44f783af8e65492169cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7467809915542603     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4344801902770996     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11118073761463165    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7467809915542603    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4344801902770996    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11118073761463165   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:35:01.649977527 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:01.649978162 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:01.653040105 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:01.658673377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4a8e6eb8244513ab5741c3678a589a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7474590539932251     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4367235004901886     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11267311125993729    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7474590539932251    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4367235004901886    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11267311125993729   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4367235004901886, 'test_mse': 0.11267311125993729, 'test_iou': 0.7474590539932251}]\n",
      "MSE value is 0.11267311125993729\n",
      "IoU value is 0.7474590539932251\n",
      "num_param value is 107631\n",
      "Training time: 206.12837886810303\n",
      "Fitness: 16.354325100223793\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.354325100223793, IoU: 0.7474590539932251, FPS: 348.1683472001209, Model Size: 107631\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:35:07.534951689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:07.541522121 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:07.543828887 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:35:07.551017541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7112965214426099cddea9cc8d82cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:36:10.158574991 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:10.158576732 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:10.161380896 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:10.165378512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dbc7332cfb4d8aab118f8365d867b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7006839513778687     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32386478781700134    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054043225944042206    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7006839513778687    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32386478781700134   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054043225944042206   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:36:15.333264786 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:15.336051764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:15.336242170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:15.341553236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f249a068d53496f8598ab9bd77f2215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6793685555458069     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32970473170280457    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05647490546107292    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6793685555458069    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32970473170280457   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05647490546107292   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32970473170280457, 'test_mse': 0.05647490546107292, 'test_iou': 0.6793685555458069}]\n",
      "MSE value is 0.05647490546107292\n",
      "IoU value is 0.6793685555458069\n",
      "num_param value is 1566\n",
      "Training time: 62.67018699645996\n",
      "Fitness: 16.25755971717752\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 16.25755971717752, IoU: 0.6793685555458069, FPS: 409.06619657697655, Model Size: 1566\n",
      "\n",
      "Architecture: LDd0.24n1EPM2ELdo05arn1EPa2ELRr2agn1EPa2ELme3arn1EUf2mnearestES2ELDd0.45n1EUf2mnearestES1ELdo05arn1EUf2mnearestES0ELbo12k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.24n1', 'PM2', 'Ldo05arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'Uf2mnearest', 'S1', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 89274218 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.24n1', 'PM2', 'Ldo05arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'Uf2mnearest', 'S1', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo08agn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 15564756 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.38n1EPM2ELbo11k3s1p1arn1EPM2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELDd0.38n1EHSEE\n",
      "Chromosome: ['LDd0.38n1', 'PM2', 'Lbo11k3s1p1arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'LDd0.38n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1460592\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:36:21.422673256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:21.423218246 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:21.425019494 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:36:21.430387407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.842     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70ae13c929a4feebd173bc6b2a92b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:57:09.394960046 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:09.396087299 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:09.396896551 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:09.400772890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8ed0f7780d442b96efe119d58c645c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4289070665836334     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7166179418563843     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2821876108646393     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4289070665836334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7166179418563843    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2821876108646393    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:57:28.014509265 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:28.015487097 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:28.016041837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:28.020547589 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661253046fe74399af723719f554df50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4124954342842102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7206399440765381     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2868044376373291     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4124954342842102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7206399440765381    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2868044376373291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7206399440765381, 'test_mse': 0.2868044376373291, 'test_iou': 0.4124954342842102}]\n",
      "MSE value is 0.2868044376373291\n",
      "IoU value is 0.4124954342842102\n",
      "num_param value is 1460592\n",
      "Training time: 1248.173727273941\n",
      "Fitness: 10.435550961340157\n",
      "********\n",
      "chromosome: ['LDd0.38n1', 'PM2', 'Lbo11k3s1p1arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'LDd0.38n1', 'HS'], fitness: 10.435550961340157, IoU: 0.4124954342842102, FPS: 122.55227678117365, Model Size: 1460592\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELeo12k5s1p2arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 20612214 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo12k5s1p2arn1EPM2ELdo08arn1EUf2mnearestES0ELco09k5s1p2agn1EHSEE\n",
      "Chromosome: ['Leo12k5s1p2arn1', 'PM2', 'Ldo08arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 129140676 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo12k5s1p2arn1', 'PM2', 'Ldo08arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme4agn1EPM2ELeo11k5s1p2agn1EPa2ELRr4arn1EPM2ELDd0.30n1EUf2mnearestES2ELRr4arn1EUf2mnearestES0ELdo11agn1EUf2mnearestES0ELme4agn1EHSEE\n",
      "Chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'LRr4arn1', 'PM2', 'LDd0.30n1', 'Uf2mnearest', 'S2', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 15193195 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'LRr4arn1', 'PM2', 'LDd0.30n1', 'Uf2mnearest', 'S2', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELco04k5s1p2agn1EPa2ELbo09k5s1p2arn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES1ELeo11k5s1p2agn1EHSEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 26116174 exceed the threshold of 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELRr2arn1EPa2ELdo09agn1EPa2ELco07k5s1p2arn1EUf2mnearestES2ELne6agn1EUf2mnearestES1ELRr4arn1EUf2mnearestES0ELco06k5s1p2arn1EHSEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo09agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 21551979 exceed the threshold of 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo09agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr4arn1EPM2ELbo09k5s1p2agn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr4arn1', 'PM2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 22638114 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr4arn1', 'PM2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELne4agn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 15574581 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1273528\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 21:57:47.936482604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:47.936647181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:47.944932374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 21:57:47.949641014 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.3 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.094     Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4f7f579b784b8193b2205bfd92f5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:29:01.527986958 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:01.548839464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:01.549096888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:01.551068096 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb2255ebcd245eca37b48be9b45f42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.613939642906189     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33793386816978455    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08774915337562561    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.613939642906189    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33793386816978455   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08774915337562561   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:29:27.101876011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:27.105143260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:27.106376307 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:27.108917987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d5432cd1574856846aa8162e46a54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6163573265075684     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35780707001686096    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09303813427686691    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6163573265075684    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35780707001686096   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09303813427686691   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.35780707001686096, 'test_mse': 0.09303813427686691, 'test_iou': 0.6163573265075684}]\n",
      "MSE value is 0.09303813427686691\n",
      "IoU value is 0.6163573265075684\n",
      "num_param value is 1273528\n",
      "Training time: 1874.897144794464\n",
      "Fitness: 14.03885689973636\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 14.03885689973636, IoU: 0.6163573265075684, FPS: 89.63186050480962, Model Size: 1273528\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELdo05agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 71868146 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELdo10agn1EUf2mnearestES0ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'Ldo10agn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 19385338 exceed the threshold of 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'Ldo10agn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 1, the best fitness of the population is 17.042778698477512.\n",
      "The best historical fitness is 17.042778698477512,with the most fit individual having the following genes: ['Lme3agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_1.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 2 ***\n",
      "Architecture: LRr4arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:29:50.624395497 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:50.631217302 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:50.634144883 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:29:50.641715096 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c467cb07b61940f6ab47dffa8b0b1b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:32:31.097841513 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:31.101584542 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:31.103600468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:31.108365587 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cb23f4d7f94831941569b1543ffb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6818923950195312     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38436993956565857    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08243197947740555    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6818923950195312    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38436993956565857   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08243197947740555   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:32:37.850064992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:37.853837778 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:37.855224151 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:37.862415868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a350808466f4d90bf39aa80bd4843ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6750849485397339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3828454315662384     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08235298097133636    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6750849485397339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3828454315662384    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08235298097133636   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3828454315662384, 'test_mse': 0.08235298097133636, 'test_iou': 0.6750849485397339}]\n",
      "MSE value is 0.08235298097133636\n",
      "IoU value is 0.6750849485397339\n",
      "num_param value is 51876\n",
      "Training time: 160.7346911430359\n",
      "Fitness: 15.938103580484892\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 15.938103580484892, IoU: 0.6750849485397339, FPS: 370.8606695044205, Model Size: 51876\n",
      "\n",
      "Architecture: Lme3agn1EPa2ELme6agn1EPM2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lme3agn1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 108211\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:32:42.337399601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:42.340882878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:42.343759678 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:32:42.347544084 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 108 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.433     Total estimated model params size (MB)\n",
      "103       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa158d61d8d4b71bc87ec3b0ee5fc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:36:19.905755528 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:19.911979338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:19.914958085 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:19.919703663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e83473443e141f9af2d55a85936523f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7510963082313538     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3676922023296356     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07949750870466232    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7510963082313538    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3676922023296356    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07949750870466232   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:36:25.580907265 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:25.583137481 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:25.583145895 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:25.589376801 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc94294e43841e0b1ba36071b54b5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7507734894752502     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3655225932598114     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07819528132677078    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7507734894752502    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3655225932598114    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07819528132677078   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3655225932598114, 'test_mse': 0.07819528132677078, 'test_iou': 0.7507734894752502}]\n",
      "MSE value is 0.07819528132677078\n",
      "IoU value is 0.7507734894752502\n",
      "num_param value is 108211\n",
      "Training time: 216.56952333450317\n",
      "Fitness: 16.674281606263282\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.674281606263282, IoU: 0.7507734894752502, FPS: 323.9791457210354, Model Size: 108211\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:36:32.851362492 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:32.852892865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:32.857170028 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:36:32.860916913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b3bb38fac24de7a43278c5e84c2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:37:33.783828737 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:33.785823669 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:33.786050859 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:33.790318458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e8dc6748d242178295bf1f125de2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6497910618782043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.341068297624588     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060116905719041824    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6497910618782043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.341068297624588    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060116905719041824   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:37:38.089411473 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:38.091219349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:38.092197830 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:38.101579362 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f099e5821db04f03b24ff602975fb800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6457875370979309     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3468257188796997     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06270696222782135    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6457875370979309    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3468257188796997    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06270696222782135   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3468257188796997, 'test_mse': 0.06270696222782135, 'test_iou': 0.6457875370979309}]\n",
      "MSE value is 0.06270696222782135\n",
      "IoU value is 0.6457875370979309\n",
      "num_param value is 1566\n",
      "Training time: 60.93812322616577\n",
      "Fitness: 15.866241135269583\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 15.866241135269583, IoU: 0.6457875370979309, FPS: 398.2448492794275, Model Size: 1566\n",
      "\n",
      "Architecture: LRr2arn1EPa2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:37:43.206918896 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:43.217022939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:43.218462579 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:37:43.223989147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b039ad928141d88ee4c7e648b6d7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:41:13.084015740 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:13.084806374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:13.085886446 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:13.087042071 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a97bc3b89104f708de30a2c149cdb1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6883843541145325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34919998049736023    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05999171361327171    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6883843541145325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34919998049736023   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05999171361327171   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:41:20.864507103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:20.864591736 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:20.866451078 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:20.872746621 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c144859499d4f2a8bb083a65c734b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.67806077003479      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35327380895614624    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.061801474541425705    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.67806077003479     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35327380895614624   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061801474541425705   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.35327380895614624, 'test_mse': 0.061801474541425705, 'test_iou': 0.67806077003479}]\n",
      "MSE value is 0.061801474541425705\n",
      "IoU value is 0.67806077003479\n",
      "num_param value is 30994\n",
      "Training time: 209.87792253494263\n",
      "Fitness: 16.167570107235388\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.167570107235388, IoU: 0.67806077003479, FPS: 314.49078473447605, Model Size: 30994\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo05arn1EUf2mnearestES0ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2822264\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 22:41:26.346840244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:26.347829443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:26.347912041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 22:41:26.349292619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.289    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f45d92b9fa463a8385bd326d094e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:21:07.992151637 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:07.993211863 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:07.995093180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:07.003839740 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c51c825123484abbd78ad3f80c6602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6488989591598511     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3394656777381897     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0633511021733284     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6488989591598511    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3394656777381897    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0633511021733284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:21:49.321694846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:49.323167066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:49.323608892 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:21:49.325041494 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c06874bb65f46cc8861dcdcfe1e036c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6353592276573181     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34142613410949707    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06432747095823288    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6353592276573181    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34142613410949707   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06432747095823288   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34142613410949707, 'test_mse': 0.06432747095823288, 'test_iou': 0.6353592276573181}]\n",
      "MSE value is 0.06432747095823288\n",
      "IoU value is 0.6353592276573181\n",
      "num_param value is 2822264\n",
      "Training time: 2380.645746946335\n",
      "Fitness: 12.926932799490194\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco12k5s1p2agn1', 'HS'], fitness: 12.926932799490194, IoU: 0.6353592276573181, FPS: 54.368742660217016, Model Size: 2822264\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo12arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 134482\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:22:26.211568624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:22:26.211636236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:22:26.213763236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:22:26.222860241 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 134 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "134 K     Trainable params\n",
      "0         Non-trainable params\n",
      "134 K     Total params\n",
      "0.538     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c61c8f47ee4016a2bbc65abcab3009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:30:38.456609247 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:38.456916136 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:38.460585460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:38.470074103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bce0d1af594b6ab57eeed4a72a46a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7327191233634949     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3560832440853119     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06671865284442902    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7327191233634949    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3560832440853119    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06671865284442902   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:30:48.338024992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:48.339538294 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:48.340993726 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:48.349792376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb61d08338ef4d6a861a38f4566cc264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7280097007751465     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3486030101776123     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06214402616024017    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7280097007751465    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3486030101776123    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06214402616024017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3486030101776123, 'test_mse': 0.06214402616024017, 'test_iou': 0.7280097007751465}]\n",
      "MSE value is 0.06214402616024017\n",
      "IoU value is 0.7280097007751465\n",
      "num_param value is 134482\n",
      "Training time: 492.24596095085144\n",
      "Fitness: 16.560534033517705\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 16.560534033517705, IoU: 0.7280097007751465, FPS: 226.7878395917293, Model Size: 134482\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPM2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2835214\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W820 23:30:57.261016306 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:57.266264682 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:57.269254752 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W820 23:30:57.270692347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.341    Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9ed629f6aa403ea318516d84bb0dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:00:34.565865506 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:00:34.567437002 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:00:34.569217224 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:00:34.570100295 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8f0af7064b414a81d3b2fef49d7d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6257791519165039     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3545827567577362     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.200119748711586     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6257791519165039    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3545827567577362    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.200119748711586    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:01:16.706255673 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:16.707311951 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:16.708356474 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:16.711724247 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68211b09b21145d3866b2aca8f49c020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6267685890197754     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35673218965530396    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19931814074516296    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6267685890197754    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35673218965530396   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19931814074516296   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.35673218965530396, 'test_mse': 0.19931814074516296, 'test_iou': 0.6267685890197754}]\n",
      "MSE value is 0.19931814074516296\n",
      "IoU value is 0.6267685890197754\n",
      "num_param value is 2835214\n",
      "Training time: 1777.274908065796\n",
      "Fitness: 11.770543049353886\n",
      "********\n",
      "chromosome: ['Lco06k5s1p2arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 11.770543049353886, IoU: 0.6267685890197754, FPS: 54.72106828657817, Model Size: 2835214\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELRr2agn1EPM2ELco05k5s1p2arn1EUf2mnearestES2ELRr3arn1EUf2mnearestES1ELRr2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 324377\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:01:53.346504343 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:53.354923112 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:53.355730254 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:01:53.357097634 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 324 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "324 K     Trainable params\n",
      "0         Non-trainable params\n",
      "324 K     Total params\n",
      "1.298     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71056adcb9484b4a9bfb29d65754a61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:06:45.385021276 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:45.387049741 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:45.389570308 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:45.395252092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9db5a8df8f4e54a0ad96dc808609d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45189860463142395    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5552204847335815     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32079485058784485    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45189860463142395   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5552204847335815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32079485058784485   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:06:56.822993940 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:56.823122897 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:56.824147087 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:06:56.831859734 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97db29011d144d67853291e48b210fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4549587070941925     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5464158654212952     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.29972755908966064    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4549587070941925    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5464158654212952    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.29972755908966064   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5464158654212952, 'test_mse': 0.29972755908966064, 'test_iou': 0.4549587070941925}]\n",
      "MSE value is 0.29972755908966064\n",
      "IoU value is 0.4549587070941925\n",
      "num_param value is 324377\n",
      "Training time: 292.0324306488037\n",
      "Fitness: 11.919130177555713\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'HS'], fitness: 11.919130177555713, IoU: 0.4549587070941925, FPS: 213.2358952187782, Model Size: 324377\n",
      "\n",
      "Architecture: LDd0.38n1EPM2ELdo05arn1EPM2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELdo05arn1EHSEE\n",
      "Chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 10601960 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.24n1EPa2ELbo11k3s1p1arn1EPa2ELRr2agn1EPa2ELme3arn1EUf2mnearestES2ELDd0.45n1EUf2mnearestES1ELDd0.38n1EUf2mnearestES0ELbo12k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'Uf2mnearest', 'S1', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 8380582\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 00:07:05.459717080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:07:05.463655748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:07:05.466648989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 00:07:05.474518597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 8.4 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.522    Total estimated model params size (MB)\n",
      "55        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7074a8ab504b518745961d3f06f030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 01:24:52.887091752 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:24:52.887551545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:24:52.888056732 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:24:52.896828290 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc639014afe14446b85116165c40c80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7790613174438477     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7790613174438477    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 01:26:34.016890324 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:26:34.026148377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:26:34.030080455 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:26:34.034353241 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86829ec5f2dd4017839d1869c0df8bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7752878069877625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7752878069877625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7752878069877625, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 8380582\n",
      "Training time: 4666.424693107605\n",
      "Fitness: 5.391985658357372\n",
      "********\n",
      "chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'LRr2agn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'Uf2mnearest', 'S1', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS'], fitness: 5.391985658357372, IoU: 0.6023015975952148, FPS: 22.69629153891413, Model Size: 8380582\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo08agn1EUf2mnearestES0ELeo12k5s1p2arn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 20265056 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 15911914 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo12k5s1p2arn1EPM2ELRr3agn1EUf2mnearestES2ELco09k5s1p2agn1EHSEE\n",
      "Chromosome: ['Leo12k5s1p2arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 6761143\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 01:28:02.582727408 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:28:02.583179296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:28:02.583337823 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 01:28:02.592772165 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 6.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "6.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 M     Total params\n",
      "27.045    Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06166081f8bd441c96945e9c877feef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:36:18.845092707 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:36:18.849743404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:36:18.852619606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:36:18.861162979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc973823480b4adfb5f67585d2b3841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6292729377746582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5384717583656311     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16964897513389587    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6292729377746582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5384717583656311    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16964897513389587   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:37:54.824209077 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:37:54.826167770 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:37:54.827224756 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:37:54.836855952 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a82cdfc591347ae88e988d56eaa82cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6216984391212463     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.552868664264679     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17696872353553772    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6216984391212463    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.552868664264679    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17696872353553772   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.552868664264679, 'test_mse': 0.17696872353553772, 'test_iou': 0.6216984391212463}]\n",
      "MSE value is 0.17696872353553772\n",
      "IoU value is 0.6216984391212463\n",
      "num_param value is 6761143\n",
      "Training time: 4095.4846153259277\n",
      "Fitness: 7.952243886905509\n",
      "********\n",
      "chromosome: ['Leo12k5s1p2arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'HS'], fitness: 7.952243886905509, IoU: 0.6216984391212463, FPS: 24.229363090180087, Model Size: 6761143\n",
      "\n",
      "Architecture: Lme4agn1EPM2ELeo11k5s1p2agn1EPa2ELbo09k3s1p1arn1EPM2ELDd0.30n1EUf2mnearestES0ELRr4arn1EUf2mnearestES0ELdo11agn1EUf2mnearestES0ELme4agn1EHSEE\n",
      "Chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'Lbo09k3s1p1arn1', 'PM2', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 48562013 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'Lbo09k3s1p1arn1', 'PM2', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELco04k5s1p2agn1EPa2ELbo09k5s1p2arn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES1ELeo11k5s1p2agn1EHSEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 26116174 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Pa2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo11k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.35n1EPa2ELdo12agn1EPa2ELdo09agn1EPa2ELco07k5s1p2arn1EUf2mnearestES2ELne6agn1EUf2mnearestES1ELRr4arn1EUf2mnearestES0ELco06k5s1p2arn1EHSEE\n",
      "Chromosome: ['LDd0.35n1', 'Pa2', 'Ldo12agn1', 'Pa2', 'Ldo09agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 145613762 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.35n1', 'Pa2', 'Ldo12agn1', 'Pa2', 'Ldo09agn1', 'Pa2', 'Lco07k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lne6agn1', 'Uf2mnearest', 'S1', 'LRr4arn1', 'Uf2mnearest', 'S0', 'Lco06k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 248712443 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 86538\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:39:20.539741574 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:39:20.556247464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:39:20.559398784 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:39:20.560587274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 86.5 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "86.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 K    Total params\n",
      "0.346     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c38c46d4db24f539a00bd12219e1dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:42:58.381066170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:42:58.386152450 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:42:58.386178463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:42:58.388666809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19cffe18941448692ca92ced154a665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6273635029792786     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32370874285697937    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06972172856330872    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6273635029792786    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32370874285697937   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06972172856330872   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:43:07.093588464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:07.095377353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:07.095542273 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:07.101015629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bd49c01e264077b6c41915f6ed6cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.614846408367157     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3214101493358612     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.069522425532341     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.614846408367157    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3214101493358612    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.069522425532341    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3214101493358612, 'test_mse': 0.069522425532341, 'test_iou': 0.614846408367157}]\n",
      "MSE value is 0.069522425532341\n",
      "IoU value is 0.614846408367157\n",
      "num_param value is 86538\n",
      "Training time: 218.24584889411926\n",
      "Fitness: 15.411893659173906\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 15.411893659173906, IoU: 0.614846408367157, FPS: 252.15982623996348, Model Size: 86538\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 579714814 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne6arn1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 20619\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:43:20.951606152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:20.956634564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:20.966200568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:43:20.968717332 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 20.6 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e616fa4d8b4d2fa76622d2d7855f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:45:37.321773230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:37.322180978 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:37.326733077 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:37.334249099 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641bcd33522044d5b2beec37588bdc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6631219983100891     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33325475454330444    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05895165726542473    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6631219983100891    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33325475454330444   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05895165726542473   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:45:43.207967245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:43.210410075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:43.212415178 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:43.213382404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a44d7543c24488a18af0d20367db4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6537756323814392     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.335586279630661     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06013745814561844    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6537756323814392    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.335586279630661    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06013745814561844   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.335586279630661, 'test_mse': 0.06013745814561844, 'test_iou': 0.6537756323814392}]\n",
      "MSE value is 0.06013745814561844\n",
      "IoU value is 0.6537756323814392\n",
      "num_param value is 20619\n",
      "Training time: 137.74158668518066\n",
      "Fitness: 15.949876373986147\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.949876373986147, IoU: 0.6537756323814392, FPS: 364.4784727147372, Model Size: 20619\n",
      "\n",
      "For generation 2, the best fitness of the population is 16.674281606263282.\n",
      "The best historical fitness is 17.042778698477512,with the most fit individual having the following genes: ['Lme3agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_2.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 3 ***\n",
      "Architecture: LRr2arn1EPa2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:45:49.859926124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:49.862291641 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:49.864640645 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:45:49.871401258 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73db495fabf14ecbaf36eeb227d9ddfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:49:36.625036479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:36.626875061 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:36.626900803 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:36.634196725 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4476ff9089124760bcf6f618315b8e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7762175798416138     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3255510628223419     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0533103346824646     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7762175798416138    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3255510628223419    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0533103346824646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:49:43.071543259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:43.073059209 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:43.074487987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:43.083814021 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328a3cc8c3f54f7e87587670079dba41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7780498266220093     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32263311743736267    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052408743649721146    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7780498266220093    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32263311743736267   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052408743649721146   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32263311743736267, 'test_mse': 0.052408743649721146, 'test_iou': 0.7780498266220093}]\n",
      "MSE value is 0.052408743649721146\n",
      "IoU value is 0.7780498266220093\n",
      "num_param value is 107631\n",
      "Training time: 227.75521683692932\n",
      "Fitness: 17.174878780605944\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 17.174878780605944, IoU: 0.7780498266220093, FPS: 329.7402972361094, Model Size: 107631\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELdo12arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 135265\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:49:49.234591510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:49.234688791 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:49.235535314 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:49:49.242544768 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 135 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "135 K     Trainable params\n",
      "0         Non-trainable params\n",
      "135 K     Total params\n",
      "0.541     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5f1bb417ab4fe5a0377b91aba4c6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:58:18.307746554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:18.308596052 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:18.308606404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:18.315795459 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b371df13e94d15ba1cdfc609de3135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6875264644622803     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31174251437187195    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.051060307770967484    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6875264644622803    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31174251437187195   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.051060307770967484   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:58:28.257401406 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:28.271137591 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:28.271785167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:28.280149216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff34ec533e904a3e98d0db26d285928e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6864290833473206     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31179389357566833    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05089566856622696    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6864290833473206    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31179389357566833   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05089566856622696   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.31179389357566833, 'test_mse': 0.05089566856622696, 'test_iou': 0.6864290833473206}]\n",
      "MSE value is 0.05089566856622696\n",
      "IoU value is 0.6864290833473206\n",
      "num_param value is 135265\n",
      "Training time: 509.05195474624634\n",
      "Fitness: 16.244718303348304\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 16.244718303348304, IoU: 0.6864290833473206, FPS: 221.15715229921648, Model Size: 135265\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 02:58:37.396113862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:37.401900993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:37.401904829 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 02:58:37.404720026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569b3afcdf5c4c35a5c3ca4fbec9c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:02:30.302144994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:30.304121945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:30.304227743 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:30.311490171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dfa03458f247699e1c3fa0fe753bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7392816543579102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32216542959213257    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05242188647389412    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7392816543579102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32216542959213257   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05242188647389412   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:02:37.765557313 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:37.768336829 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:37.769626212 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:37.770360702 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e77813ffad45cb9342110980480121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7237817049026489     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32263728976249695    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052107930183410645    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7237817049026489    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32263728976249695   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052107930183410645   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32263728976249695, 'test_mse': 0.052107930183410645, 'test_iou': 0.7237817049026489}]\n",
      "MSE value is 0.052107930183410645\n",
      "IoU value is 0.7237817049026489\n",
      "num_param value is 30994\n",
      "Training time: 232.88860630989075\n",
      "Fitness: 16.71155133128241\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.71155133128241, IoU: 0.7237817049026489, FPS: 331.4344532356097, Model Size: 30994\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELRr4agn1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19430\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:02:43.889299212 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:43.890819217 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:43.894264239 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:02:43.895890531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd07b8cb30554fb2accd9e1d282ec876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:04:54.607159764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:04:54.607165080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:04:54.610649543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:04:54.611690057 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330c7ed024834faf98c163daa64509af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6423702239990234     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4010460078716278     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09366938471794128    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6423702239990234    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4010460078716278    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09366938471794128   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:05:00.419879229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:00.427514057 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:00.430732715 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:00.439105264 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ced26e13ca4758a96e4a74934db51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.64165860414505      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39834076166152954    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0927698165178299     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.64165860414505     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39834076166152954   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0927698165178299    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.39834076166152954, 'test_mse': 0.0927698165178299, 'test_iou': 0.64165860414505}]\n",
      "MSE value is 0.0927698165178299\n",
      "IoU value is 0.64165860414505\n",
      "num_param value is 19430\n",
      "Training time: 131.70070552825928\n",
      "Fitness: 15.548214067435826\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.548214067435826, IoU: 0.64165860414505, FPS: 362.5555339023418, Model Size: 19430\n",
      "\n",
      "Architecture: LRr4arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:05:06.019088795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:06.019250307 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:06.020639389 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:05:06.023760613 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e8d1db45ba422e9260611dce2e8ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:07:46.554611537 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:46.557887638 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:46.558824896 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:46.559123330 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4f7abce01d44a7b575651bc392958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7516086101531982     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34264716506004333    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06101538985967636    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7516086101531982    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34264716506004333   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06101538985967636   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:07:52.421025103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:52.422310967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:52.423050957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:52.430872532 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490de324b2e648e6bb656b4564341c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7432227730751038     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3314160108566284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05525698512792587    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7432227730751038    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3314160108566284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05525698512792587   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3314160108566284, 'test_mse': 0.05525698512792587, 'test_iou': 0.7432227730751038}]\n",
      "MSE value is 0.05525698512792587\n",
      "IoU value is 0.7432227730751038\n",
      "num_param value is 51876\n",
      "Training time: 160.5316858291626\n",
      "Fitness: 16.8567163897234\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 16.8567163897234, IoU: 0.7432227730751038, FPS: 368.56315602166933, Model Size: 51876\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:07:58.929542126 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:58.933837839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:58.936857664 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:07:58.946476213 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437a04abc55b434fb9054e5e80ed1422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:09:47.269415058 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:47.278772268 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:47.281975993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:47.292121340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d80c7935db4963bf5a2819b16434c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6344086527824402     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3327164947986603     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.059741731733083725    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6344086527824402    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3327164947986603    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.059741731733083725   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:09:52.672666686 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:52.675204412 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:52.684624749 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:52.690781460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538e5e204ee242cb9c2d75554557270c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6410585045814514     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3425517976284027     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06430210173130035    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6410585045814514    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3425517976284027    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06430210173130035   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3425517976284027, 'test_mse': 0.06430210173130035, 'test_iou': 0.6410585045814514}]\n",
      "MSE value is 0.06430210173130035\n",
      "IoU value is 0.6410585045814514\n",
      "num_param value is 1566\n",
      "Training time: 109.32776260375977\n",
      "Fitness: 15.80484752696944\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 15.80484752696944, IoU: 0.6410585045814514, FPS: 392.65351157424766, Model Size: 1566\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 86538\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:09:58.847044358 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:58.858893653 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:58.866129725 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:09:58.874601301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 86.5 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "86.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 K    Total params\n",
      "0.346     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4efe0dbc9f449858ee150744a23ee18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:13:35.718472832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:35.720430764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:35.720669321 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:35.729611809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c5e009d2c402f9cb7dfbb426f215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5390904545783997     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33225980401039124    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07351266592741013    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5390904545783997    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33225980401039124   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07351266592741013   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:13:44.546437067 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:44.546522671 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:44.549565939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:44.558337399 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdbeff062e24ba18b5129e44ca120c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5367139577865601     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.330473929643631     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07414872944355011    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5367139577865601    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.330473929643631    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07414872944355011   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.330473929643631, 'test_mse': 0.07414872944355011, 'test_iou': 0.5367139577865601}]\n",
      "MSE value is 0.07414872944355011\n",
      "IoU value is 0.5367139577865601\n",
      "num_param value is 86538\n",
      "Training time: 217.85750913619995\n",
      "Fitness: 14.590299318866869\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 14.590299318866869, IoU: 0.5367139577865601, FPS: 245.77304229210756, Model Size: 86538\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo05arn1EUf2mnearestES1ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2822264\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:13:53.785807687 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:53.792290550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:53.795256237 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:13:53.801210702 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.289    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40d5ba08f7b47658c994ab9aabeb4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:53:24.736087301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:53:24.736108212 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:53:24.739545272 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:53:25.745940211 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1043b870d654865a95a6928034cb6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6327260136604309     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4328048825263977     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10787355154752731    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6327260136604309    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4328048825263977    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10787355154752731   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:54:07.150621581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:07.150680696 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:07.152569497 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:07.161288197 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91d9c160106480db7045b693e0baddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6209046840667725     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43879586458206177    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11084509640932083    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6209046840667725    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43879586458206177   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11084509640932083   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.43879586458206177, 'test_mse': 0.11084509640932083, 'test_iou': 0.6209046840667725}]\n",
      "MSE value is 0.11084509640932083\n",
      "IoU value is 0.6209046840667725\n",
      "num_param value is 2822264\n",
      "Training time: 2371.9165709018707\n",
      "Fitness: 12.388938075744019\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS'], fitness: 12.388938075744019, IoU: 0.6209046840667725, FPS: 54.49541993281737, Model Size: 2822264\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELRr2agn1EPM2ELco05k5s1p2arn1EUf2mnearestES2ELdo07arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 20215787 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'LRr2agn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2394691\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 03:54:44.152240292 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:44.157377291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:44.160339347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 03:54:44.170236864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.4 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.579     Total estimated model params size (MB)\n",
      "65        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f495284e6c47888646a32921616121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:12:52.558862031 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:12:52.596620410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:12:52.597646903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:12:52.598818229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b78608ff4b4d10baf74497064937f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5269815921783447     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.786078155040741     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33181679248809814    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5269815921783447    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.786078155040741    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33181679248809814   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:13:21.981819192 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:21.005659463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:21.011532793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:21.016281101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fcd4cc79f84291b72328fe90e2718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5362122058868408     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7883691787719727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32839664816856384    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5362122058868408    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7883691787719727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32839664816856384   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7883691787719727, 'test_mse': 0.32839664816856384, 'test_iou': 0.5362122058868408}]\n",
      "MSE value is 0.32839664816856384\n",
      "IoU value is 0.5362122058868408\n",
      "num_param value is 2394691\n",
      "Training time: 1088.4091050624847\n",
      "Fitness: 10.495303109574662\n",
      "********\n",
      "chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 10.495303109574662, IoU: 0.5362122058868408, FPS: 80.56643975238813, Model Size: 2394691\n",
      "\n",
      "Architecture: Leo12k5s1p2arn1EPM2ELco04k5s1p2agn1EUf2mnearestES2ELDd0.45n1EHSEE\n",
      "Chromosome: ['Leo12k5s1p2arn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1740148\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:13:46.103429704 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:46.122911624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:46.123912368 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:13:46.130935454 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.7 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.961     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f7bd95f3c743e297b6fa2a4614642d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:31:37.897776047 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:37.902544682 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:37.952431703 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:37.952457350 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dfc5ec983345009de043e5faaf5f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7274506092071533     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48239412903785706    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.139980748295784     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7274506092071533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48239412903785706   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.139980748295784    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:31:57.387237078 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:57.388178318 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:57.420382150 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:31:57.420456011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b7c7d5abf24be196a9cc3d669e9a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7106031179428101     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48321276903152466    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14008072018623352    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7106031179428101    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48321276903152466   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14008072018623352   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.48321276903152466, 'test_mse': 0.14008072018623352, 'test_iou': 0.7106031179428101}]\n",
      "MSE value is 0.14008072018623352\n",
      "IoU value is 0.7106031179428101\n",
      "num_param value is 1740148\n",
      "Training time: 1070.7938077449799\n",
      "Fitness: 14.137191932343852\n",
      "********\n",
      "chromosome: ['Leo12k5s1p2arn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'LDd0.45n1', 'HS'], fitness: 14.137191932343852, IoU: 0.7106031179428101, FPS: 111.45573936787254, Model Size: 1740148\n",
      "\n",
      "Architecture: LDd0.24n1EPa2ELbo11k3s1p1arn1EPa2ELco04k5s1p2arn1EPa2ELme3arn1EUf2mnearestES2ELco09k5s1p2agn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELbo12k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 22535436 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.38n1EPM2ELdo05arn1EPM2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELdo05arn1EHSEE\n",
      "Chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 10601960 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo08agn1EUf2mnearestES0ELeo12k5s1p2arn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 20265056 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Leo12k5s1p2arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1050277\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:32:16.955758245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:32:16.957634344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:32:16.008425244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:32:16.008457976 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.201     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530f40072c9f4be996804c57bacc51aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:44:58.699712535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:44:58.709919593 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:44:58.720185125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:44:58.728332059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc594206b3ea4445a291e15cb563a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7790613174438477     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7790613174438477    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:45:15.889393866 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:15.920233092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:15.933078746 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:15.933896590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f3fd45a4c846498a52ecf1687e85d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7752878069877625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7752878069877625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7752878069877625, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 1050277\n",
      "Training time: 762.7624926567078\n",
      "Fitness: 12.722290658357373\n",
      "********\n",
      "chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 12.722290658357373, IoU: 0.6023015975952148, FPS: 140.17907765677208, Model Size: 1050277\n",
      "\n",
      "Architecture: Lme4agn1EPM2ELeo11k5s1p2agn1EPa2ELbo09k3s1p1arn1EPa2ELdo12agn1EUf2mnearestES0ELdo09agn1EUf2mnearestES0ELdo11agn1EUf2mnearestES0ELme4agn1EHSEE\n",
      "Chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'Lbo09k3s1p1arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S0', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 52372691 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme4agn1', 'PM2', 'Leo11k5s1p2agn1', 'Pa2', 'Lbo09k3s1p1arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S0', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'Uf2mnearest', 'S0', 'Lme4agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 137908799 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo08k3s1p1agn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELne4agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Leo08k3s1p1agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 139892\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:45:31.076368630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:31.103084307 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:31.106838647 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:45:31.113180209 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 139 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "139 K     Trainable params\n",
      "0         Non-trainable params\n",
      "139 K     Total params\n",
      "0.560     Total estimated model params size (MB)\n",
      "79        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cb78c7f9fd435abb225b5fe4a889a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:52:18.426014734 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:18.427699775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:18.427832913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:18.428128921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375231d7d7644789b68d6a4bbe084b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6198009848594666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3675602674484253     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0897107943892479     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6198009848594666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3675602674484253    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0897107943892479    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:52:28.241110030 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:28.266903524 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:28.266913808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:28.276255543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcc9b47bd404a3ea0c27900309384ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6141883730888367     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3698060214519501     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09117183834314346    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6141883730888367    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3698060214519501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09117183834314346   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3698060214519501, 'test_mse': 0.09117183834314346, 'test_iou': 0.6141883730888367}]\n",
      "MSE value is 0.09117183834314346\n",
      "IoU value is 0.6141883730888367\n",
      "num_param value is 139892\n",
      "Training time: 407.5966181755066\n",
      "Fitness: 15.1664511208816\n",
      "********\n",
      "chromosome: ['Leo08k3s1p1agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 15.1664511208816, IoU: 0.6141883730888367, FPS: 225.36715755695099, Model Size: 139892\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES0ELdo05agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 293888854 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EUf2mnearestES1ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50313\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:52:40.936916534 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:40.964689862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:40.966088089 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:52:40.968961814 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 50.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "50.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.3 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a79e71776284a79b0f1e868d5db9642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:55:41.759467405 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:41.761621430 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:41.764598692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:41.767131359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ec98bf95894498af0b30280e24c748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.720202624797821     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34606605768203735    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06583211570978165    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.720202624797821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34606605768203735   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06583211570978165   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:55:46.693262051 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:46.701857263 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:46.702034056 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:46.702847879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070ad8ea465244e6b01bc8b1df835c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7047112584114075     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3444395661354065     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06463847309350967    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7047112584114075    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3444395661354065    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06463847309350967   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3444395661354065, 'test_mse': 0.06463847309350967, 'test_iou': 0.7047112584114075}]\n",
      "MSE value is 0.06463847309350967\n",
      "IoU value is 0.7047112584114075\n",
      "num_param value is 50313\n",
      "Training time: 181.26061296463013\n",
      "Fitness: 16.389659463527504\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'HS'], fitness: 16.389659463527504, IoU: 0.7047112584114075, FPS: 360.6019742257915, Model Size: 50313\n",
      "\n",
      "For generation 3, the best fitness of the population is 17.174878780605944.\n",
      "The best historical fitness is 17.174878780605944,with the most fit individual having the following genes: ['LRr2arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_3.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 4 ***\n",
      "Architecture: LRr4arn1EPa2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:55:52.399270010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:52.410850864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:52.425050390 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:55:52.427093907 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93dc2413f2541e2bdfc07b99d04982b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:59:17.632237348 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:17.637287922 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:17.637466485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:17.643759599 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38788577f8f044a3b0f479f1cd777914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7269482016563416     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4406715929508209     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1152653768658638     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7269482016563416    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4406715929508209    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1152653768658638    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:59:24.833665329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:24.840788848 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:24.842557273 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:24.845610753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3207a71671403aa50821de8fefda60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7369174361228943     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4372846484184265     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1137050986289978     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7369174361228943    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4372846484184265    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1137050986289978    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4372846484184265, 'test_mse': 0.1137050986289978, 'test_iou': 0.7369174361228943}]\n",
      "MSE value is 0.1137050986289978\n",
      "IoU value is 0.7369174361228943\n",
      "num_param value is 107631\n",
      "Training time: 205.19545125961304\n",
      "Fitness: 16.240581000825166\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.240581000825166, IoU: 0.7369174361228943, FPS: 346.8151607105921, Model Size: 107631\n",
      "\n",
      "Architecture: Lne4agn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 52659\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 04:59:29.734186249 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:30.742518328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:30.745319340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 04:59:30.753820133 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 52.7 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "52.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.7 K    Total params\n",
      "0.211     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1dee06c125447d8641dd2dfa383087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:02:44.381482783 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:44.396601730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:44.400866022 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:44.410211267 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794bdece07204a9cbb3a2a8214596988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7826159000396729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30206894874572754    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04565756395459175    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7826159000396729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30206894874572754   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04565756395459175   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:02:50.276826394 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:50.290170639 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:50.292160809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:50.300209586 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baddb6ca94e4edfa9d4bb731adbc798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7750296592712402     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30309757590293884    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.046050991863012314    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7750296592712402    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30309757590293884   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.046050991863012314   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.30309757590293884, 'test_mse': 0.046050991863012314, 'test_iou': 0.7750296592712402}]\n",
      "MSE value is 0.046050991863012314\n",
      "IoU value is 0.7750296592712402\n",
      "num_param value is 52659\n",
      "Training time: 194.649067401886\n",
      "Fitness: 17.257401005574373\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 17.257401005574373, IoU: 0.7750296592712402, FPS: 351.5066002858445, Model Size: 52659\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:02:56.045255394 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:56.066990742 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:56.076161187 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:02:56.085477582 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc2452241934e099a6496dbde77172c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:06:48.538106798 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:48.549568287 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:48.550559150 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:48.557563638 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c3ebc3e7c34ccd847fdefbd07a10c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7383777499198914     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3335013687610626     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05724869668483734    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7383777499198914    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3335013687610626    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05724869668483734   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:06:55.824468200 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:55.830819302 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:55.833493142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:06:55.842693119 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f9ad500920471ab80214a7f4d1eb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.728198766708374     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3376884162425995     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05888352543115616    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.728198766708374    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3376884162425995    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05888352543115616   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3376884162425995, 'test_mse': 0.05888352543115616, 'test_iou': 0.728198766708374}]\n",
      "MSE value is 0.05888352543115616\n",
      "IoU value is 0.728198766708374\n",
      "num_param value is 30994\n",
      "Training time: 232.51665902137756\n",
      "Fitness: 16.694902992170462\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.694902992170462, IoU: 0.728198766708374, FPS: 345.57100749098987, Model Size: 30994\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELRr4agn1EUf2mnearestES1ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50363\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 05:07:00.704914717 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:07:00.716455679 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:07:00.718695965 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 05:07:00.724148611 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 50.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "50.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e964ad8843a9484aa2422b476cffa86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:23:24.146529996 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:23:24.148066066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:23:24.151053759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:23:24.155291958 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acf94a311e24b98b91d8a3afe8d3501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6610568165779114     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.514140248298645     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1509508192539215     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6610568165779114    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.514140248298645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1509508192539215    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:24:00.382263966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:00.383665832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:00.384990548 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:00.389356738 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c531a49a884c17addb8a80f91153f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6500735282897949     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.514945387840271     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15112626552581787    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6500735282897949    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.514945387840271    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15112626552581787   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.514945387840271, 'test_mse': 0.15112626552581787, 'test_iou': 0.6500735282897949}]\n",
      "MSE value is 0.15112626552581787\n",
      "IoU value is 0.6500735282897949\n",
      "num_param value is 1628750\n",
      "Training time: 2290.612045764923\n",
      "Fitness: 13.55912960362296\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'HS'], fitness: 13.55912960362296, IoU: 0.6500735282897949, FPS: 63.52515537639482, Model Size: 1628750\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1050277\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:24:32.977717192 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:32.981090698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:32.983007369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:24:32.985303007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.201     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdd018a59fe4c429642b4171dc53f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:37:13.563602137 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:13.571066324 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:13.574067546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:13.580270510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866984514ab3422486b30db2f8c4f3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7790613174438477     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7790613174438477    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:37:30.782345956 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:30.784321945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:30.785732621 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:30.786877070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28886b012c504921bdfedc2ef1bac808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7752878069877625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7752878069877625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7752878069877625, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 1050277\n",
      "Training time: 761.5999975204468\n",
      "Fitness: 12.722290658357373\n",
      "********\n",
      "chromosome: ['Lco09k5s1p2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 12.722290658357373, IoU: 0.6023015975952148, FPS: 139.38509243246975, Model Size: 1050277\n",
      "\n",
      "Architecture: Lne3arn1EPa2ELdo05arn1EUf2mnearestES1ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lne3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2822264\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 06:37:44.273387591 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:44.284651483 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:44.286623179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 06:37:44.296135606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.289    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbf8a5ae4724267817d5387fc74f312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:17:16.959488590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:16.960178793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:16.962958956 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:16.972880216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d12aaae3764cadad0355eab8cc24ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5796506404876709     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4634242057800293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1265307068824768     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5796506404876709    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4634242057800293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1265307068824768    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:17:58.127972916 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:58.129671122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:58.130152737 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:17:58.138894484 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3172a617c74419859a1fbc916ac7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5768485069274902     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46601608395576477    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12791958451271057    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5768485069274902    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46601608395576477   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12791958451271057   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.46601608395576477, 'test_mse': 0.12791958451271057, 'test_iou': 0.5768485069274902}]\n",
      "MSE value is 0.12791958451271057\n",
      "IoU value is 0.5768485069274902\n",
      "num_param value is 2822264\n",
      "Training time: 2371.642525434494\n",
      "Fitness: 11.812101347717137\n",
      "********\n",
      "chromosome: ['Lne3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS'], fitness: 11.812101347717137, IoU: 0.5768485069274902, FPS: 54.770301236957145, Model Size: 2822264\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELRr2agn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 40032\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:18:34.705217369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:18:34.706985204 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:18:34.710704273 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:18:34.713399795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 40.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "40.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.0 K    Total params\n",
      "0.160     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c410c23bfc4c8ba6842b2e23f41c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:20:38.006158917 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:38.008124052 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:38.010360387 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:38.020288116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a86424437424c74a0fb5e805719a8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5759299397468567     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34681934118270874    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1488327980041504     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5759299397468567    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34681934118270874   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1488327980041504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:20:45.838492069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:45.840887909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:45.842917805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:45.850570764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8833da75edd4fe39d5090a8bc752131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5690208077430725     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3515613377094269     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13364841043949127    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5690208077430725    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3515613377094269    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13364841043949127   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3515613377094269, 'test_mse': 0.13364841043949127, 'test_iou': 0.5690208077430725}]\n",
      "MSE value is 0.13364841043949127\n",
      "IoU value is 0.5690208077430725\n",
      "num_param value is 40032\n",
      "Training time: 123.32256484031677\n",
      "Fitness: 14.471253148515942\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 14.471253148515942, IoU: 0.5690208077430725, FPS: 311.26060200962263, Model Size: 40032\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPa2ELdo06arn1EPM2ELco05k5s1p2arn1EUf2mnearestES2ELdo07arn1EUf2mnearestES1ELDd0.30n1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'LDd0.30n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 10911978 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'LDd0.30n1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.24n1EPa2ELbo11k3s1p1arn1EPa2ELco04k5s1p2arn1EPa2ELme3arn1EUf2mnearestES2ELco09k5s1p2agn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELbo12k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 22535436 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.24n1', 'Pa2', 'Lbo11k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S2', 'Lco09k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo12k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.38n1EPM2ELdo05arn1EPM2ELDd0.35n1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELdo05arn1EHSEE\n",
      "Chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 10600034 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.38n1', 'PM2', 'Ldo05arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Ldo05arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELne5arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 249177355 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 61397\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:20:54.058817669 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:54.069067867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:54.070430984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:20:54.077522616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 61.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "61.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.4 K    Total params\n",
      "0.246     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0d9ff7c06b4b1bbcd66dd74e96d919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:25:04.090858362 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:04.091712625 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:04.091746564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:04.093546837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be322161973c45699baa3a041825b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6232379078865051     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33715683221817017    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07824155688285828    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6232379078865051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33715683221817017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07824155688285828   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:25:12.118455974 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:12.125492187 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:12.127835365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:12.131576098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1712a2b6bcd9485283e9a29f1e4c3742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6172446012496948     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3350590467453003     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07741723954677582    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6172446012496948    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3350590467453003    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07741723954677582   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3350590467453003, 'test_mse': 0.07741723954677582, 'test_iou': 0.6172446012496948}]\n",
      "MSE value is 0.07741723954677582\n",
      "IoU value is 0.6172446012496948\n",
      "num_param value is 61397\n",
      "Training time: 250.35087752342224\n",
      "Fitness: 15.392504360479482\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 15.392504360479482, IoU: 0.6172446012496948, FPS: 271.51151200786563, Model Size: 61397\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 16115246 exceed the threshold of 10000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 654728\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:25:20.757706821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:20.766804843 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:20.768886108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:25:20.777322263 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 654 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "654 K     Trainable params\n",
      "0         Non-trainable params\n",
      "654 K     Total params\n",
      "2.619     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cf63da33bd4d2aa04ae061ba8f3126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:37:08.367067997 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:08.368741274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:08.371868927 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:08.377925860 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb432543ba74a9faa2dbeaba0d17e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6148539781570435     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45248329639434814    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12232648581266403    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6148539781570435    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45248329639434814   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12232648581266403   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:37:22.103041032 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:22.103964041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:22.106999178 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:22.116644552 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9714560aa545ccb5cfabff34ef7a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5947843790054321     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45946386456489563    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12594227492809296    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5947843790054321    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45946386456489563   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12594227492809296   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.45946386456489563, 'test_mse': 0.12594227492809296, 'test_iou': 0.5947843790054321}]\n",
      "MSE value is 0.12594227492809296\n",
      "IoU value is 0.5947843790054321\n",
      "num_param value is 654728\n",
      "Training time: 708.614333152771\n",
      "Fitness: 14.174565774369581\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 14.174565774369581, IoU: 0.5947843790054321, FPS: 163.4930530525934, Model Size: 654728\n",
      "\n",
      "For generation 4, the best fitness of the population is 17.257401005574373.\n",
      "The best historical fitness is 17.257401005574373,with the most fit individual having the following genes: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_4.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 5 ***\n",
      "Architecture: LRr2arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:37:34.565421619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:34.565488186 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:34.570433904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:37:34.577137276 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87550d15c37479dbf0a8eb616ab93dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:40:15.153827149 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:15.153894711 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:15.154040529 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:15.157523338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b717484c93124a5a8783474b2381969c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7970709204673767     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2983907461166382     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04118519276380539    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7970709204673767    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2983907461166382    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04118519276380539   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:40:21.849045849 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:21.852683537 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:21.853633160 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:21.862256280 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acf8400609f4b7eb63408e494eb862e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7925160527229309     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2889121472835541     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03657198324799538    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7925160527229309    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2889121472835541    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03657198324799538   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.2889121472835541, 'test_mse': 0.03657198324799538, 'test_iou': 0.7925160527229309}]\n",
      "MSE value is 0.03657198324799538\n",
      "IoU value is 0.7925160527229309\n",
      "num_param value is 51876\n",
      "Training time: 160.6432762145996\n",
      "Fitness: 17.520467898581863\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 17.520467898581863, IoU: 0.7925160527229309, FPS: 376.9168718149115, Model Size: 51876\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 31777\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:40:26.313432934 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:26.320243850 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:26.322989858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:40:26.328655432 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.8 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.8 K    Total params\n",
      "0.127     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d521e6efd97443e0b060a508c7e16b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:44:11.252443533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:11.255988375 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:11.258983001 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:11.268430486 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f3689092c244dd827f0ce5763745ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7145989537239075     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3191264271736145     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05002530291676521    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7145989537239075    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3191264271736145    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05002530291676521   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:44:18.766198466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:18.771437699 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:18.773051832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:18.780521375 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0ca2d0be234026abfe7e6ede68fc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7116926908493042     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31812843680381775    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.049604468047618866    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7116926908493042    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31812843680381775   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.049604468047618866   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.31812843680381775, 'test_mse': 0.049604468047618866, 'test_iou': 0.7116926908493042}]\n",
      "MSE value is 0.049604468047618866\n",
      "IoU value is 0.7116926908493042\n",
      "num_param value is 31777\n",
      "Training time: 224.99170756340027\n",
      "Fitness: 16.612548375651922\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.612548375651922, IoU: 0.7116926908493042, FPS: 326.45975464832856, Model Size: 31777\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELdo12arn1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 89976\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:44:24.999927512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:24.008354226 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:24.011559625 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:44:24.013580790 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 90.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "90.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.0 K    Total params\n",
      "0.360     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5877df3fcf5e43b299941f149fa8c6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:48:15.688145328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:15.690188217 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:15.691715504 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:15.699881203 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e74220e0845039f2025390b3ffa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6575944423675537     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3953758180141449     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07956328243017197    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6575944423675537    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3953758180141449    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07956328243017197   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:48:22.389060772 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:22.393245276 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:22.393330585 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:22.395097380 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54199b19635c4311b1af3ffc45c65682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6529542207717896     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.387759804725647     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07542407512664795    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6529542207717896    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.387759804725647    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07542407512664795   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.387759804725647, 'test_mse': 0.07542407512664795, 'test_iou': 0.6529542207717896}]\n",
      "MSE value is 0.07542407512664795\n",
      "IoU value is 0.6529542207717896\n",
      "num_param value is 89976\n",
      "Training time: 231.70030546188354\n",
      "Fitness: 15.738223575809961\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 15.738223575809961, IoU: 0.6529542207717896, FPS: 322.0748533250801, Model Size: 89976\n",
      "\n",
      "Architecture: LRr4arn1EPa2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES0ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:48:28.719910912 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:28.721851088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:28.722929783 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:48:28.724243095 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c79fbbd93994f5b82ac7d74eed10347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:51:31.581400101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:31.581430424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:31.583425535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:31.593387476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7681f91c2191464e8a1660f86a2f42b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7416056990623474     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4309097230434418     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1102747842669487     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7416056990623474    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4309097230434418    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1102747842669487    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:51:38.978995451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:38.980068073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:38.980081473 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:38.980455833 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebca3dbae36b4792a9e64c5351af6a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7349501252174377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.431960791349411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11123421788215637    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7349501252174377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.431960791349411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11123421788215637   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.431960791349411, 'test_mse': 0.11123421788215637, 'test_iou': 0.7349501252174377}]\n",
      "MSE value is 0.11123421788215637\n",
      "IoU value is 0.7349501252174377\n",
      "num_param value is 107631\n",
      "Training time: 182.87626957893372\n",
      "Fitness: 16.24087319779864\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.24087319779864, IoU: 0.7349501252174377, FPS: 340.3497728995322, Model Size: 107631\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELRr4agn1EUf2mnearestES1ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50363\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:51:44.928030534 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:44.933152638 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:44.933772288 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:51:44.938876206 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 50.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "50.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773415d75a644ed4b059f0215c9cf47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:54:27.422837477 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:27.423883380 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:27.423922803 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:27.424684398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48fc203d1414d0095c1529b535537da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6971451044082642     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.384303480386734     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08003822714090347    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6971451044082642    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.384303480386734    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08003822714090347   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:54:33.403820872 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:33.410320420 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:33.417959656 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:33.422763168 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0d665cd4684b86b3863f0c47e859af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.687761664390564     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38413098454475403    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08028285205364227    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.687761664390564    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38413098454475403   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08028285205364227   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.38413098454475403, 'test_mse': 0.08028285205364227, 'test_iou': 0.687761664390564}]\n",
      "MSE value is 0.08028285205364227\n",
      "IoU value is 0.687761664390564\n",
      "num_param value is 50363\n",
      "Training time: 163.48130679130554\n",
      "Fitness: 16.08408853764645\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'HS'], fitness: 16.08408853764645, IoU: 0.687761664390564, FPS: 354.59259448068525, Model Size: 50363\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 61397\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:54:39.147583966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:39.157399367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:39.159219008 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:54:39.163202350 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 61.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "61.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.4 K    Total params\n",
      "0.246     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd4b0234c454f509d3b4184dac59823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:58:49.245175315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:49.247595059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:49.247822315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:49.257811857 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fc1dcaba764e98ab71807ada1681af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5924699902534485     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32694828510284424    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0832478478550911     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5924699902534485    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32694828510284424   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0832478478550911    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:58:57.399197504 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:57.401801435 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:57.405783023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:58:57.409942349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a8daa4c384498948fd7419f9a61c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5880663990974426     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32279855012893677    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0843706876039505     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5880663990974426    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32279855012893677   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0843706876039505    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32279855012893677, 'test_mse': 0.0843706876039505, 'test_iou': 0.5880663990974426}]\n",
      "MSE value is 0.0843706876039505\n",
      "IoU value is 0.5880663990974426\n",
      "num_param value is 61397\n",
      "Training time: 250.09665393829346\n",
      "Fitness: 15.041205682526687\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 15.041205682526687, IoU: 0.5880663990974426, FPS: 270.445868369918, Model Size: 61397\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELDd0.45n1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 07:59:05.903904141 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:59:05.905189535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:59:05.906549152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 07:59:05.907755911 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb214c108ac34c358f2df54e4c605855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:00:42.005685659 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:42.012098558 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:42.013892701 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:42.015399354 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af84a280598f48ac91b7ffe3e5538eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5978491902351379     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34445011615753174    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06479117274284363    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5978491902351379    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34445011615753174   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06479117274284363   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:00:47.108063394 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:47.113987442 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:47.114764915 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:47.118062759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31080dd3f124d56874a7cc77e64c834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5879323482513428     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34959644079208374    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06724505871534348    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5879323482513428    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34959644079208374   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06724505871534348   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34959644079208374, 'test_mse': 0.06724505871534348, 'test_iou': 0.5879323482513428}]\n",
      "MSE value is 0.06724505871534348\n",
      "IoU value is 0.5879323482513428\n",
      "num_param value is 1516\n",
      "Training time: 97.10861420631409\n",
      "Fitness: 15.247726713657142\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS'], fitness: 15.247726713657142, IoU: 0.5879323482513428, FPS: 418.01225163510276, Model Size: 1516\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELne3arn1EUf2mnearestES0ELme3arn1EUf2mnearestES0ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1249014\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:00:52.002960662 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:52.009749685 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:52.018047831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:00:52.028078279 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.2 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.996     Total estimated model params size (MB)\n",
      "62        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff530cab77464ad38b4608f35a008d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:19:41.108038453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:19:41.112863203 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:19:41.114537541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:19:41.119644697 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7a6c447b9b477e8ee87354feca8692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7031782269477844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3165537118911743     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054338306188583374    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7031782269477844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3165537118911743    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054338306188583374   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:20:01.757228639 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:01.759823491 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:01.759832123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:01.762887193 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672891a0beb84facbdc81991eb4c2be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6930752992630005     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32157304883003235    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.056726668030023575    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6930752992630005    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32157304883003235   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.056726668030023575   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32157304883003235, 'test_mse': 0.056726668030023575, 'test_iou': 0.6930752992630005}]\n",
      "MSE value is 0.056726668030023575\n",
      "IoU value is 0.6930752992630005\n",
      "num_param value is 1249014\n",
      "Training time: 1129.108922958374\n",
      "Fitness: 15.144924036159049\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo07k3s1p1arn1', 'HS'], fitness: 15.144924036159049, IoU: 0.6930752992630005, FPS: 116.18116693806188, Model Size: 1249014\n",
      "\n",
      "Architecture: Leo08k3s1p1agn1EPM2ELRr4agn1EUf2mnearestES1ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Leo08k3s1p1agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1590516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:20:18.066189854 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:18.073776909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:18.074711577 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:20:18.080689038 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24072a4551b34c0e8f17e9df96300842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:34:48.369165326 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:34:48.369976530 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:34:48.370623581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:34:48.376441905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85ecdf2193b415d83abd3f9b7662e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6633139252662659     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44855520129203796    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.119987353682518     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6633139252662659    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44855520129203796   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.119987353682518    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:35:14.066601818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:14.067325566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:14.067330098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:14.067939046 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc7fcfe80594cf1a2d36cc2596de6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6570349931716919     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.44163239002227783    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1160927563905716     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6570349931716919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.44163239002227783   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1160927563905716    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.44163239002227783, 'test_mse': 0.1160927563905716, 'test_iou': 0.6570349931716919}]\n",
      "MSE value is 0.1160927563905716\n",
      "IoU value is 0.6570349931716919\n",
      "num_param value is 1590516\n",
      "Training time: 870.2946019172668\n",
      "Fitness: 13.939662711844353\n",
      "********\n",
      "chromosome: ['Leo08k3s1p1agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS'], fitness: 13.939662711844353, IoU: 0.6570349931716919, FPS: 88.97164023452277, Model Size: 1590516\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES0ELne4agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 173639\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:35:36.649537923 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:36.666863189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:36.670373441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:35:36.676854615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 173 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "173 K     Trainable params\n",
      "0         Non-trainable params\n",
      "173 K     Total params\n",
      "0.695     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def4aa70fbdf4994954f917f5d8e718c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:41:19.621330977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:19.622396410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:19.623626458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:19.628796284 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3b09fc5418480a999af0d06a561ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5659072399139404     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4006694555282593     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11624719202518463    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5659072399139404    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4006694555282593    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11624719202518463   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:41:30.010766313 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:30.017809227 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:30.018249340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:30.025162547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10634d1beef947368b7cca2d18430203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5793588757514954     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39754265546798706    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11418075114488602    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5793588757514954    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39754265546798706   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11418075114488602   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.39754265546798706, 'test_mse': 0.11418075114488602, 'test_iou': 0.5793588757514954}]\n",
      "MSE value is 0.11418075114488602\n",
      "IoU value is 0.5793588757514954\n",
      "num_param value is 173639\n",
      "Training time: 342.973445892334\n",
      "Fitness: 14.59515417540174\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 14.59515417540174, IoU: 0.5793588757514954, FPS: 214.89755665507658, Model Size: 173639\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELRr2agn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 40032\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:41:39.424357848 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:39.430823207 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:39.432820655 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:41:39.435255555 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 40.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "40.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.0 K    Total params\n",
      "0.160     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b426b35abb34639877bff07d416c949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:45:22.470230118 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:22.484042809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:22.484261365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:22.488614009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996325afeb64e84960b21b3ad30ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5413240194320679     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3440200090408325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11756329983472824    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5413240194320679    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3440200090408325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11756329983472824   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:45:29.356708936 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:29.357114910 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:29.357354930 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:29.364802141 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb8805a25bb4eca9a85d29afb74197f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5342444181442261     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3541471064090729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11437094211578369    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5342444181442261    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3541471064090729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11437094211578369   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3541471064090729, 'test_mse': 0.11437094211578369, 'test_iou': 0.5342444181442261}]\n",
      "MSE value is 0.11437094211578369\n",
      "IoU value is 0.5342444181442261\n",
      "num_param value is 40032\n",
      "Training time: 223.04507899284363\n",
      "Fitness: 14.276084790864084\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 14.276084790864084, IoU: 0.5342444181442261, FPS: 313.94730708273374, Model Size: 40032\n",
      "\n",
      "Architecture: Ldo05agn1EPa2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 654728\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:45:36.834239246 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:36.835828247 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:36.836199795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:45:36.837766145 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 654 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "654 K     Trainable params\n",
      "0         Non-trainable params\n",
      "654 K     Total params\n",
      "2.619     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e2be37ba534edca36eac57a3ad2735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:57:25.306893251 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:25.306895291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:25.309037598 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:25.310430436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1786c4d9514f9285052022310fd4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6029959917068481     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4928983449935913     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14354707300662994    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6029959917068481    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4928983449935913    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14354707300662994   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:57:39.126425147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:39.127657234 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:39.129305908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:39.131166025 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8016eb86734ed3a592d0f37a0f8bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5804343819618225     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5022809505462646     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14814512431621552    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5804343819618225    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5022809505462646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14814512431621552   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5022809505462646, 'test_mse': 0.14814512431621552, 'test_iou': 0.5804343819618225}]\n",
      "MSE value is 0.14814512431621552\n",
      "IoU value is 0.5804343819618225\n",
      "num_param value is 654728\n",
      "Training time: 709.4724390506744\n",
      "Fitness: 13.859316177363121\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 13.859316177363121, IoU: 0.5804343819618225, FPS: 163.34484816767548, Model Size: 654728\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPM2ELco04k5s1p2agn1EUf2mnearestES2ELne5arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1636366\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 08:57:51.490484942 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:51.501071550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:51.501255259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 08:57:51.510408640 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.545     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4082f7b535342f3920389e53a90126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:31:51.352478867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:31:51.363168345 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:31:51.365160397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:31:51.366037376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d967249fa2ef436caa114ac19eb56bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7070552110671997     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3288348317146301     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05850191041827202    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7070552110671997    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3288348317146301    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05850191041827202   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:32:28.805206339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:28.805322041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:28.805588415 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:28.809407966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587cf97bd3574f35b4117481829514bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7100765109062195     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3216339647769928     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054768629372119904    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7100765109062195    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3216339647769928    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054768629372119904   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3216339647769928, 'test_mse': 0.054768629372119904, 'test_iou': 0.7100765109062195}]\n",
      "MSE value is 0.054768629372119904\n",
      "IoU value is 0.7100765109062195\n",
      "num_param value is 1636366\n",
      "Training time: 2039.858470916748\n",
      "Fitness: 14.945151305828583\n",
      "********\n",
      "chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'HS'], fitness: 14.945151305828583, IoU: 0.7100765109062195, FPS: 63.19177758889918, Model Size: 1636366\n",
      "\n",
      "Architecture: Ldo08agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1042661\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:32:59.552886535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:59.554011843 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:59.559203513 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:32:59.566796876 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.0 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.171     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe99abf37c8464580eefee064ef66cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:48:38.312179543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:38.319772267 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:38.321341260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:38.323026144 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18751b9080b4a3aa8117c578a0e48fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7538562417030334     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3324737250804901     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.058449361473321915    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7538562417030334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3324737250804901    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.058449361473321915   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:48:54.461290300 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:54.461909997 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:54.462908080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:48:54.463000723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde5911daa48475ea3cfa34ee46a4a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7509278059005737     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32819584012031555    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05589507520198822    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7509278059005737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32819584012031555   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05589507520198822   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32819584012031555, 'test_mse': 0.05589507520198822, 'test_iou': 0.7509278059005737}]\n",
      "MSE value is 0.05589507520198822\n",
      "IoU value is 0.7509278059005737\n",
      "num_param value is 1042661\n",
      "Training time: 938.7605922222137\n",
      "Fitness: 15.937255037014149\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 15.937255037014149, IoU: 0.7509278059005737, FPS: 139.93316256986475, Model Size: 1042661\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELdo05arn1EUf2mnearestES1ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2821634\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 09:49:09.877723957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:49:09.879221183 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:49:09.882922551 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 09:49:09.890431041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.287    Total estimated model params size (MB)\n",
      "22        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271b246a8d0c4deeac117ccfda83a22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:19:42.408401171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:19:42.433862407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:19:42.434827874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:19:42.440947355 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bd1a3e1d98476ba46f14b04a522b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6647738814353943     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.371776282787323     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07788508385419846    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6647738814353943    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.371776282787323    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07788508385419846   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:20:24.166935125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:20:24.168055427 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:20:24.170270612 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:20:24.172331188 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade30b4d5b43440fa5d9dd77a527757b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6422803401947021     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.383384108543396     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0838681161403656     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6422803401947021    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.383384108543396    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0838681161403656    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.383384108543396, 'test_mse': 0.0838681161403656, 'test_iou': 0.6422803401947021}]\n",
      "MSE value is 0.0838681161403656\n",
      "IoU value is 0.6422803401947021\n",
      "num_param value is 2821634\n",
      "Training time: 1833.522948026657\n",
      "Fitness: 12.827384151772687\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS'], fitness: 12.827384151772687, IoU: 0.6422803401947021, FPS: 55.29115210256095, Model Size: 2821634\n",
      "\n",
      "Architecture: Lco06k5s1p2arn1EPa2ELdo06arn1EPM2ELco05k5s1p2arn1EUf2mnearestES2ELdo07arn1EUf2mnearestES1ELDd0.30n1EHSEE\n",
      "Chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'LDd0.30n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 10911978 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco06k5s1p2arn1', 'Pa2', 'Ldo06arn1', 'PM2', 'Lco05k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'LDd0.30n1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo12agn1EUf2mnearestES2ELdo09agn1EUf2mnearestES0ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 530145567 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3456\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:21:05.954626240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:21:05.961440490 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:21:05.964164179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:21:05.966193342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 3.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "82        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc52078e6718433ab07585bd6a07a164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:23:40.197079458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:40.205065490 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:40.209874059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:40.213412803 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0afb04575c46a691c942ff99bcdb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4425473213195801     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4949236214160919     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19129081070423126    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4425473213195801    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4949236214160919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19129081070423126   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:23:46.181760767 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:46.181794903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:46.182618615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:46.184268324 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d66c70002434fcb92c302148a226d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43744972348213196    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.49226114153862      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19031967222690582    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43744972348213196   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.49226114153862     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19031967222690582   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.49226114153862, 'test_mse': 0.19031967222690582, 'test_iou': 0.43744972348213196}]\n",
      "MSE value is 0.19031967222690582\n",
      "IoU value is 0.43744972348213196\n",
      "num_param value is 3456\n",
      "Training time: 155.55417108535767\n",
      "Fitness: 12.772145772807768\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 12.772145772807768, IoU: 0.43744972348213196, FPS: 366.4707099156388, Model Size: 3456\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELRr3arn1EPa2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELeo12k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo12k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 22404880 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo12k3s1p1agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 654728\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:23:52.964789255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:52.966990906 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:52.970303693 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:23:52.974110954 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 654 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "654 K     Trainable params\n",
      "0         Non-trainable params\n",
      "654 K     Total params\n",
      "2.619     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b3b06f74a544b3a93d92001b5b6035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:35:40.145287993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:40.157881116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:40.164915566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:40.167513435 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977378fba9da4c3fa64fa8221914d973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5922724008560181     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4941648244857788     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14460968971252441    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5922724008560181    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4941648244857788    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14460968971252441   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:35:54.069598469 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:54.075192236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:54.078047260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:35:54.080123155 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ebec6a4a594f2e8ff2dd359c6aed8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5736132264137268     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5021907091140747     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14852243661880493    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5736132264137268    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5021907091140747    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14852243661880493   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5021907091140747, 'test_mse': 0.14852243661880493, 'test_iou': 0.5736132264137268}]\n",
      "MSE value is 0.14852243661880493\n",
      "IoU value is 0.5736132264137268\n",
      "num_param value is 654728\n",
      "Training time: 708.1918339729309\n",
      "Fitness: 13.788243313306841\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 13.788243313306841, IoU: 0.5736132264137268, FPS: 162.17381921299935, Model Size: 654728\n",
      "\n",
      "For generation 5, the best fitness of the population is 17.520467898581863.\n",
      "The best historical fitness is 17.520467898581863,with the most fit individual having the following genes: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_5.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 6 ***\n",
      "Architecture: Lne4agn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 52659\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:36:06.554858320 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:36:06.555165432 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:36:06.558102834 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:36:06.567827637 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 52.7 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "52.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.7 K    Total params\n",
      "0.211     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa96bb571e246cabf5d4c911459586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:39:02.960193377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:02.969493791 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:02.972236033 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:02.973901966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4422098880485d89a96eedc2a90644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7484312057495117     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3091509938240051     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04488158971071243    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7484312057495117    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3091509938240051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04488158971071243   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:39:08.876020012 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:08.884951658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:08.886089803 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:08.894839656 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de6d30f1eed4ce49a5325d7957cd18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7485240697860718     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30422285199165344    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.041775595396757126    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7485240697860718    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30422285199165344   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.041775595396757126   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.30422285199165344, 'test_mse': 0.041775595396757126, 'test_iou': 0.7485240697860718}]\n",
      "MSE value is 0.041775595396757126\n",
      "IoU value is 0.7485240697860718\n",
      "num_param value is 52659\n",
      "Training time: 175.39877605438232\n",
      "Fitness: 17.031577915651297\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 17.031577915651297, IoU: 0.7485240697860718, FPS: 358.3715406975341, Model Size: 52659\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:39:13.570250291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:13.578319245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:13.583216262 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:39:13.590209338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe13ef0ee14407ab83ff79bfd506060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:43:06.178913337 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:06.193937921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:06.195348781 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:06.199699936 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdba867317443c8b49a62a257d67beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7020304203033447     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3352833390235901     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05882171913981438    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7020304203033447    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3352833390235901    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05882171913981438   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:43:12.638231011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:12.642494060 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:12.643540069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:12.650959111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0d904aaa61406b8f60cf95a2bf82de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7000817060470581     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3327345848083496     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.057026445865631104    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7000817060470581    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3327345848083496    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.057026445865631104   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3327345848083496, 'test_mse': 0.057026445865631104, 'test_iou': 0.7000817060470581}]\n",
      "MSE value is 0.057026445865631104\n",
      "IoU value is 0.7000817060470581\n",
      "num_param value is 30994\n",
      "Training time: 232.60867500305176\n",
      "Fitness: 16.43032429874442\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.43032429874442, IoU: 0.7000817060470581, FPS: 334.15563600787846, Model Size: 30994\n",
      "\n",
      "Architecture: LRr4arn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:43:18.735258786 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:19.741611897 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:19.746253190 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:43:19.752831362 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccceef05608444d9962db68b07bc450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:46:44.910174764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:44.911549156 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:44.913785910 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:44.919424479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736c3ad022ac4f65a5a7afe9cc8f4e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7531208992004395     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40939849615097046    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09564227610826492    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7531208992004395    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40939849615097046   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09564227610826492   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:46:50.502687567 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:50.511625965 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:50.515314898 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:50.515878851 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e812e156ca54d7889bd42b35fd26eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7538775205612183     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40815848112106323    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09570921212434769    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7538775205612183    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40815848112106323   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09570921212434769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.40815848112106323, 'test_mse': 0.09570921212434769, 'test_iou': 0.7538775205612183}]\n",
      "MSE value is 0.09570921212434769\n",
      "IoU value is 0.7538775205612183\n",
      "num_param value is 107631\n",
      "Training time: 205.1680154800415\n",
      "Fitness: 16.55765321853918\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.55765321853918, IoU: 0.7538775205612183, FPS: 325.04697979503607, Model Size: 107631\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELRr4agn1EUf2mnearestES0ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50363\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:46:57.747456621 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:57.755888864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:57.757033179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:46:57.760631240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 50.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "50.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf70485c8bfb46e187ea4de20f5085dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:50:00.372290176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:00.373129952 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:00.373156752 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:00.379055400 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dee99e1a49479e97d89a19b0e424bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6986372470855713     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.369151771068573     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07764406502246857    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6986372470855713    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.369151771068573    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07764406502246857   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:50:06.539620019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:06.542325993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:06.543683047 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:06.544774868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644d701ac8a4bc1b7b4c09dcfedcd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6767221093177795     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3648349344730377     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07488551735877991    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6767221093177795    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3648349344730377    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07488551735877991   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3648349344730377, 'test_mse': 0.07488551735877991, 'test_iou': 0.6767221093177795}]\n",
      "MSE value is 0.07488551735877991\n",
      "IoU value is 0.6767221093177795\n",
      "num_param value is 50363\n",
      "Training time: 183.6172320842743\n",
      "Fitness: 16.020174435714537\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS'], fitness: 16.020174435714537, IoU: 0.6767221093177795, FPS: 347.0587434612116, Model Size: 50363\n",
      "\n",
      "Architecture: Ldo08agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1042661\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 10:50:12.400483260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:12.401442311 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:12.402945680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 10:50:12.403213534 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.0 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.171     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93770326b633467a93f633ef6ee15621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:05:51.795016742 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:05:51.805074137 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:05:51.806988630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:05:51.812970487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84ba7a9f4d448dfb12dc351a7f1c6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.748020589351654     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3618517816066742     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06960397958755493    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.748020589351654    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3618517816066742    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06960397958755493   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:06:07.020881440 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:07.033414231 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:07.035282821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:07.038582040 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad379a2e4bbb41d1a269f49092cb9222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7542955279350281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35088562965393066    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06423495709896088    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7542955279350281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35088562965393066   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06423495709896088   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.35088562965393066, 'test_mse': 0.06423495709896088, 'test_iou': 0.7542955279350281}]\n",
      "MSE value is 0.06423495709896088\n",
      "IoU value is 0.7542955279350281\n",
      "num_param value is 1042661\n",
      "Training time: 938.4005439281464\n",
      "Fitness: 15.896715561413204\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 15.896715561413204, IoU: 0.7542955279350281, FPS: 139.50460661945286, Model Size: 1042661\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELdo12arn1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 89976\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:06:21.456223374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:21.458786376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:21.461803399 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:06:21.467354969 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 90.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "90.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.0 K    Total params\n",
      "0.360     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3cde3c3d2e4bbdb43f34fc22e56afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:10:13.214435507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:13.225894501 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:13.227948601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:13.236141408 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f530c718a34b829795ee6cbdab7264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.666146457195282     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3895379304885864     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07697717845439911    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.666146457195282    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3895379304885864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07697717845439911   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:10:20.150768039 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:20.152706999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:20.156149730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:20.159722328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cd188388964a278714e3cb0b4e08d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6620383262634277     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38170355558395386    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07280836999416351    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6620383262634277    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38170355558395386   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07280836999416351   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.38170355558395386, 'test_mse': 0.07280836999416351, 'test_iou': 0.6620383262634277}]\n",
      "MSE value is 0.07280836999416351\n",
      "IoU value is 0.6620383262634277\n",
      "num_param value is 89976\n",
      "Training time: 231.75634336471558\n",
      "Fitness: 15.851736476400948\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 15.851736476400948, IoU: 0.6620383262634277, FPS: 311.1323182703365, Model Size: 89976\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELDd0.45n1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:10:26.644528659 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:26.649950552 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:26.650360792 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:10:26.653107310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400902f19503472188bd7ce0bdbb349d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:12:04.511129744 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:04.512096215 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:04.514158082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:04.518933315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d40eaf03f24e5798e270f6d64da2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5890234708786011     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34160301089286804    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06463770568370819    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5890234708786011    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34160301089286804   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06463770568370819   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:12:09.740694171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:09.742776101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:09.742781370 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:09.743412098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eec9f8952cc429ba9f56dc4d649a933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5919826030731201     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3435560464859009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06509295850992203    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5919826030731201    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3435560464859009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06509295850992203   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3435560464859009, 'test_mse': 0.06509295850992203, 'test_iou': 0.5919826030731201}]\n",
      "MSE value is 0.06509295850992203\n",
      "IoU value is 0.5919826030731201\n",
      "num_param value is 1516\n",
      "Training time: 97.84126091003418\n",
      "Fitness: 15.307161886432246\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS'], fitness: 15.307161886432246, IoU: 0.5919826030731201, FPS: 395.490304070775, Model Size: 1516\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELco05k5s1p2agn1EUf2mnearestES0ELme3arn1EUf2mnearestES0ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 30938996 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo07k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELne3arn1EUf2mnearestES2ELne5arn1EUf2mnearestES0ELdo07arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1584566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:12:15.190523180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:15.199523142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:15.199533490 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:12:15.201148895 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.338     Total estimated model params size (MB)\n",
      "64        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8afbe2214043b18b0ba8c5ba7d8ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:39:28.685875759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:28.698364248 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:28.699070728 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:28.707927228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a34d326c2c44fffbe55e1f1e409f12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5687130093574524     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3274814486503601     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09480571001768112    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5687130093574524    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3274814486503601    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09480571001768112   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:39:54.239552852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:54.240589845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:54.242041571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:39:54.247664865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466104cd4e334190b39fda7bcf68b72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5703257918357849     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3360534608364105     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09966210275888443    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5703257918357849    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3360534608364105    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09966210275888443   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3360534608364105, 'test_mse': 0.09966210275888443, 'test_iou': 0.5703257918357849}]\n",
      "MSE value is 0.09966210275888443\n",
      "IoU value is 0.5703257918357849\n",
      "num_param value is 1584566\n",
      "Training time: 1633.4974422454834\n",
      "Fitness: 13.212394406523552\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS'], fitness: 13.212394406523552, IoU: 0.5703257918357849, FPS: 89.16736683699928, Model Size: 1584566\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPM2ELco04k5s1p2agn1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1050277\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:40:17.776890370 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:40:17.777330906 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:40:17.782064002 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:40:17.785824699 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.201     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc20f89e19ba48f19a8126376f2bac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:54:32.306536832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:32.309965083 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:32.310153976 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:32.312612173 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e30176e71f4b59a2b65fe16e4c6c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.631667971611023     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45880070328712463    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11755377799272537    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.631667971611023    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45880070328712463   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11755377799272537   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:54:49.770363522 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:49.770908024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:49.772047814 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:54:49.777016874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a735c7294c5247069e032c3c8a64346a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6262450218200684     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4576358199119568     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11719344556331635    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6262450218200684    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4576358199119568    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11719344556331635   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4576358199119568, 'test_mse': 0.11719344556331635, 'test_iou': 0.6262450218200684}]\n",
      "MSE value is 0.11719344556331635\n",
      "IoU value is 0.6262450218200684\n",
      "num_param value is 1050277\n",
      "Training time: 855.5421783924103\n",
      "Fitness: 14.16317453289042\n",
      "********\n",
      "chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 14.16317453289042, IoU: 0.6262450218200684, FPS: 136.25178843904857, Model Size: 1050277\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELne5arn1EPM2ELne3arn1EUf2mnearestES0ELco04k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'Lne5arn1', 'PM2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1114103\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 11:55:03.559088478 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:55:03.561857600 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:55:03.568072403 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 11:55:03.569025359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.456     Total estimated model params size (MB)\n",
      "65        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f897917580bc4693b41cbc306ed994ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:14:28.095669520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:28.097428813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:28.098489603 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:28.105562091 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916b504022fc42189ffd9d5131d58a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5673719644546509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3666509985923767     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8045401573181152     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5673719644546509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3666509985923767    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8045401573181152    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:14:46.339822283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:46.340624801 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:46.344348156 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:14:46.344707733 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f159b31e6a5343b2ac2fc1d3d62c8ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5698861479759216     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36576807498931885    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8459319472312927     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5698861479759216    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36576807498931885   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8459319472312927    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.36576807498931885, 'test_mse': 0.8459319472312927, 'test_iou': 0.5698861479759216}]\n",
      "MSE value is 0.8459319472312927\n",
      "IoU value is 0.5698861479759216\n",
      "num_param value is 1114103\n",
      "Training time: 1164.5382676124573\n",
      "Fitness: 10.002076282291952\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'Lne5arn1', 'PM2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 10.002076282291952, IoU: 0.5698861479759216, FPS: 123.94539906447214, Model Size: 1114103\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELRr2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 634793\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:15:02.580443643 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:15:02.587039251 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:15:02.587665775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:15:02.596659097 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 634 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "634 K     Trainable params\n",
      "0         Non-trainable params\n",
      "634 K     Total params\n",
      "2.539     Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071c15703bd84458b08fc6e3c778139d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:29:25.025075477 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:25.028308721 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:25.029231845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:25.037811668 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bbefd5afad413d877a260d413a2ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7328137159347534     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30062156915664673    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05865131691098213    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7328137159347534    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30062156915664673   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05865131691098213   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:29:43.923892526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:43.924419463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:43.925747769 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:43.927491740 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5475c74bfe574422882ef1cafd3901fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7253812551498413     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2988111972808838     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0553087554872036     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7253812551498413    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2988111972808838    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0553087554872036    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.2988111972808838, 'test_mse': 0.0553087554872036, 'test_iou': 0.7253812551498413}]\n",
      "MSE value is 0.0553087554872036\n",
      "IoU value is 0.7253812551498413\n",
      "num_param value is 634793\n",
      "Training time: 862.4298624992371\n",
      "Fitness: 16.09491932775234\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 16.09491932775234, IoU: 0.7253812551498413, FPS: 126.95596655924369, Model Size: 634793\n",
      "\n",
      "Architecture: Leo08k3s1p1agn1EPM2ELRr4agn1EUf2mnearestES1ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Leo08k3s1p1agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1590516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:29:59.800955211 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:59.801928654 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:59.801975231 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:29:59.803277058 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffdc223e4f94528b5c83f482db6d5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:44:31.281380933 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:31.286821984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:31.289848600 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:31.298555118 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7b485007944186b452a00a4fff6af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5969960689544678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4777323603630066     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12977249920368195    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5969960689544678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4777323603630066    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12977249920368195   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:44:57.175482212 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:57.175579687 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:57.177419913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:44:57.183518075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03bcb0ffe140e6916125e2aaa1bf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5891785621643066     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4665672481060028     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1237485334277153     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5891785621643066    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4665672481060028    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1237485334277153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4665672481060028, 'test_mse': 0.1237485334277153, 'test_iou': 0.5891785621643066}]\n",
      "MSE value is 0.1237485334277153\n",
      "IoU value is 0.5891785621643066\n",
      "num_param value is 1590516\n",
      "Training time: 872.503954410553\n",
      "Fitness: 13.20005765342584\n",
      "********\n",
      "chromosome: ['Leo08k3s1p1agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS'], fitness: 13.20005765342584, IoU: 0.5891785621643066, FPS: 88.32139126136863, Model Size: 1590516\n",
      "\n",
      "Architecture: Ldo05agn1EPa2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 654728\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:45:20.925063549 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:45:20.945225452 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:45:20.947190678 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:45:20.953489180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 654 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "654 K     Trainable params\n",
      "0         Non-trainable params\n",
      "654 K     Total params\n",
      "2.619     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6fb41d23df4f059c806734cdd95eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:53:39.160042909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:39.162792960 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:39.164132104 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:39.166252419 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2029e8eda3f243a8be268ee969fc16c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5952498316764832     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48025158047676086    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13692010939121246    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5952498316764832    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48025158047676086   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13692010939121246   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:53:53.148196177 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:53.148196335 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:53.148271078 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:53:53.148872635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f622a258440445908b3d102a9be5a95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5811994671821594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4848838150501251     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1392226666212082     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5811994671821594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4848838150501251    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1392226666212082    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4848838150501251, 'test_mse': 0.1392226666212082, 'test_iou': 0.5811994671821594}]\n",
      "MSE value is 0.1392226666212082\n",
      "IoU value is 0.5811994671821594\n",
      "num_param value is 654728\n",
      "Training time: 499.237135887146\n",
      "Fitness: 13.935181905600034\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 13.935181905600034, IoU: 0.5811994671821594, FPS: 160.08573316985976, Model Size: 654728\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELeo05k5s1p2arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 626798\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 12:54:06.744481271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:54:06.744481282 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:54:06.747890923 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 12:54:06.755259224 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 626 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "626 K     Trainable params\n",
      "0         Non-trainable params\n",
      "626 K     Total params\n",
      "2.507     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfe53bc83bb48ba897dd89e481db348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:09:08.825016781 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:08.826182862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:08.826207308 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:08.828684089 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437f279eee2340d9a3647764f922fb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7667018175125122     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3508032560348511     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06746210157871246    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7667018175125122    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3508032560348511    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06746210157871246   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:09:23.896594870 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:23.897562665 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:23.901108556 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:23.908843755 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252efa07d6a34ee58ae4502f9f57c06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7536137104034424     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3598538637161255     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07188491523265839    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7536137104034424    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3598538637161255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07188491523265839   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3598538637161255, 'test_mse': 0.07188491523265839, 'test_iou': 0.7536137104034424}]\n",
      "MSE value is 0.07188491523265839\n",
      "IoU value is 0.7536137104034424\n",
      "num_param value is 626798\n",
      "Training time: 902.0839638710022\n",
      "Fitness: 16.238698868211575\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS'], fitness: 16.238698868211575, IoU: 0.7536137104034424, FPS: 149.17625394289004, Model Size: 626798\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELdo05arn1EUf2mnearestES1ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2821634\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:09:36.410090084 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:36.413053795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:36.413061304 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:09:36.420364565 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.287    Total estimated model params size (MB)\n",
      "22        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c063f50762e40d6a2e4212fa05088ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:48:54.803139688 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:48:54.804024830 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:48:54.806136285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:48:54.811043400 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52db60bc11546559ed273a11639239a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6667729020118713     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37919533252716064    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08127886056900024    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6667729020118713    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37919533252716064   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08127886056900024   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:49:35.612710611 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:49:35.614504016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:49:35.621029940 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:49:35.625415164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb668ded7f564ba291dd876c72a794ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6574466824531555     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3784080147743225     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08064164221286774    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6574466824531555    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3784080147743225    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08064164221286774   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3784080147743225, 'test_mse': 0.08064164221286774, 'test_iou': 0.6574466824531555}]\n",
      "MSE value is 0.08064164221286774\n",
      "IoU value is 0.6574466824531555\n",
      "num_param value is 2821634\n",
      "Training time: 2357.38920211792\n",
      "Fitness: 13.006594302316783\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS'], fitness: 13.006594302316783, IoU: 0.6574466824531555, FPS: 55.34686449814437, Model Size: 2821634\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELne5arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 27219759 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3456\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:50:12.099561274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:50:12.106851487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:50:12.107144706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:50:12.113859281 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 3.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "82        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f668b360a0b452c84641a251207f0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:52:47.464479974 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:47.466788179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:47.466930996 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:47.468418316 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9030273f01e8496ebb92e96a807e7eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4405653476715088     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3800683617591858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1408499777317047     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4405653476715088    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3800683617591858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1408499777317047    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:52:53.499934068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:53.506281192 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:53.506298260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:52:53.507098826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0662ae1ea1494071b2a12b27cae4f969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4457651972770691     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3750761151313782     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14346866309642792    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4457651972770691    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3750761151313782    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14346866309642792   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3750761151313782, 'test_mse': 0.14346866309642792, 'test_iou': 0.4457651972770691}]\n",
      "MSE value is 0.14346866309642792\n",
      "IoU value is 0.4457651972770691\n",
      "num_param value is 3456\n",
      "Training time: 155.30290603637695\n",
      "Fitness: 13.199516524818655\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 13.199516524818655, IoU: 0.4457651972770691, FPS: 351.7730753414967, Model Size: 3456\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 579714814 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19380\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:53:04.053303253 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:53:04.063149253 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:53:04.065567379 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:53:04.066881553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6448ea6bd5eb428ea238cf1f73e9ab1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:55:40.564276429 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:40.564276368 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:40.564502828 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:40.567333409 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccd56f462e44dbdbb6a58fd4c80aefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6298126578330994     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3611657917499542     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07273975759744644    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6298126578330994    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3611657917499542    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07273975759744644   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:55:46.394112164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:46.397356635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:46.398194666 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:46.405754183 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa3e2faabdd4e2497c9bb64cbfbbd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.627876341342926     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3637022376060486     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07405202090740204    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.627876341342926    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3637022376060486    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07405202090740204   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3637022376060486, 'test_mse': 0.07405202090740204, 'test_iou': 0.627876341342926}]\n",
      "MSE value is 0.07405202090740204\n",
      "IoU value is 0.627876341342926\n",
      "num_param value is 19380\n",
      "Training time: 156.81728386878967\n",
      "Fitness: 15.569919407348438\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.569919407348438, IoU: 0.627876341342926, FPS: 364.14529663904966, Model Size: 19380\n",
      "\n",
      "For generation 6, the best fitness of the population is 17.031577915651297.\n",
      "The best historical fitness is 17.520467898581863,with the most fit individual having the following genes: ['LRr2arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_6.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 7 ***\n",
      "Architecture: LRr4arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:55:52.043629743 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:52.052886812 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:52.053261470 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:55:52.056820075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04984d7879b4e0c8dd1d3948a6156ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:58:33.889243993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:33.894304496 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:33.894526969 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:33.896536445 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54267c15d2844d00817d0b81726f4fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7818391919136047     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.30962073802948      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.046840786933898926    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7818391919136047    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.30962073802948     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.046840786933898926   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:58:38.695314016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:38.699137461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:38.699266029 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:38.705913520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ab606673f44fa29905b877e9bc8712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7714855074882507     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3065584599971771     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04507637023925781    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7714855074882507    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3065584599971771    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04507637023925781   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3065584599971771, 'test_mse': 0.04507637023925781, 'test_iou': 0.7714855074882507}]\n",
      "MSE value is 0.04507637023925781\n",
      "IoU value is 0.7714855074882507\n",
      "num_param value is 51876\n",
      "Training time: 160.84532809257507\n",
      "Fitness: 17.231657771263922\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 17.231657771263922, IoU: 0.7714855074882507, FPS: 362.47912914521964, Model Size: 51876\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 108414\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 13:58:44.319503942 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:44.320212006 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:44.320250288 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 13:58:44.327053526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 108 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.434     Total estimated model params size (MB)\n",
      "103       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b20b056ae544e28a37109c1d6040f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:02:49.214282168 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:49.220953478 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:49.220978862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:49.221177656 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4b9df4ae3948a89f35bc82cbfb00b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8037327527999878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28934040665626526    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03900209441781044    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8037327527999878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28934040665626526   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03900209441781044   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:02:56.935820449 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:56.945423444 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:56.945427924 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:02:56.945859374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a981a59f434be39bef743cd3240a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8114964962005615     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2800207734107971     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03393793851137161    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8114964962005615    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2800207734107971    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03393793851137161   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.2800207734107971, 'test_mse': 0.03393793851137161, 'test_iou': 0.8114964962005615}]\n",
      "MSE value is 0.03393793851137161\n",
      "IoU value is 0.8114964962005615\n",
      "num_param value is 108414\n",
      "Training time: 244.90461134910583\n",
      "Fitness: 17.678311352573793\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 17.678311352573793, IoU: 0.8114964962005615, FPS: 320.4064849269568, Model Size: 108414\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:03:02.277978359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:03:02.285729771 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:03:02.288724259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:03:02.298876967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a489488da9a9470b86d288a0415e2f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:06:55.280451734 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:06:55.281105512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:06:55.284292338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:06:55.289077778 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c907fce8a614868bc6da7769eba76f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7409181594848633     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3299207389354706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054679274559020996    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7409181594848633    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3299207389354706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054679274559020996   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:07:02.837801095 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:02.848028017 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:02.850009730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:02.859604719 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638ce39a9bd849a591a60188ac6b6991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7291196584701538     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33084914088249207    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05476979911327362    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7291196584701538    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33084914088249207   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05476979911327362   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.33084914088249207, 'test_mse': 0.05476979911327362, 'test_iou': 0.7291196584701538}]\n",
      "MSE value is 0.05476979911327362\n",
      "IoU value is 0.7291196584701538\n",
      "num_param value is 30994\n",
      "Training time: 232.99712347984314\n",
      "Fitness: 16.74094426730074\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.74094426730074, IoU: 0.7291196584701538, FPS: 325.67703534558785, Model Size: 30994\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELeo05k5s1p2arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 626798\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:07:08.099100324 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:08.100114202 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:08.101096246 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:07:08.105189152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 626 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "626 K     Trainable params\n",
      "0         Non-trainable params\n",
      "626 K     Total params\n",
      "2.507     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f61ea4147142ddb8dab5b9bc687252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:22:10.632785835 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:10.642842082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:10.645962723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:10.648827767 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29ec6c2314b475d8ee78268fc6a216e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7128522396087646     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43764737248420715    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10784130543470383    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7128522396087646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43764737248420715   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10784130543470383   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:22:26.751352748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:26.760877160 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:26.762838294 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:26.771659502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d90ffb9e9c347d0ad562f3688c3bd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6956045627593994     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4594246447086334     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11949136853218079    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6956045627593994    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4594246447086334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11949136853218079   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4594246447086334, 'test_mse': 0.11949136853218079, 'test_iou': 0.6956045627593994}]\n",
      "MSE value is 0.11949136853218079\n",
      "IoU value is 0.6956045627593994\n",
      "num_param value is 626798\n",
      "Training time: 902.5455179214478\n",
      "Fitness: 15.261875677340804\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS'], fitness: 15.261875677340804, IoU: 0.6956045627593994, FPS: 149.38560629046614, Model Size: 626798\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELRr2agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELco10k3s1p1agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 13721849 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELRr4agn1EUf2mnearestES1ELne5arn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2805\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:22:39.390206789 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:39.396401142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:39.396755079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:22:39.398261536 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21390527048e4cf08d2f33799ea3294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:23:58.588964391 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:23:58.597559644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:23:58.598468845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:23:58.602200017 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7a805c63f24846b18badc9aeac6e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6583777070045471     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3597795367240906     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06844379752874374    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6583777070045471    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3597795367240906    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06844379752874374   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:24:04.271796370 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:04.275032252 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:04.277263391 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:04.279607486 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301afe50ec5c4596ae0ec2ed7134c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6427386403083801     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36152493953704834    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06954599171876907    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6427386403083801    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36152493953704834   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06954599171876907   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.36152493953704834, 'test_mse': 0.06954599171876907, 'test_iou': 0.6427386403083801}]\n",
      "MSE value is 0.06954599171876907\n",
      "IoU value is 0.6427386403083801\n",
      "num_param value is 2805\n",
      "Training time: 79.20039558410645\n",
      "Fitness: 15.77434296306115\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'HS'], fitness: 15.77434296306115, IoU: 0.6427386403083801, FPS: 383.6339566811336, Model Size: 2805\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 25029\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:24:09.587482981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:09.590665462 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:09.592028584 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:24:09.600157871 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 25.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "25.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.0 K    Total params\n",
      "0.100     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade41071e0124ddb995495a7c5e2b453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:27:59.964037728 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:27:59.968143277 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:27:59.971847393 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:27:59.981876290 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2f04378053486a8db3364ea13964ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7190454006195068     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31680238246917725    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05067014694213867    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7190454006195068    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31680238246917725   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05067014694213867   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:28:06.877905916 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:06.885198292 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:06.886218620 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:06.891711644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483259d70d8c4de78d9cc9fc6381bb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7148902416229248     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31360259652137756    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.048791538923978806    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7148902416229248    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31360259652137756   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.048791538923978806   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.31360259652137756, 'test_mse': 0.048791538923978806, 'test_iou': 0.7148902416229248}]\n",
      "MSE value is 0.048791538923978806\n",
      "IoU value is 0.7148902416229248\n",
      "num_param value is 25029\n",
      "Training time: 229.37508368492126\n",
      "Fitness: 16.65865666806557\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 16.65865666806557, IoU: 0.7148902416229248, FPS: 314.4973638760573, Model Size: 25029\n",
      "\n",
      "Architecture: Ldo08agn1EPa2ELdo12arn1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'Pa2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 7186457\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 14:28:12.369870328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:12.373283170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:12.376575683 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 14:28:12.381797754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 7.2 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "7.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.2 M     Total params\n",
      "28.746    Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407feaf180db4495866812ea657693a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:44:54.120927795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:44:54.154581965 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:44:54.155586878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:44:54.158905297 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26a824906fd4e4ab112d570d119214e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7790613174438477     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7790613174438477    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:46:34.460651202 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:46:34.510615530 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:46:34.513654920 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:46:34.516629147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d6cd323eca4c2da63af2a652a490de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7752878069877625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7752878069877625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7752878069877625, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 7186457\n",
      "Training time: 4601.744074344635\n",
      "Fitness: 6.586110658357373\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'Pa2', 'Ldo12arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 6.586110658357373, IoU: 0.6023015975952148, FPS: 23.172034852844114, Model Size: 7186457\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19380\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:48:01.867406867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:48:01.869114762 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:48:01.869124818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:48:01.869720176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e60d0caf07b449daa0f65451727ebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:49:28.444162358 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:28.449546036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:28.458866128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:28.464337520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b614f20894fc4fac9ad59a17263112e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.6546590924263      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3574604094028473     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07177358865737915    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.6546590924263     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3574604094028473    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07177358865737915   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:49:34.364712743 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:34.375253355 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:34.376024236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:34.378851306 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa784c9d08ee4ce7b72eac396e6502ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6302245855331421     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3601568937301636     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07302636653184891    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6302245855331421    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3601568937301636    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07302636653184891   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3601568937301636, 'test_mse': 0.07302636653184891, 'test_iou': 0.6302245855331421}]\n",
      "MSE value is 0.07302636653184891\n",
      "IoU value is 0.6302245855331421\n",
      "num_param value is 19380\n",
      "Training time: 87.71387600898743\n",
      "Fitness: 15.602301343502331\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.602301343502331, IoU: 0.6302245855331421, FPS: 365.06850522289085, Model Size: 19380\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELDd0.45n1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:49:40.956758541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:40.956813936 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:40.956814213 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:49:40.959839259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2061e145469416baddf5b97918191f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:50:35.674227893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:35.706598910 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:35.708631633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:35.709613543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6801573bd7eb4c6d9c9a68dddcadcf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6608331799507141     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.349162220954895     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06378669291734695    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6608331799507141    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.349162220954895    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06378669291734695   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:50:41.968480630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:41.006636870 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:41.008611466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:41.018596473 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474ec7dd8d25471eb30f1f0dbca28fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6614464521408081     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34983402490615845    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06412677466869354    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6614464521408081    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34983402490615845   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06412677466869354   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34983402490615845, 'test_mse': 0.06412677466869354, 'test_iou': 0.6614464521408081}]\n",
      "MSE value is 0.06412677466869354\n",
      "IoU value is 0.6614464521408081\n",
      "num_param value is 1516\n",
      "Training time: 55.72413754463196\n",
      "Fitness: 16.010325072818897\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.45n1', 'HS'], fitness: 16.010325072818897, IoU: 0.6614464521408081, FPS: 395.0665100518254, Model Size: 1516\n",
      "\n",
      "Architecture: Lco09k5s1p2agn1EPM2ELco04k5s1p2agn1EUf2mnearestES1ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 32425474 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2agn1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo08agn1EPa2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1470494\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 15:50:46.444024547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:46.477536077 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:46.485572395 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 15:50:46.495306068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.882     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685bb9206c9644d0b931d0dffe4711d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:10:43.672993680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:10:43.674163761 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:10:43.678511580 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:10:43.682765270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a1908861354cfc9d74c30fea21c343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5863307118415833     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5014206767082214     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14871422946453094    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5863307118415833    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5014206767082214    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14871422946453094   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:11:08.926672339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:08.937359889 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:08.942589989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:08.949072388 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a563de2f764344f2ba8148e16a022ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5643542408943176     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5112895369529724     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15365344285964966    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5643542408943176    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5112895369529724    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15365344285964966   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5112895369529724, 'test_mse': 0.15365344285964966, 'test_iou': 0.5643542408943176}]\n",
      "MSE value is 0.15365344285964966\n",
      "IoU value is 0.5643542408943176\n",
      "num_param value is 1470494\n",
      "Training time: 1197.1950664520264\n",
      "Fitness: 12.84116279103372\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 12.84116279103372, IoU: 0.5643542408943176, FPS: 94.05442735236389, Model Size: 1470494\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELco04k5s1p2agn1EUf2mnearestES2ELne5arn1EUf2mnearestES0ELdo07arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 25200900 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo08k3s1p1agn1EPa2ELbo05k3s1p1arn1EUf2mnearestES1ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Leo08k3s1p1agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 39670796 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo08k3s1p1agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lbo07k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELco12k5s1p2agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 126914\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:11:30.913131905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:30.914716466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:30.917009890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:11:30.918274512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 126 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "126 K     Trainable params\n",
      "0         Non-trainable params\n",
      "126 K     Total params\n",
      "0.508     Total estimated model params size (MB)\n",
      "59        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cded96578702433ab5bbff7a6d3c167c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:16:54.123125123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:16:54.154550146 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:16:54.155607372 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:16:54.159089981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b89f714b384fae919e99cdc1701a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3117617964744568     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8463236689567566     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8404133319854736     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3117617964744568    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8463236689567566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8404133319854736    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:17:04.458488934 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:04.497606390 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:04.505498093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:04.510751944 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562c0b29885b46ec93b69945da6ac19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28859126567840576    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8473743796348572     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.807900607585907     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28859126567840576   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8473743796348572    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.807900607585907    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8473743796348572, 'test_mse': 0.807900607585907, 'test_iou': 0.28859126567840576}]\n",
      "MSE value is 0.807900607585907\n",
      "IoU value is 0.28859126567840576\n",
      "num_param value is 126914\n",
      "Training time: 324.26210141181946\n",
      "Fitness: 8.290276182794196\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 8.290276182794196, IoU: 0.28859126567840576, FPS: 212.6130467276578, Model Size: 126914\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELDd0.30n1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1160\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:17:14.942608986 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:14.958515514 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:14.958591260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:17:14.965561898 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.2 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5ebc383a6d4da58c9362f3c415d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:18:56.427906950 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:18:56.445221764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:18:56.457691117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:18:56.464648936 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40adf821e7f4c76a42e568ac0b7e27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6727796792984009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3378981053829193     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06056593358516693    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6727796792984009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3378981053829193    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06056593358516693   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:19:02.870171735 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:02.871243599 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:02.880258878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:02.885686578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08f2bc75d1c4b30a3e2e4d802891e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6592861413955688     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3490695655345917     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06643234193325043    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6592861413955688    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3490695655345917    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06643234193325043   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3490695655345917, 'test_mse': 0.06643234193325043, 'test_iou': 0.6592861413955688}]\n",
      "MSE value is 0.06643234193325043\n",
      "IoU value is 0.6592861413955688\n",
      "num_param value is 1160\n",
      "Training time: 102.4379289150238\n",
      "Fitness: 15.968761361211035\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 15.968761361211035, IoU: 0.6592861413955688, FPS: 389.0981018324135, Model Size: 1160\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 137908799 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELDd0.35n1EPa2ELdo12agn1EUf2mnearestES1ELdo09agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'LDd0.35n1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S1', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 13147516 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'LDd0.35n1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S1', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 16115246 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELRr3arn1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 656654\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:19:09.783036050 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:09.789149844 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:09.793224872 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:19:09.795513723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 656 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "656 K     Trainable params\n",
      "0         Non-trainable params\n",
      "656 K     Total params\n",
      "2.627     Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49976ae50dd44b0aa7ce6fcf4550d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:31:04.743544981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:04.759492458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:04.774549626 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:04.778026223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2785fab63d54d4cad6c40be06ec7b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6886179447174072     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3500162363052368     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06998245418071747    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6886179447174072    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3500162363052368    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06998245418071747   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:31:18.982055470 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:18.014637562 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:18.017585083 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:18.017827845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be2550ccfcb4531b769ed76413b12c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6663971543312073     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3515082001686096     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07057324051856995    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6663971543312073    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3515082001686096    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07057324051856995   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3515082001686096, 'test_mse': 0.07057324051856995, 'test_iou': 0.6663971543312073}]\n",
      "MSE value is 0.07057324051856995\n",
      "IoU value is 0.6663971543312073\n",
      "num_param value is 656654\n",
      "Training time: 715.2914762496948\n",
      "Fitness: 15.348107712096926\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.348107712096926, IoU: 0.6663971543312073, FPS: 158.286493638431, Model Size: 656654\n",
      "\n",
      "For generation 7, the best fitness of the population is 17.678311352573793.\n",
      "The best historical fitness is 17.678311352573793,with the most fit individual having the following genes: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_7.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 8 ***\n",
      "Architecture: LRr4arn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 107631\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:31:31.813607468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:31.815532315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:31.816766815 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:31:31.820785647 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 107 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.431     Total estimated model params size (MB)\n",
      "105       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9651251c813497781d62060d44a1a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:34:13.871282180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:13.891607316 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:13.892567166 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:13.894900092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20fdf754b7e4478949cb5b80781ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7572708129882812     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3206842541694641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05354342982172966    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7572708129882812    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3206842541694641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05354342982172966   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:34:19.554140112 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:19.596612819 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:19.597622945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:19.607378775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f171c34d0bf841a2ab79123b899b753b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7501947283744812     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3202303647994995     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05297815054655075    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7501947283744812    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3202303647994995    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05297815054655075   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3202303647994995, 'test_mse': 0.05297815054655075, 'test_iou': 0.7501947283744812}]\n",
      "MSE value is 0.05297815054655075\n",
      "IoU value is 0.7501947283744812\n",
      "num_param value is 107631\n",
      "Training time: 162.05847215652466\n",
      "Fitness: 16.89118950453242\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 16.89118950453242, IoU: 0.7501947283744812, FPS: 316.4254989837812, Model Size: 107631\n",
      "\n",
      "Architecture: Lne4agn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 52659\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:34:26.962665576 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:26.005696446 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:26.009581158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:34:26.018859341 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 52.7 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "52.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.7 K    Total params\n",
      "0.211     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ffe38d50724928956c2502fe9ebcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:37:23.224279847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:23.224587339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:23.228134606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:23.228229636 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea591d4b2f2942a6937d37e350ee7025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7706583142280579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3061125576496124     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045686088502407074    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7706583142280579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3061125576496124    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045686088502407074   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:37:29.449735541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:29.451348917 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:29.451798659 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:29.453374707 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b323ea771545348f2cfb4c60f30e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7684200406074524     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3051254153251648     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04504840448498726    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7684200406074524    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3051254153251648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04504840448498726   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3051254153251648, 'test_mse': 0.04504840448498726, 'test_iou': 0.7684200406074524}]\n",
      "MSE value is 0.04504840448498726\n",
      "IoU value is 0.7684200406074524\n",
      "num_param value is 52659\n",
      "Training time: 177.2354645729065\n",
      "Fitness: 17.200476162669005\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 17.200476162669005, IoU: 0.7684200406074524, FPS: 342.28443447860144, Model Size: 52659\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:37:35.388499401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:35.402146116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:35.404138366 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:37:35.409857600 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f274c12b4e434150897700a4d096e1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:41:29.615509714 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:29.629927550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:29.668517500 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:29.668517503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7549a5c3c95547619f4eb1cdb4d160de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7447004914283752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34609168767929077    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06173295900225639    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7447004914283752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34609168767929077   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06173295900225639   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:41:36.402049502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:36.407572408 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:36.464406207 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:36.464478589 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b089a44f7844a96a432223682add916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7299144268035889     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3462970554828644     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06200028583407402    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7299144268035889    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3462970554828644    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06200028583407402   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3462970554828644, 'test_mse': 0.06200028583407402, 'test_iou': 0.7299144268035889}]\n",
      "MSE value is 0.06200028583407402\n",
      "IoU value is 0.7299144268035889\n",
      "num_param value is 30994\n",
      "Training time: 234.25612711906433\n",
      "Fitness: 16.68434359056988\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.68434359056988, IoU: 0.7299144268035889, FPS: 317.4333866752803, Model Size: 30994\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELRr4agn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2602\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:41:43.793180673 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:43.818552004 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:43.836577360 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:41:43.845921410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae90f7afc2c4f50b85c1bd66b48ca3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:42:59.717754418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:42:59.719714971 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:42:59.739357806 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:00.748131339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af3c0a78a054089a0629cdcc1f8274e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6292983293533325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36371079087257385    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06981905549764633    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6292983293533325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36371079087257385   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06981905549764633   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:43:05.425070932 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:05.429044098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:05.435640242 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:05.440625084 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6178c65ee69a4f43983865169e7d9f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6282548308372498     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3632276952266693     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06953173130750656    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6282548308372498    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3632276952266693    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06953173130750656   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3632276952266693, 'test_mse': 0.06953173130750656, 'test_iou': 0.6282548308372498}]\n",
      "MSE value is 0.06953173130750656\n",
      "IoU value is 0.6282548308372498\n",
      "num_param value is 2602\n",
      "Training time: 76.91286110877991\n",
      "Fitness: 15.629832531733971\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 15.629832531733971, IoU: 0.6282548308372498, FPS: 374.17077757828605, Model Size: 2602\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:43:11.857608623 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:11.857848125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:11.882621712 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:43:11.882777525 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db4e761a08a4000a8317c5f6d154e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:45:02.794208502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:02.800438638 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:02.868427327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:02.868472447 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4dea84cff6401bb8bac2ab66db0a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6400466561317444     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3484003245830536     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06668383628129959    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6400466561317444    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3484003245830536    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06668383628129959   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:45:07.563080275 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:07.565029921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:07.604401001 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:07.604469476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcc65012abd44a39480316b87b84692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6275078058242798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36214661598205566    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07377762347459793    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6275078058242798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36214661598205566   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07377762347459793   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.36214661598205566, 'test_mse': 0.07377762347459793, 'test_iou': 0.6275078058242798}]\n",
      "MSE value is 0.07377762347459793\n",
      "IoU value is 0.6275078058242798\n",
      "num_param value is 1566\n",
      "Training time: 110.92248845100403\n",
      "Fitness: 15.586427303804875\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 15.586427303804875, IoU: 0.6275078058242798, FPS: 372.08959026625985, Model Size: 1566\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELDd0.30n1EUf2mnearestES1ELDd0.45n1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1110\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:45:13.073737981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:13.073737978 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:13.104378966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:45:13.104505616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d69f377c1374a8087da50d05e54b1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:46:05.431309325 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:05.444420961 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:05.459517165 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:05.461987259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd80e55747ec4caeb84a2d0d4e76591b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6738805770874023     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34165093302726746    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05837571620941162    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6738805770874023    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34165093302726746   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05837571620941162   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:46:11.105628531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:11.127046545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:11.154595411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:11.158827101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e8ba8145664052b6cff97ee72fecd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6577954292297363     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3489021062850952     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0616452731192112     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6577954292297363    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3489021062850952    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0616452731192112    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3489021062850952, 'test_mse': 0.0616452731192112, 'test_iou': 0.6577954292297363}]\n",
      "MSE value is 0.0616452731192112\n",
      "IoU value is 0.6577954292297363\n",
      "num_param value is 1110\n",
      "Training time: 52.3805468082428\n",
      "Fitness: 15.996186376889407\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'LDd0.45n1', 'HS'], fitness: 15.996186376889407, IoU: 0.6577954292297363, FPS: 371.64741333230546, Model Size: 1110\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELRr4agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2602\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:46:16.537920152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:16.541759067 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:16.566359715 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:46:16.570298145 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378d5a375648413a96b788e8995f6f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:47:33.224835502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:33.227679342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:33.231571793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:33.236345543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01bf82259f24c689ab48e6bfb8730cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.647849440574646     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3468727767467499     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06327550113201141    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.647849440574646    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3468727767467499    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06327550113201141   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:47:39.826075528 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:39.827139093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:39.828158591 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:39.837172462 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3562c3db1ff465fbbf40b83ac14bf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6373838186264038     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3509712815284729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0651422068476677     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6373838186264038    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3509712815284729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0651422068476677    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3509712815284729, 'test_mse': 0.0651422068476677, 'test_iou': 0.6373838186264038}]\n",
      "MSE value is 0.0651422068476677\n",
      "IoU value is 0.6373838186264038\n",
      "num_param value is 2602\n",
      "Training time: 76.65482950210571\n",
      "Fitness: 15.759653935285002\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: 15.759653935285002, IoU: 0.6373838186264038, FPS: 371.5465242809404, Model Size: 2602\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EUf2mnearestES1ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19583\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:47:44.299247828 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:44.324715473 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:44.326415419 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:47:44.327305840 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.6 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcad3d95c5841599fbe0512d31dd5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:49:16.999064258 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:16.005449025 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:16.052411711 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:16.052454807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c171eb17620477d9ab4b26418f83e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6698155403137207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35739266872406006    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07226114720106125    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6698155403137207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35739266872406006   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07226114720106125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:49:22.178730815 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:22.198740538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:22.268415937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:22.268477121 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d57ac5e2684e678b022034bb39209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6610691547393799     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3586345613002777     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07284770905971527    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6610691547393799    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3586345613002777    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07284770905971527   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3586345613002777, 'test_mse': 0.07284770905971527, 'test_iou': 0.6610691547393799}]\n",
      "MSE value is 0.07284770905971527\n",
      "IoU value is 0.6610691547393799\n",
      "num_param value is 19583\n",
      "Training time: 91.69547820091248\n",
      "Fitness: 15.912095967653457\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'HS'], fitness: 15.912095967653457, IoU: 0.6610691547393799, FPS: 345.5564874908185, Model Size: 19583\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELRr3arn1EUf2mnearestES0ELeo05k5s1p2arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 628724\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 16:49:28.075223892 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:28.082825908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:28.128427102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 16:49:28.128482232 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 628 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "628 K     Trainable params\n",
      "0         Non-trainable params\n",
      "628 K     Total params\n",
      "2.515     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0343357cd4b74af8b455854935d43909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:07:59.531393951 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:07:59.544118924 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:07:59.560407837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:07:59.568885200 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bfdc25d7064792882dea5259014d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7367814183235168     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40070268511772156    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09312271326780319    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7367814183235168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40070268511772156   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09312271326780319   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:08:15.010504750 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:15.023383016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:15.050209616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:15.059310372 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a4127877284408aa3b21c42317710e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7348567247390747     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3928326666355133     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08959661424160004    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7348567247390747    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3928326666355133    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08959661424160004   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3928326666355133, 'test_mse': 0.08959661424160004, 'test_iou': 0.7348567247390747}]\n",
      "MSE value is 0.08959661424160004\n",
      "IoU value is 0.7348567247390747\n",
      "num_param value is 628724\n",
      "Training time: 1111.4675052165985\n",
      "Fitness: 15.897551648183066\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HS'], fitness: 15.897551648183066, IoU: 0.7348567247390747, FPS: 145.03061673862578, Model Size: 628724\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELdo07arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1131512\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:08:29.911172546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:29.923675645 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:29.930044432 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:08:29.935733244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.1 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.526     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36f419e013f485285ae417f9590e9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:23:02.281334542 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:02.283746782 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:02.285729328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:02.291110538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ad415c36994223b3abd1a1125ea96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5641524195671082     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5944731831550598     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1956680566072464     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5641524195671082    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5944731831550598    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1956680566072464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:23:23.000927338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:23.001053796 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:23.007378311 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:23.013397708 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d27250d84c45ea9cb3da615f7120ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5491784811019897     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5907821655273438     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1935841590166092     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5491784811019897    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5907821655273438    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1935841590166092    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5907821655273438, 'test_mse': 0.1935841590166092, 'test_iou': 0.5491784811019897}]\n",
      "MSE value is 0.1935841590166092\n",
      "IoU value is 0.5491784811019897\n",
      "num_param value is 1131512\n",
      "Training time: 873.3702404499054\n",
      "Fitness: 12.738400087976196\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS'], fitness: 12.738400087976196, IoU: 0.5491784811019897, FPS: 109.59213073701898, Model Size: 1131512\n",
      "\n",
      "Architecture: Ldo08agn1EPa2ELdo08agn1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 14760970 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo08agn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELne5arn1EPa2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19318\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:23:41.521807374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:41.524775019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:41.535311753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:23:41.536082093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.3 K    Total params\n",
      "0.077     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8158b30a22db4ba29b1796673f59b42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:27:10.999593838 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:10.001259824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:10.048397341 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:10.048454400 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e6d1fe93db4cc495524e544d188f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3187769651412964     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7818962335586548     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45538023114204407    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3187769651412964    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7818962335586548    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45538023114204407   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:27:17.052238596 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:17.054822485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:17.104411586 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:17.104465479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509e8c6dcd80477682202f001c4b7b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2995263636112213     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7922417521476746     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4590032696723938     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2995263636112213    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7922417521476746    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4590032696723938    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7922417521476746, 'test_mse': 0.4590032696723938, 'test_iou': 0.2995263636112213}]\n",
      "MSE value is 0.4590032696723938\n",
      "IoU value is 0.2995263636112213\n",
      "num_param value is 19318\n",
      "Training time: 208.5139217376709\n",
      "Fitness: 9.829939871673735\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 9.829939871673735, IoU: 0.2995263636112213, FPS: 306.2356790984912, Model Size: 19318\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 323719\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:27:23.669126043 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:23.694535113 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:24.752414395 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:27:24.752448359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 323 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "323 K     Trainable params\n",
      "0         Non-trainable params\n",
      "323 K     Total params\n",
      "1.295     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03620beaf435401d95557d7a05b77b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:33:56.650222850 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:33:56.660668598 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:33:56.667711036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:33:56.677156890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05fdd5ac5fd46078323a81d00682fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7299377918243408     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3319269120693207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06009439751505852    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7299377918243408    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3319269120693207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06009439751505852   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:34:07.830955696 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:07.830959919 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:07.857233030 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:07.866410335 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ba9caeea7f4f2c86ae548b4fb2c0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7318922281265259     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.327232301235199     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.057570312172174454    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7318922281265259    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.327232301235199    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.057570312172174454   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.327232301235199, 'test_mse': 0.057570312172174454, 'test_iou': 0.7318922281265259}]\n",
      "MSE value is 0.057570312172174454\n",
      "IoU value is 0.7318922281265259\n",
      "num_param value is 323719\n",
      "Training time: 392.94644594192505\n",
      "Fitness: 16.450839360402835\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 16.450839360402835, IoU: 0.7318922281265259, FPS: 215.15495740930552, Model Size: 323719\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELRr2agn1EPM2ELRr3agn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 6357980\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 17:34:16.235529690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:16.248134282 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:16.260344800 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 17:34:16.266454596 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 6.4 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "6.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 M     Total params\n",
      "25.432    Total estimated model params size (MB)\n",
      "67        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f543da734c9f47b2989c9f20e7079d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:12:43.420435487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:12:43.421258804 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:12:43.421339686 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:12:43.431148276 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f36d854c4554e248189de007679fa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.55793696641922      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4938330352306366     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5213061571121216     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.55793696641922     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4938330352306366    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5213061571121216    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:14:44.706057953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:14:44.713886043 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:14:44.720931784 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:14:44.726004230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf416ddc52144d7a19251ca65470afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5334039330482483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4959232211112976     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5511704087257385     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5334039330482483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4959232211112976    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5511704087257385    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4959232211112976, 'test_mse': 0.5511704087257385, 'test_iou': 0.5334039330482483}]\n",
      "MSE value is 0.5511704087257385\n",
      "IoU value is 0.5334039330482483\n",
      "num_param value is 6357980\n",
      "Training time: 5907.181554555893\n",
      "Fitness: 5.422804281100022\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 5.422804281100022, IoU: 0.5334039330482483, FPS: 19.216158245148183, Model Size: 6357980\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELco04k5s1p2agn1EUf2mnearestES2ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 401300\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:16:29.888691864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:16:29.902928908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:16:29.906451071 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:16:29.910000262 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 401 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "401 K     Trainable params\n",
      "0         Non-trainable params\n",
      "401 K     Total params\n",
      "1.605     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60a765afe8646d18e1e61ec30d0aa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:24:02.909143887 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:02.918333836 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:02.976412797 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:02.976468903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3848f17a75e042f483fe06ff2838a61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5212178826332092     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4039265513420105     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08201350271701813    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5212178826332092    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4039265513420105    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08201350271701813   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:24:13.198798807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:13.207593461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:13.276428687 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:13.276469777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78255dcb7e4341dbb9fb129dc97735b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5250973701477051     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4124179184436798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08704780042171478    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5250973701477051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4124179184436798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08704780042171478   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4124179184436798, 'test_mse': 0.08704780042171478, 'test_iou': 0.5250973701477051}]\n",
      "MSE value is 0.08704780042171478\n",
      "IoU value is 0.5250973701477051\n",
      "num_param value is 401300\n",
      "Training time: 453.2514772415161\n",
      "Fitness: 14.04890118358092\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS'], fitness: 14.04890118358092, IoU: 0.5250973701477051, FPS: 196.8236818508682, Model Size: 401300\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELdo07arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 25200900 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo12agn1EUf2mnearestES2ELdo09agn1EUf2mnearestES0ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 530145567 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo12agn1', 'Uf2mnearest', 'S2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3456\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:24:28.144959856 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:28.148350848 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:28.180410153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:24:28.180461592 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 3.5 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "3.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "82        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3349d9c30f9b488dbc75965bc5c6607a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:27:05.893881566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:05.912548108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:05.936791779 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:05.942247088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c2b6c5b4324fe49cd2a77c0adedf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4447426497936249     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39966997504234314    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14749978482723236    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4447426497936249    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39966997504234314   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14749978482723236   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:27:11.382196279 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:11.395971547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:11.417661495 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:11.423107111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc053c7bcbd949e5b81af3383c0bf920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43944957852363586    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3937203884124756     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14869606494903564    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43944957852363586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3937203884124756    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14869606494903564   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3937203884124756, 'test_mse': 0.14869606494903564, 'test_iou': 0.43944957852363586}]\n",
      "MSE value is 0.14869606494903564\n",
      "IoU value is 0.43944957852363586\n",
      "num_param value is 3456\n",
      "Training time: 157.08155488967896\n",
      "Fitness: 13.096562773550652\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 13.096562773550652, IoU: 0.43944957852363586, FPS: 326.7349828774533, Model Size: 3456\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELRr3arn1EPa2ELdo05arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELeo12k3s1p1agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo12k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 22404880 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Pa2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo12k3s1p1agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 654728\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:27:18.816565773 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:18.823058992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:18.880403641 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:27:18.880459149 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 654 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "654 K     Trainable params\n",
      "0         Non-trainable params\n",
      "654 K     Total params\n",
      "2.619     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe383e38c9c438a904433b2e4472743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:38:04.898319219 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:04.904232942 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:04.929298243 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:04.935105391 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3324cd54b78b45fd8fa570071b0ca7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5880946516990662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5092340111732483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15196579694747925    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5880946516990662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5092340111732483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15196579694747925   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:38:18.346843185 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:18.368341712 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:18.382878928 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:18.386078754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f822212ed354f09a1ed4feffb497fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5619702339172363     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5192091464996338     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15688447654247284    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5619702339172363    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5192091464996338    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15688447654247284   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5192091464996338, 'test_mse': 0.15688447654247284, 'test_iou': 0.5619702339172363}]\n",
      "MSE value is 0.15688447654247284\n",
      "IoU value is 0.5619702339172363\n",
      "num_param value is 654728\n",
      "Training time: 646.085755109787\n",
      "Fitness: 13.608879761679662\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 13.608879761679662, IoU: 0.5619702339172363, FPS: 154.5768608503691, Model Size: 654728\n",
      "\n",
      "For generation 8, the best fitness of the population is 17.200476162669005.\n",
      "The best historical fitness is 17.678311352573793,with the most fit individual having the following genes: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_8.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 9 ***\n",
      "Architecture: LRr4arn1EPa2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:38:31.460271802 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:31.463664070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:31.524417422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:38:31.524475151 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d9941e9028444e893d6c7e3d0df9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:41:13.252097851 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:13.257238418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:13.284254269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:13.293250374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0423557828ed4c5e9e5d3cf80dfd4423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7484633326530457     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30775687098503113    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.047072798013687134    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7484633326530457    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30775687098503113   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.047072798013687134   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:41:19.562914311 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:19.581352993 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:19.591746816 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:19.592109202 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82224ea2fd1454982766bbb0c20c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7446649670600891     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30776044726371765    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04664758965373039    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7446649670600891    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30776044726371765   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04664758965373039   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.30776044726371765, 'test_mse': 0.04664758965373039, 'test_iou': 0.7446649670600891}]\n",
      "MSE value is 0.04664758965373039\n",
      "IoU value is 0.7446649670600891\n",
      "num_param value is 51876\n",
      "Training time: 161.78409051895142\n",
      "Fitness: 16.949087939177545\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'Pa2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 16.949087939177545, IoU: 0.7446649670600891, FPS: 337.9449593309014, Model Size: 51876\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 108414\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:41:25.583954497 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:25.596207551 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:25.613935407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:41:25.619244028 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 108 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.434     Total estimated model params size (MB)\n",
      "103       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8cd723f4474376b26eb29f4d26875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:45:31.540192704 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:31.548383250 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:31.549945312 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:31.556506631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963e3a1ec01b4d33857109e821a9d879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8169929385185242     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3143555521965027     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.050982072949409485    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8169929385185242    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3143555521965027    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.050982072949409485   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:45:39.872352629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:39.882181518 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:39.885177868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:39.894784270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b781f9dbe5d4a168fa706366b8e9a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8177798390388489     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3069537878036499     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04705338552594185    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8177798390388489    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3069537878036499    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04705338552594185   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3069537878036499, 'test_mse': 0.04705338552594185, 'test_iou': 0.8177798390388489}]\n",
      "MSE value is 0.04705338552594185\n",
      "IoU value is 0.8177798390388489\n",
      "num_param value is 108414\n",
      "Training time: 245.93421411514282\n",
      "Fitness: 17.619995790185392\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 17.619995790185392, IoU: 0.8177798390388489, FPS: 295.4116854040052, Model Size: 108414\n",
      "\n",
      "Architecture: LRr2arn1EPM2ELdo05agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 30994\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:45:45.722449616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:45.731342817 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:46.784423579 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:45:46.784455108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 31.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0925de416f641c9a339f122c5622f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:49:17.790353875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:17.799727327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:17.811660578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:17.819140221 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f300b34f2e5400f8ee4a0775b6b718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7436535954475403     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31976473331451416    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04856834188103676    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7436535954475403    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31976473331451416   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04856834188103676   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:49:24.832233123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:24.844563433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:24.869299019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:24.871619927 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de18924360194acf90dd79f612cce2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.722384512424469     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31990301609039307    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.048109013587236404    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.722384512424469    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31990301609039307   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.048109013587236404   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.31990301609039307, 'test_mse': 0.048109013587236404, 'test_iou': 0.722384512424469}]\n",
      "MSE value is 0.048109013587236404\n",
      "IoU value is 0.722384512424469\n",
      "num_param value is 30994\n",
      "Training time: 211.05365300178528\n",
      "Fitness: 16.73384339734251\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'PM2', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.73384339734251, IoU: 0.722384512424469, FPS: 301.19128533077117, Model Size: 30994\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 323719\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:49:30.583636198 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:30.589918158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:30.595270066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:49:30.599485646 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 323 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "323 K     Trainable params\n",
      "0         Non-trainable params\n",
      "323 K     Total params\n",
      "1.295     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418b0fc03a9c4cc5986996b3ffbd91b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:56:53.174602114 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:56:53.180860936 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:56:53.181040928 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:56:53.190465154 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d315a02b23b4b109f31f2b7cbdb9496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7762448787689209     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31725576519966125    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05345366522669792    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7762448787689209    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31725576519966125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05345366522669792   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:57:03.383297514 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:03.386824636 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:03.388694619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:03.392727648 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cf46b19c7e4187b0a193d17a5b5515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7776925563812256     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30645543336868286    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04755161702632904    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7776925563812256    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30645543336868286   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04755161702632904   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.30645543336868286, 'test_mse': 0.04755161702632904, 'test_iou': 0.7776925563812256}]\n",
      "MSE value is 0.04755161702632904\n",
      "IoU value is 0.7776925563812256\n",
      "num_param value is 323719\n",
      "Training time: 442.61792492866516\n",
      "Fitness: 16.999275547397875\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 16.999275547397875, IoU: 0.7776925563812256, FPS: 215.00834532287067, Model Size: 323719\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELDd0.30n1EUf2mnearestES1ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 79510\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:57:13.798420734 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:13.798900988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:13.803451271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:57:13.811032487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 79.5 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "79.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "79.5 K    Total params\n",
      "0.318     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e97733d5894bdba41a1f84704d1068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:59:28.000616668 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:28.000890258 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:28.002157014 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:28.011749032 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9977594287456e86d7f6c7faf47307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7066638469696045     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3297669291496277     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0582878552377224     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7066638469696045    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3297669291496277    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0582878552377224    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:59:35.507112428 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:35.509166307 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:35.509980542 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:35.513406823 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7b661932b24ddb8b65328cb6b4d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6934312582015991     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3387771546840668     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.062391072511672974    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6934312582015991    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3387771546840668    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.062391072511672974   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3387771546840668, 'test_mse': 0.062391072511672974, 'test_iou': 0.6934312582015991}]\n",
      "MSE value is 0.062391072511672974\n",
      "IoU value is 0.6934312582015991\n",
      "num_param value is 79510\n",
      "Training time: 135.1970956325531\n",
      "Fitness: 16.26753228084366\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Lco12k5s1p2agn1', 'HS'], fitness: 16.26753228084366, IoU: 0.6934312582015991, FPS: 295.2902887759982, Model Size: 79510\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EUf2mnearestES1ELDd0.45n1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'LDd0.45n1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1719\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 19:59:42.352939977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:42.358062411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:42.412391698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 19:59:42.412437744 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.7 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5f5159267c499988bbf6fc63da7e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:01:27.947543063 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:27.954026405 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:27.978994575 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:27.980153841 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a0f969de5a49209c14e04ec8927ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6721011400222778     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35657045245170593    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07064403593540192    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6721011400222778    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35657045245170593   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07064403593540192   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:01:33.832951919 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:33.835604979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:33.861677620 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:33.866979114 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae0fbab1ea74051bfb4c8f5d5b3d3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.669106125831604     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3479171693325043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06616973131895065    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.669106125831604    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3479171693325043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06616973131895065   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3479171693325043, 'test_mse': 0.06616973131895065, 'test_iou': 0.669106125831604}]\n",
      "MSE value is 0.06616973131895065\n",
      "IoU value is 0.669106125831604\n",
      "num_param value is 1719\n",
      "Training time: 104.61723732948303\n",
      "Fitness: 16.06871188985592\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'LDd0.45n1', 'HS'], fitness: 16.06871188985592, IoU: 0.669106125831604, FPS: 359.7457397792742, Model Size: 1719\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELRr3arn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2805\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:01:38.494792481 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:38.506446417 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:38.528735713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:01:38.534298528 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da8d15cfd3744a999b69f3d4cce7ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:03:36.226023292 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:36.228273608 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:36.230339171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:36.232104167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b8726070e94d58a759ee0d515c1a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6861265301704407     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3426904082298279     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06423560529947281    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6861265301704407    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3426904082298279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06423560529947281   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:03:42.147582709 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:42.154685954 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:42.160905190 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:42.163946898 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81e4d29ff374f07a60ed349c71f8dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6844562292098999     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3407731354236603     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06291508674621582    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6844562292098999    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3407731354236603    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06291508674621582   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3407731354236603, 'test_mse': 0.06291508674621582, 'test_iou': 0.6844562292098999}]\n",
      "MSE value is 0.06291508674621582\n",
      "IoU value is 0.6844562292098999\n",
      "num_param value is 2805\n",
      "Training time: 117.72588467597961\n",
      "Fitness: 16.24984654089487\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 16.24984654089487, IoU: 0.6844562292098999, FPS: 354.36483482168734, Model Size: 2805\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELRr4agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 41186\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:03:48.904790507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:48.918204642 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:48.918204898 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:03:48.927228055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 41.2 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "41.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.2 K    Total params\n",
      "0.165     Total estimated model params size (MB)\n",
      "45        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c459cb5368be4a93b92db266d458d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:08:38.440897043 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:38.447519292 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:38.448098312 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:38.455557105 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f686aa3b7f442f85f47dbee28dc515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7049685716629028     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3448319137096405     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.061297234147787094    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7049685716629028    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3448319137096405    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061297234147787094   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:08:46.575089357 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:46.586138813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:46.592410055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:46.596842074 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ebb96662148d2a13cb24059d19816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7036635279655457     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34272947907447815    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05978194624185562    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7036635279655457    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34272947907447815   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05978194624185562   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34272947907447815, 'test_mse': 0.05978194624185562, 'test_iou': 0.7036635279655457}]\n",
      "MSE value is 0.05978194624185562\n",
      "IoU value is 0.7036635279655457\n",
      "num_param value is 41186\n",
      "Training time: 290.5272626876831\n",
      "Fitness: 16.43135261379083\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: 16.43135261379083, IoU: 0.7036635279655457, FPS: 267.17992410066614, Model Size: 41186\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELRr4agn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2602\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:08:54.103963462 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:54.128567104 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:54.145689772 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:08:54.146059795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f7bb2abf554ad98a56a9468a79e83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:10:10.675739706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:10.679032071 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:10.683504227 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:10.689619363 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9e8daba4a242edb4b4d1a5caa73ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6885576844215393     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34265008568763733    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.061509087681770325    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6885576844215393    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34265008568763733   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061509087681770325   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:10:16.535444647 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:16.536357170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:16.537502963 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:16.543730418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcc12e26f88436085da924c701a880f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6756998300552368     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3444160521030426     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.062254399061203     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6756998300552368    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3444160521030426    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.062254399061203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3444160521030426, 'test_mse': 0.062254399061203, 'test_iou': 0.6756998300552368}]\n",
      "MSE value is 0.062254399061203\n",
      "IoU value is 0.6756998300552368\n",
      "num_param value is 2602\n",
      "Training time: 76.56761765480042\n",
      "Fitness: 16.168337074850673\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 16.168337074850673, IoU: 0.6756998300552368, FPS: 363.96890868656794, Model Size: 2602\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1566\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:10:22.140097836 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:22.141723972 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:22.142027261 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:10:22.144378501 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7818139a3e40339162df00634f9e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:12:11.705515886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:11.712094755 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:11.715191144 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:11.717023887 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a4d4d3252b4b22810bbbff26e702d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6120933890342712     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34899434447288513    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06632500141859055    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6120933890342712    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34899434447288513   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06632500141859055   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:12:17.527248142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:17.529248469 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:17.531099558 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:17.532674727 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30073f58fc434dafa0f0a6dd596c6e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6074631214141846     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.357071191072464     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07057063281536102    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6074631214141846    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.357071191072464    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07057063281536102   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.357071191072464, 'test_mse': 0.07057063281536102, 'test_iou': 0.6074631214141846}]\n",
      "MSE value is 0.07057063281536102\n",
      "IoU value is 0.6074631214141846\n",
      "num_param value is 1566\n",
      "Training time: 109.59133076667786\n",
      "Fitness: 15.413878135286748\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 15.413878135286748, IoU: 0.6074631214141846, FPS: 362.4663172297551, Model Size: 1566\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELco04k5s1p2agn1EUf2mnearestES2ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 401300\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:12:23.113335463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:23.116446101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:23.116710930 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:12:23.124181932 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 401 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "401 K     Trainable params\n",
      "0         Non-trainable params\n",
      "401 K     Total params\n",
      "1.605     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d04af482a84e49a2bbdee8c242c3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:19:55.115897809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:19:55.144063402 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:19:55.146041888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:19:55.153405748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c820a1aaa3ea4421b9ff41bb1b3da807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.536591649055481     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4262114465236664     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09970042109489441    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.536591649055481    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4262114465236664    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09970042109489441   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:20:06.502910933 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:06.502960456 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:06.504328434 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:06.507001080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ab146079d7459b97adb9491ad93fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5276381969451904     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43333205580711365    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10340423136949539    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5276381969451904    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43333205580711365   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10340423136949539   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.43333205580711365, 'test_mse': 0.10340423136949539, 'test_iou': 0.5276381969451904}]\n",
      "MSE value is 0.10340423136949539\n",
      "IoU value is 0.5276381969451904\n",
      "num_param value is 401300\n",
      "Training time: 451.9544720649719\n",
      "Fitness: 13.937943716491294\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS'], fitness: 13.937943716491294, IoU: 0.5276381969451904, FPS: 192.9699170478129, Model Size: 401300\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1470494\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:20:17.988528691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:17.997888073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:17.999580333 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:20:17.000778405 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.5 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.882     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d35b8103c034c9793aae3ad65c6b44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:40:27.593189132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:27.595237532 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:27.596145825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:27.600689411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e3663244074dc39d69d529e206c2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5840741991996765     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4809684753417969     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13850270211696625    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5840741991996765    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4809684753417969    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13850270211696625   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:40:52.461584701 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:52.471265953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:52.474739149 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:40:52.476581100 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0b7c4fb4f4494a99d402f359bd96d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5643430352210999     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4924934506416321     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14447638392448425    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5643430352210999    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4924934506416321    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14447638392448425   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4924934506416321, 'test_mse': 0.14447638392448425, 'test_iou': 0.5643430352210999}]\n",
      "MSE value is 0.14447638392448425\n",
      "IoU value is 0.5643430352210999\n",
      "num_param value is 1470494\n",
      "Training time: 1210.6516761779785\n",
      "Fitness: 12.910556577898264\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 12.910556577898264, IoU: 0.5643430352210999, FPS: 90.89453689854062, Model Size: 1470494\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELRr2arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 20857\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:41:14.608268271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:41:14.608402758 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:41:14.609960914 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:41:14.619676323 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 20.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "20.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.9 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6b918292d34ddebde14120869fee50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:44:44.197916644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:44.199525926 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:44.202427542 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:44.204872841 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6f0f4dabfd41dbae8ef85f4a4a32c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6403869986534119     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3272024095058441     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07908987998962402    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6403869986534119    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3272024095058441    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07908987998962402   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:44:51.722793337 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:51.723743856 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:51.724846816 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:51.726728877 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a743499946e44d269b879459279bc666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6452429294586182     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32625049352645874    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0793486163020134     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6452429294586182    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32625049352645874   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0793486163020134    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32625049352645874, 'test_mse': 0.0793486163020134, 'test_iou': 0.6452429294586182}]\n",
      "MSE value is 0.0793486163020134\n",
      "IoU value is 0.6452429294586182\n",
      "num_param value is 20857\n",
      "Training time: 209.57983350753784\n",
      "Fitness: 15.696419489426047\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 15.696419489426047, IoU: 0.6452429294586182, FPS: 286.8112362227414, Model Size: 20857\n",
      "\n",
      "Architecture: Ldo05agn1EPa2ELbo05k3s1p1arn1EUf2mnearestES0ELdo07arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 28272038 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Uf2mnearest', 'S0', 'Ldo07arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELRr2agn1EPM2ELRr3agn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 81934\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:44:59.037206309 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:59.049507344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:59.050721679 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:44:59.058577357 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 81.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "81.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "81.9 K    Total params\n",
      "0.328     Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2c21d60220476b84bf2b5688c7f409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:48:58.648092007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:48:58.654655713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:48:58.656422827 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:48:58.659699954 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434a64ebf228445c99ca0861811b0629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48329079151153564    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.765609860420227     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40688663721084595    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48329079151153564   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.765609860420227    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40688663721084595   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:49:08.475876344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:08.483503025 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:08.485475618 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:08.493003257 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fad1fa460142bbb53d78cde3da21dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46914708614349365    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7449547052383423     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3878750205039978     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46914708614349365   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7449547052383423    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3878750205039978    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.7449547052383423, 'test_mse': 0.3878750205039978, 'test_iou': 0.46914708614349365}]\n",
      "MSE value is 0.3878750205039978\n",
      "IoU value is 0.46914708614349365\n",
      "num_param value is 81934\n",
      "Training time: 239.61695289611816\n",
      "Fitness: 11.814796594669824\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 11.814796594669824, IoU: 0.46914708614349365, FPS: 222.9736479029211, Model Size: 81934\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELDd0.30n1EPa2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1371368\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 20:49:17.509665482 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:17.511755503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:17.512616076 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 20:49:17.519621558 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.4 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.485     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62000a7b5e57466ebbcd9f71d88b2681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:26:51.204372102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:26:51.213241328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:26:51.216900880 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:26:51.218154825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e399886f0143059b29380b46613d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5209420323371887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4355691373348236     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35596898198127747    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5209420323371887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4355691373348236    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35596898198127747   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:27:20.318866824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:20.318866743 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:20.321497547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:20.326013256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbdea44ba4c4d85adca4a7d0f6d3f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5260797142982483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.444387823343277     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3891415596008301     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5260797142982483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.444387823343277    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3891415596008301    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.444387823343277, 'test_mse': 0.3891415596008301, 'test_iou': 0.5260797142982483}]\n",
      "MSE value is 0.3891415596008301\n",
      "IoU value is 0.5260797142982483\n",
      "num_param value is 1371368\n",
      "Training time: 2253.664979457855\n",
      "Fitness: 11.08811953625925\n",
      "********\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 11.08811953625925, IoU: 0.5260797142982483, FPS: 78.43820396002496, Model Size: 1371368\n",
      "\n",
      "Architecture: Lco10k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES0ELme3arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco10k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 15664048 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco10k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4442\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:27:46.065617131 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:46.067686665 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:46.069642117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:27:46.076921818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 4.4 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e36d700788548a79698ab57b8a214cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:29:09.985951389 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:09.991365719 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:09.992650367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:09.996803259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c97dc9ab5264ffa975b4e23be8e8212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36985448002815247    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4652157723903656     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16049443185329437    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36985448002815247   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4652157723903656    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16049443185329437   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:29:15.453781461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:15.464694445 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:15.469129347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:15.477908343 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e0198f80b84217a1334743967b6006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3820204436779022     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4645398259162903     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1645604372024536     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3820204436779022    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4645398259162903    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1645604372024536    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4645398259162903, 'test_mse': 0.1645604372024536, 'test_iou': 0.3820204436779022}]\n",
      "MSE value is 0.1645604372024536\n",
      "IoU value is 0.3820204436779022\n",
      "num_param value is 4442\n",
      "Training time: 82.89762783050537\n",
      "Fitness: 12.402693334090232\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 12.402693334090232, IoU: 0.3820204436779022, FPS: 320.71903145590574, Model Size: 4442\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES0ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 579714814 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.35n1EUf2mnearestES1ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19380\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:29:26.578821093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:26.590209702 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:26.592202695 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:29:26.600505389 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763ca90e63ea4014b43d73f5830fb084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:30:54.285009949 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:30:54.285694296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:30:54.286938614 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:30:54.289444754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad0d90d88e2478084e891f48f7a6953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.604922890663147     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34930548071861267    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06429331749677658    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.604922890663147    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34930548071861267   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06429331749677658   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:31:00.555615908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:00.566750588 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:00.569698210 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:00.573916176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67a519c9f54f66a81a373e7a10403b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6018528938293457     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3524845838546753     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06542988121509552    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6018528938293457    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3524845838546753    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06542988121509552   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3524845838546753, 'test_mse': 0.06542988121509552, 'test_iou': 0.6018528938293457}]\n",
      "MSE value is 0.06542988121509552\n",
      "IoU value is 0.6018528938293457\n",
      "num_param value is 19380\n",
      "Training time: 87.97060513496399\n",
      "Fitness: 15.385031741388163\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'HS'], fitness: 15.385031741388163, IoU: 0.6018528938293457, FPS: 327.7092506108455, Model Size: 19380\n",
      "\n",
      "For generation 9, the best fitness of the population is 17.619995790185392.\n",
      "The best historical fitness is 17.678311352573793,with the most fit individual having the following genes: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_9.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 10 ***\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2509008\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:31:07.835018601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:07.839581367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:07.843518205 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:31:07.850593455 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.5 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "10.036    Total estimated model params size (MB)\n",
      "93        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f46eb6f056841b6979a5b831c421f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:46:13.349902309 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:13.355529094 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:13.357442178 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:13.362346284 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ebc841bd1945e2bab5a8a7e1a027db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8106913566589355     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3085842430591583     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.047462545335292816    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8106913566589355    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3085842430591583    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.047462545335292816   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:46:38.745834824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:38.747602671 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:38.749101715 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:38.754563080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e7fec10d564e73a6b1b6d1172e4317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8091095089912415     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.30753737688064575    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04659656807780266    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8091095089912415    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.30753737688064575   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04659656807780266   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.30753737688064575, 'test_mse': 0.04659656807780266, 'test_iou': 0.8091095089912415}]\n",
      "MSE value is 0.04659656807780266\n",
      "IoU value is 0.8091095089912415\n",
      "num_param value is 2509008\n",
      "Training time: 906.5532069206238\n",
      "Fitness: 15.136867131247895\n",
      "********\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'], fitness: 15.136867131247895, IoU: 0.8091095089912415, FPS: 93.37010863550468, Model Size: 2509008\n",
      "\n",
      "Architecture: Lne4agn1EPa2ELco04k5s1p2arn1EUf2mnearestES0ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 13976\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:46:59.252496796 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:59.252497012 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:59.257954281 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:46:59.258634374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 14.0 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "14.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 K    Total params\n",
      "0.056     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3733b7194a4452a83f16f0d9be94081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:49:00.942516705 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:00.943388227 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:00.949367819 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:00.952634186 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d63f7760254dd098f82dcb5f62b392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7114879488945007     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3052777647972107     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045295678079128265    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7114879488945007    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3052777647972107    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045295678079128265   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:49:06.772284329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:06.780448032 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:06.781203315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:06.790504261 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702a52f4e957413dbceeb065ceb14598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7042699456214905     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3056321442127228     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04528892785310745    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7042699456214905    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3056321442127228    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04528892785310745   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3056321442127228, 'test_mse': 0.04528892785310745, 'test_iou': 0.7042699456214905}]\n",
      "MSE value is 0.04528892785310745\n",
      "IoU value is 0.7042699456214905\n",
      "num_param value is 13976\n",
      "Training time: 120.6889419555664\n",
      "Fitness: 16.595456379081263\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'HS'], fitness: 16.595456379081263, IoU: 0.7042699456214905, FPS: 361.97838522565524, Model Size: 13976\n",
      "\n",
      "Architecture: LRr4arn1EPM2ELeo09k5s1p2agn1EUf2mnearestES0ELRr2agn1EHSEE\n",
      "Chromosome: ['LRr4arn1', 'PM2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 51876\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:49:11.494932987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:11.508546813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:11.511809882 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:49:11.521359891 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 51.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "51.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.9 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n",
      "54        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e6e418b38c49448c4e7e6f2b5ef1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:51:53.050429885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:53.050429958 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:53.053147652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:53.060808595 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dbf751adc447439a067ff35c4b57df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7066380977630615     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3801259696483612     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07841593027114868    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7066380977630615    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3801259696483612    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07841593027114868   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:51:59.387660939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:59.396137752 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:59.397130781 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:51:59.397366269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6d52fcd3c74d5c852083ee20a741fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.701367199420929     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37442466616630554    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07611561566591263    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.701367199420929    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37442466616630554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07611561566591263   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.37442466616630554, 'test_mse': 0.07611561566591263, 'test_iou': 0.701367199420929}]\n",
      "MSE value is 0.07611561566591263\n",
      "IoU value is 0.701367199420929\n",
      "num_param value is 51876\n",
      "Training time: 161.64525985717773\n",
      "Fitness: 16.254477797559836\n",
      "********\n",
      "chromosome: ['LRr4arn1', 'PM2', 'Leo09k5s1p2agn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'HS'], fitness: 16.254477797559836, IoU: 0.701367199420929, FPS: 334.6901906335033, Model Size: 51876\n",
      "\n",
      "Architecture: LRr2arn1EPa2ELRr4agn1EUf2mnearestES0ELme3agn1EHSEE\n",
      "Chromosome: ['LRr2arn1', 'Pa2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1210\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:52:05.472831125 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:52:05.492631507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:52:05.492983436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:52:05.496055044 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.2 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "55        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc07b54ea3d49279cec9da7cfb80000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:53:44.715822141 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:44.721672704 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:44.722666904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:44.730932591 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33eaae4a72a4b028bb992cc39a5b0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7199690937995911     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3295315206050873     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054122086614370346    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7199690937995911    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3295315206050873    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054122086614370346   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:53:50.581571804 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:50.589249244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:50.594265697 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:50.601411930 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73141ff219f343ae95f6d2f607bb5b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7140132188796997     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32461288571357727    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05147924646735191    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7140132188796997    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32461288571357727   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05147924646735191   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.32461288571357727, 'test_mse': 0.05147924646735191, 'test_iou': 0.7140132188796997}]\n",
      "MSE value is 0.05147924646735191\n",
      "IoU value is 0.7140132188796997\n",
      "num_param value is 1210\n",
      "Training time: 99.28573870658875\n",
      "Fitness: 16.649333386732607\n",
      "********\n",
      "chromosome: ['LRr2arn1', 'Pa2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HS'], fitness: 16.649333386732607, IoU: 0.7140132188796997, FPS: 358.07437393069426, Model Size: 1210\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELRr4agn1EUf2mnearestES0ELco12k5s1p2agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lco12k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2823560\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 21:53:56.280199866 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:56.280334240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:56.281246381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 21:53:56.282043313 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.294    Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0dba37f9944de7bca1cde19587669e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:33:39.373723270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:33:39.376688087 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:33:39.377113164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:33:39.377898810 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b49356a80ca499ab89f176314faefee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6936469674110413     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34858301281929016    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07048509269952774    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6936469674110413    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34858301281929016   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07048509269952774   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:34:22.275542714 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:22.275549465 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:22.276607681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:22.282783963 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492c4233f96e4f31bc889a7e2a3fc64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.674778163433075     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.35517823696136475    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07376445084810257    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.674778163433075    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.35517823696136475   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07376445084810257   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.35517823696136475, 'test_mse': 0.07376445084810257, 'test_iou': 0.674778163433075}]\n",
      "MSE value is 0.07376445084810257\n",
      "IoU value is 0.674778163433075\n",
      "num_param value is 2823560\n",
      "Training time: 2383.0984218120575\n",
      "Fitness: 13.237251127998189\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lco12k5s1p2agn1', 'HS'], fitness: 13.237251127998189, IoU: 0.674778163433075, FPS: 53.712659113259946, Model Size: 2823560\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELDd0.30n1EUf2mnearestES1ELne5arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2146\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:34:59.601052825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:59.608910742 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:59.610331813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:34:59.614026656 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.1 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70fbd1e22a2492b9b1de22d254d11a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:36:40.592898725 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:40.599191525 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:40.600064568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:40.604155253 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4181d583569d4ef8bb4ebdab3d7f6b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6129382252693176     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.38881716132164      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07160750776529312    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6129382252693176    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.38881716132164     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07160750776529312   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:36:46.375547876 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:46.383176903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:46.389278258 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:46.396643214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d4363340ee4b28914486c3e4814e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6095686554908752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.39013591408729553    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07251674681901932    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6095686554908752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.39013591408729553   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07251674681901932   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.39013591408729553, 'test_mse': 0.07251674681901932, 'test_iou': 0.6095686554908752}]\n",
      "MSE value is 0.07251674681901932\n",
      "IoU value is 0.6095686554908752\n",
      "num_param value is 2146\n",
      "Training time: 100.99433875083923\n",
      "Fitness: 15.417404289119926\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'HS'], fitness: 15.417404289119926, IoU: 0.6095686554908752, FPS: 358.9124338099931, Model Size: 2146\n",
      "\n",
      "Architecture: Lne4agn1EPM2ELRr3arn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne4agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2602\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:36:52.279763882 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:52.281457831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:52.281703978 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:36:52.282819052 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.6 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdac4ee5d373479cb618023667e6e7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:38:08.548492156 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:08.568377885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:08.632417715 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:08.632454071 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a712de56218402d95cb1c088c4bd473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6942564249038696     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3411088287830353     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06304421275854111    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6942564249038696    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3411088287830353    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06304421275854111   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:38:14.321342043 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:14.342697842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:14.392414886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:14.392473928 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce713c8c635426aba625dd42d69cddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6871072053909302     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34137725830078125    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06288933008909225    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6871072053909302    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34137725830078125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06288933008909225   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34137725830078125, 'test_mse': 0.06288933008909225, 'test_iou': 0.6871072053909302}]\n",
      "MSE value is 0.06288933008909225\n",
      "IoU value is 0.6871072053909302\n",
      "num_param value is 2602\n",
      "Training time: 76.32986569404602\n",
      "Fitness: 16.27678728592234\n",
      "********\n",
      "chromosome: ['Lne4agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 16.27678728592234, IoU: 0.6871072053909302, FPS: 367.62166286348105, Model Size: 2602\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELRr4agn1EUf2mnearestES0ELne6arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2805\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:38:20.848930605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:20.863226414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:20.924409081 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:38:20.924456505 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.8 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704d4283c1e5416580b313122c5ae543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:39:39.168077414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:39.187034447 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:39.213007466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:39.220512119 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe3f3a06e6c487e8d4832867e36839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6568143367767334     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3476839065551758     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06452186405658722    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6568143367767334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3476839065551758    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06452186405658722   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:39:45.884763912 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:45.891774473 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:45.895750164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:45.902198941 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb61ff2a8f94366801347053207b717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6588669419288635     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34665846824645996    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06365526467561722    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6588669419288635    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34665846824645996   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06365526467561722   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.34665846824645996, 'test_mse': 0.06365526467561722, 'test_iou': 0.6588669419288635}]\n",
      "MSE value is 0.06365526467561722\n",
      "IoU value is 0.6588669419288635\n",
      "num_param value is 2805\n",
      "Training time: 79.32605314254761\n",
      "Fitness: 15.987406753636689\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HS'], fitness: 15.987406753636689, IoU: 0.6588669419288635, FPS: 373.02457603769176, Model Size: 2805\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EUf2mnearestES1ELRr2arn1EHSEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1769\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:39:50.343174686 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:50.347672363 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:50.352810706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:39:50.356424176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.8 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61581664818440c6a84aaa9c128d5051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:40:55.151257102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:40:55.160952477 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:40:55.208430090 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:40:55.208473450 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f2b8ab11ed4d11b25f3da9e341ba47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6105483770370483     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3594416081905365     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0703548938035965     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6105483770370483    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3594416081905365    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0703548938035965    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:41:01.806399726 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:01.836018183 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:01.876386684 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:01.876538720 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4a71082e5b47389bc3355ad5166092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6013734340667725     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3612542450428009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07118870317935944    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6013734340667725    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3612542450428009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07118870317935944   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3612542450428009, 'test_mse': 0.07118870317935944, 'test_iou': 0.6013734340667725}]\n",
      "MSE value is 0.07118870317935944\n",
      "IoU value is 0.6013734340667725\n",
      "num_param value is 1769\n",
      "Training time: 64.82481503486633\n",
      "Fitness: 15.347388660872031\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'HS'], fitness: 15.347388660872031, IoU: 0.6013734340667725, FPS: 372.51826252987024, Model Size: 1769\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELbo12k3s1p1arn1EUf2mnearestES1ELco04k5s1p2arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lbo12k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2424902\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 22:41:06.298351792 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:06.305432609 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:06.356423660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 22:41:06.356457541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 2.4 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.700     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c839fedadaa646d9970107414acb68c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:11:02.423906264 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:02.425004509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:02.449232146 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:02.455595330 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98a68408e19470ab174c46485a40952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5244007110595703     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3928166329860687     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20755963027477264    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5244007110595703    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3928166329860687    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20755963027477264   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:11:46.272556578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:46.285218468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:46.302413165 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:11:46.307770361 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2dd9dea155479c9c7b8e2bcdd3f0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.532426655292511     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3959525227546692     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.21232180297374725    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.532426655292511    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3959525227546692    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.21232180297374725   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3959525227546692, 'test_mse': 0.21232180297374725, 'test_iou': 0.532426655292511}]\n",
      "MSE value is 0.21232180297374725\n",
      "IoU value is 0.532426655292511\n",
      "num_param value is 2424902\n",
      "Training time: 1796.1180183887482\n",
      "Fitness: 11.147999507332962\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lbo12k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 11.147999507332962, IoU: 0.532426655292511, FPS: 52.55491833681052, Model Size: 2424902\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELRr3agn1EUf2mnearestES1ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 13270\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:12:24.413821166 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:12:24.424213444 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:12:24.442878316 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:12:24.450648658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 13.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "13.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 K    Total params\n",
      "0.053     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2f4a7c845e4d0c9fc6ae24a047ada5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:13:46.249388290 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:46.250408142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:46.256313355 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:46.258793529 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d393538158a948a381f29b6ccf69de55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6093701720237732     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43693995475769043    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11052235960960388    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6093701720237732    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43693995475769043   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11052235960960388   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:13:52.413144300 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:52.419238266 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:52.421810339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:52.427021085 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0987b96af141c0bde58103e2c93025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6028813719749451     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.42606115341186523    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1049063429236412     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6028813719749451    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.42606115341186523   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1049063429236412    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.42606115341186523, 'test_mse': 0.1049063429236412, 'test_iou': 0.6028813719749451}]\n",
      "MSE value is 0.1049063429236412\n",
      "IoU value is 0.6028813719749451\n",
      "num_param value is 13270\n",
      "Training time: 81.81274652481079\n",
      "Fitness: 15.066084576940534\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco04k5s1p2agn1', 'HS'], fitness: 15.066084576940534, IoU: 0.6028813719749451, FPS: 342.00543189855847, Model Size: 13270\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 19380\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:13:58.295265808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:58.299992646 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:58.300091245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:13:58.300236539 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 19.4 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "19.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.4 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f6adb3898b43c0a66506338b84053e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:15:26.860148386 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:26.869852568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:26.924426780 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:26.924474884 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4851795b4540cfae18b1e962ce29f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5975072383880615     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.38699647784233093    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08256956189870834    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5975072383880615    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.38699647784233093   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08256956189870834   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:15:32.040236988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:32.051694310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:32.104431050 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:32.104486279 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7ee747291a4f278ab5da5e8cf7b569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6092426180839539     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3926442861557007     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08625850081443787    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6092426180839539    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3926442861557007    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08625850081443787   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3926442861557007, 'test_mse': 0.08625850081443787, 'test_iou': 0.6092426180839539}]\n",
      "MSE value is 0.08625850081443787\n",
      "IoU value is 0.6092426180839539\n",
      "num_param value is 19380\n",
      "Training time: 87.57003164291382\n",
      "Fitness: 15.278958026410697\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 15.278958026410697, IoU: 0.6092426180839539, FPS: 345.5817559240853, Model Size: 19380\n",
      "\n",
      "Architecture: Ldo08agn1EPM2ELco07k3s1p1agn1EUf2mnearestES2ELbo07k3s1p1arn1EHSEE\n",
      "Chromosome: ['Ldo08agn1', 'PM2', 'Lco07k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 12510358 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo08agn1', 'PM2', 'Lco07k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lbo07k3s1p1arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELDd0.35n1EUf2mnearestES0ELdo05agn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18344\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:15:38.045841315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:38.052963985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:38.096424900 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:15:38.096455244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 18.3 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "18.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.3 K    Total params\n",
      "0.073     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bfd45c9a92433eac95a7a58a525bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:17:38.353185536 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:38.366155013 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:38.383154446 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:38.385846080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c15e307b43432580a159622075fae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3440394699573517     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.913414716720581     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3375385105609894     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3440394699573517    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.913414716720581    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3375385105609894    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:17:44.086683710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:44.086722539 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:44.111245486 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:44.120849075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af374c14feb84ec887e8fe5f4d302c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33815476298332214    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9152286052703857     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3390240967273712     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33815476298332214   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9152286052703857    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3390240967273712    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9152286052703857, 'test_mse': 0.3390240967273712, 'test_iou': 0.33815476298332214}]\n",
      "MSE value is 0.3390240967273712\n",
      "IoU value is 0.33815476298332214\n",
      "num_param value is 18344\n",
      "Training time: 120.30917072296143\n",
      "Fitness: 10.831329128426114\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo05agn1', 'HS'], fitness: 10.831329128426114, IoU: 0.33815476298332214, FPS: 367.56177333160167, Model Size: 18344\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES1ELme3arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4442\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:17:49.623993342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:49.636612953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:49.641843531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:17:49.651547328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 4.4 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b455e8a6d44c888bdd3c4bd0a87b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:19:12.221545414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:12.232826270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:12.235645065 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:12.238419354 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42124802c91495c9a58c0c49e36d1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49260225892066956    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3943544030189514     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14220936596393585    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49260225892066956   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3943544030189514    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14220936596393585   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:19:18.514652374 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:18.523215961 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:18.525675582 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:18.531429722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58789c2591114d77af7fba7897abff56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5062063932418823     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3895682096481323     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14596956968307495    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5062063932418823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3895682096481323    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14596956968307495   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.3895682096481323, 'test_mse': 0.14596956968307495, 'test_iou': 0.5062063932418823}]\n",
      "MSE value is 0.14596956968307495\n",
      "IoU value is 0.5062063932418823\n",
      "num_param value is 4442\n",
      "Training time: 82.6133987903595\n",
      "Fitness: 13.783857134951788\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HS'], fitness: 13.783857134951788, IoU: 0.5062063932418823, FPS: 336.7035769472864, Model Size: 4442\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELRr2agn1EPM2ELRr3agn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELme3arn1EHSEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 81934\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:19:24.556731670 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:24.557700289 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:24.563709744 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:19:24.564537463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 81.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "81.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "81.9 K    Total params\n",
      "0.328     Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82b4c03137b472c97b4a9149158ade4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:23:23.580451874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:23.584731990 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:23.628443606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:23.628478703 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392106f2797d42d181b24c3f2f9bfe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49462515115737915    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6353616714477539     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3118877112865448     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49462515115737915   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6353616714477539    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3118877112865448    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:23:33.245730036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:33.266571803 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:33.316440851 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:33.316455118 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523e96d2bcd449a5962ab2bce1ec0cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.47870635986328125    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.615332841873169     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.29382216930389404    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.47870635986328125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.615332841873169    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.29382216930389404   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.615332841873169, 'test_mse': 0.29382216930389404, 'test_iou': 0.47870635986328125}]\n",
      "MSE value is 0.29382216930389404\n",
      "IoU value is 0.47870635986328125\n",
      "num_param value is 81934\n",
      "Training time: 239.03239130973816\n",
      "Fitness: 12.434167048485932\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'LRr2agn1', 'PM2', 'LRr3agn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HS'], fitness: 12.434167048485932, IoU: 0.47870635986328125, FPS: 226.36707926461614, Model Size: 81934\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELDd0.35n1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELco04k5s1p2agn1EHSEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 9750626\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W821 23:23:42.279989028 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:42.317564520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:42.364457090 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W821 23:23:42.364498661 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 9.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "9.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 M     Total params\n",
      "39.003    Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd15e4def195428d998c5a1c75b78df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:47:34.422224358 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:47:34.435867688 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:47:34.459826867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:47:34.464844214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32b046109a14d1ebbd5174087f1f8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7043112516403198     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3879888653755188     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08689218014478683    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7043112516403198    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3879888653755188    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08689218014478683   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:49:53.878956218 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:49:53.895250860 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:49:53.907908507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:49:53.910542693 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc0ace5625c4166939454b4e3db2b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6856836676597595     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40365785360336304    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0941857174038887     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6856836676597595    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40365785360336304   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0941857174038887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.40365785360336304, 'test_mse': 0.0941857174038887, 'test_iou': 0.6856836676597595}]\n",
      "MSE value is 0.0941857174038887\n",
      "IoU value is 0.6856836676597595\n",
      "num_param value is 9750626\n",
      "Training time: 12232.14400434494\n",
      "Fitness: 6.245427028028708\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HS'], fitness: 6.245427028028708, IoU: 0.6856836676597595, FPS: 16.80979523223755, Model Size: 9750626\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELdo06arn1EHSEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27892\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:51:52.003194988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:51:52.013350535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:51:52.020046692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:51:52.023735811 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 27.9 K | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "27.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.9 K    Total params\n",
      "0.112     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabd1412c7604eddb40667c399514cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:53:34.071170492 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:34.087663305 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:34.116414153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:34.116463526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e157698f98844f01a2f34fe6715102e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4947201907634735     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40880489349365234    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11670637875795364    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4947201907634735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40880489349365234   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11670637875795364   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:53:40.709143723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:40.722304699 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:41.764425123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:41.764453434 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b566a4df0bcc4be4a9320a6639947c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4791508615016937     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4053177535533905     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11723113059997559    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4791508615016937    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4053177535533905    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11723113059997559   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.4053177535533905, 'test_mse': 0.11723113059997559, 'test_iou': 0.4791508615016937}]\n",
      "MSE value is 0.11723113059997559\n",
      "IoU value is 0.4791508615016937\n",
      "num_param value is 27892\n",
      "Training time: 102.30287837982178\n",
      "Fitness: 13.71431600577756\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HS'], fitness: 13.71431600577756, IoU: 0.4791508615016937, FPS: 321.3825343474718, Model Size: 27892\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco10k3s1p1agn1EPM2ELdo05arn1EUf2mnearestES1ELdo05agn1EUf2mnearestES0ELne5arn1EHSEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 71868146 exceed the threshold of 10000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo05arn1', 'Uf2mnearest', 'S1', 'Ldo05agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HS'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo05agn1EPM2ELDd0.35n1EUf2mnearestES0ELco10k3s1p1agn1EHSEE\n",
      "Chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1751978\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 02:53:48.846070008 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:48.847886994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:48.908448616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 02:53:48.908476566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 1.8 M  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.008     Total estimated model params size (MB)\n",
      "22        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae68f90e8bcb4c899206d24c7126b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 03:14:25.380361912 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:25.396321670 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:25.414770913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:25.416639514 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cef8616bab40068375249570366c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5563527345657349     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5539623498916626     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17418910562992096    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5563527345657349    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5539623498916626    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17418910562992096   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 03:14:55.241292061 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:55.241424359 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:55.262328765 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:14:55.267882044 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83493c1678a54f4c926ac368b3a0b6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5329456329345703     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5660396814346313     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18003752827644348    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5329456329345703    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5660396814346313    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18003752827644348   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.5660396814346313, 'test_mse': 0.18003752827644348, 'test_iou': 0.5329456329345703}]\n",
      "MSE value is 0.18003752827644348\n",
      "IoU value is 0.5329456329345703\n",
      "num_param value is 1751978\n",
      "Training time: 1237.724835395813\n",
      "Fitness: 12.05178508686548\n",
      "********\n",
      "chromosome: ['Ldo05agn1', 'PM2', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco10k3s1p1agn1', 'HS'], fitness: 12.05178508686548, IoU: 0.5329456329345703, FPS: 76.78885333679865, Model Size: 1751978\n",
      "\n",
      "THE LAST GENERATION (10):\n",
      "For generation 10, the best fitness of the population is 16.649333386732607.\n",
      "The best historical fitness is 17.678311352573793,with the most fit individual having the following genes: ['Lne4agn1', 'PM2', 'Lme6agn1', 'Pa2', 'LRr3arn1', 'PM2', 'Lbo08k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme6agn1', 'Uf2mnearest', 'S0', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr4arn1', 'HS'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_10.txt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAS completed. Best architecture: Lne4agn1EPM2ELme6agn1EPa2ELRr3arn1EPM2ELbo08k5s1p2agn1EUf2mnearestES1ELme6agn1EUf2mnearestES0ELne3arn1EUf2mnearestES0ELRr4arn1EHSEE\n",
      "Process finished in 121740.51037311554 s. Starting final run...\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "\n",
      "FINAL RUN ON OPTIMIZED ARCHITECTURE\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 108414\n",
      "Running in final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 03:15:23.222998417 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:15:23.232732116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:15:23.238785999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:15:23.241352337 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | GenericNetwork   | 108 K  | train\n",
      "1 | loss_fn | FocalLoss        | 0      | train\n",
      "2 | mse     | MeanSquaredError | 0      | train\n",
      "-----------------------------------------------------\n",
      "108 K     Trainable params\n",
      "0         Non-trainable params\n",
      "108 K     Total params\n",
      "0.434     Total estimated model params size (MB)\n",
      "103       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3609808a160421bba2e842453e02cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 03:18:44.163074793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:44.164035407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:44.166112369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:44.173256590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf783cd2815a4eb698028c580ec63a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7890181541442871     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3169928789138794     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.051849670708179474    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7890181541442871    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3169928789138794    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.051849670708179474   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W822 03:18:51.251391890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:51.258953571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:51.258956597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W822 03:18:51.263064504 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62af728d81844fea4930aac5adc0935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7835386991500854     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31270045042037964    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04906309023499489    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7835386991500854    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31270045042037964   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04906309023499489   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE value is 0.04906309023499489\n",
      "IoU value is 0.7835386991500854\n",
      "num_param value is 108414\n",
      "FINAL RUN COMPLETED:\n",
      "Training time: 201.2375853061676\n",
      "Fitness: 17.25928815260328\n",
      "********\n",
      "\n",
      "Final run text file saved: ./logs/tb_logs/checkpoints/Optimized_Architecture_Final_Run_2024-08-22_03-15-22.txt\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO CONFIG.INI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: most sanity checks are still missing. Be careful please."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the [Mode] section, select the desired mode for pynattas. If both are true, nas will be done first, then ht will be done on the winning architecture of nas. If only ht is true, then tuning will be done on the architecture written in architecture_code under the [NAS] section.\n",
    "- max_layers in [NAS] section refers to the maximum size of the chromosomes (aka, maximum number of convolutions-type layers).\n",
    "- In the [GA] section, change the parameters for NAS search.\n",
    "- In the [Computation] section, be careful about the num_workers value. Currently set to 1 for safety when testing parallelization. In computation, also change the accellerator to either \"cpu\" or \"gpu\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO PARALLELIZATION (currently broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Mostly untested.\n",
    "- In main.py, change line 54 (\"nas_result = pnas.optimizers.ga.ga_optimizer(\") to:\n",
    "    - nas_result = pnas.optimizers.ga_concurrent.ga_optimizer(\" for nas parallelization using a ThreadPoolExecutor\n",
    "    - nas_result = pnas.optimizers.ga_concurrent_pp.ga_optimizer(\" for nas parallelization using a ProcessPoolExecutor\n",
    "\n",
    "Currently, it looks like there are issues with ProcessPoolExecutor. Regardless, be careful when selecting num_workers in the config.ini when testing these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO ADD NEW BLOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in pynattas.blocks add the new block to the related .py file depending on type.\n",
    "- in config.ini add the new block as a section with all related parameters. Use \"default_\" for default values that are used during NAS, and \"min_\" and \"max_\" for range values to be used during tuning. Also, update the commented vocabulary at the start for clarity purposes.\n",
    "- in pynattas.configuration.vocabulary, update relative vocabularies.\n",
    "- in pynattas.classes.generic_network, add the layer construction to the list making sure that the current_layers, current_height, and current_width is calculated correctly.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO WORK ON NEW DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add dataset to the \"data\" folder\n",
    "- Add compatible datamodule to the \"datasets\" folder\n",
    "- in pynattas.functions.fitness, import the desired datamodule. Also, around line 59, update the datahandling to be compatible with your datamodule. For the ClassificationHead, Make sure the data is resized to 256x256 sized HxW images, that the number of channels passed to the model is correct.\n",
    "- change config.ini in the [Dataset] section. \"data_path\" should point to the dataset, \"csv_path\" is for a .csv for labels if required. If it's not required, imput None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO LOGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs are stored in the \"logs\" folder and in the \"lightning_logs\" folder. In \"logs\", you will find:\n",
    "- logs about NAS iterations and results in the GA_logs subfolder\n",
    "- logs about HT iterations and results in either the GWO_logs or PSO_logs subfolder depending on the selected HT algorithm\n",
    "- logs about the final run comprised of the saved checkpoint .ckpt file in the \"tb_logs\" subfolder, together with all the confusion matrixes generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE (Coming soon...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
