{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Pynattas (old version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: assuming dependencies already in place. A guide for dependencies will be created on a later date. For now, make sure to have the latest compatible versions of:\n",
    "- pytorch and pytorch lightning, torchmetrics and torchvision, cuda\n",
    "- tensorflow and tensorboard\n",
    "- tqdm\n",
    "- datetime\n",
    "- matplotlib and numpy\n",
    "\n",
    "Solve any further incompatibilities as they are raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code with current configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: There are possible combinations of blocks that will crash the run. A saner block selection logic will be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard tensorboardX\n",
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynattas as pnas\n",
    "import torch\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Network Architecture Search ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chromosome pool:\n",
      "Architecture: Lco05k5s1p2agn1EPM2ELeo09k3s1p1agn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'PM2', 'Leo09k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 12526220 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2agn1', 'PM2', 'Leo09k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELeo10k3s1p1agn1EPa2ELRr2arn1EUf2mnearestES1ELeo10k3s1p1agn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Leo10k3s1p1agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 73832542 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Leo10k3s1p1agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 857212\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:32:48.265121660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.273538706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.292180327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.302222353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 857 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "857 K     Trainable params\n",
      "0         Non-trainable params\n",
      "857 K     Total params\n",
      "3.429     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9def9092480d4fc1896abae62d9e14b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:46:55.106376010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.119434068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.184409918 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.184455339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a867b837f173458eb19e4a5bb99a2d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7712280750274658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9056116342544556     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1125316247344017     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7712280750274658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9056116342544556    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1125316247344017    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:47:12.991074479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.005128139 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.048403622 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.048443617 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941c0a3fef4a43c1ab6284b344961b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7479709982872009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9219234585762024     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12203318625688553    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7479709982872009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9219234585762024    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12203318625688553   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9219234585762024, 'test_mse': 0.12203318625688553, 'test_iou': 0.7479709982872009}]\n",
      "MSE value is 0.12203318625688553\n",
      "IoU value is 0.7479709982872009\n",
      "num_param value is 857212\n",
      "Training time: 847.482387304306\n",
      "Fitness: 15.53489034566843\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.53489034566843, IoU: 0.7479709982872009, FPS: 134.66454063656684, Model Size: 857212\n",
      "\n",
      "Architecture: Lme3agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27024\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:47:27.934823878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.955251517 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.988398236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.988430987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.0 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.0 K    Total params\n",
      "0.108     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062d545b4f094f5a97a8913993d4b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:08.716114957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.716321952 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.719653630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.726814625 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28da911faf7c4503a52e9f21f33fe2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7175394892692566     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.855086624622345     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05018816515803337    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7175394892692566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.855086624622345    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05018816515803337   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:14.626298514 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.630881429 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.654446170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.656787283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e985e83e09e431982912dca8ec4269a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.708678662776947     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8545005321502686     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04944255203008652    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.708678662776947    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8545005321502686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04944255203008652   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8545005321502686, 'test_mse': 0.04944255203008652, 'test_iou': 0.708678662776947}]\n",
      "MSE value is 0.04944255203008652\n",
      "IoU value is 0.708678662776947\n",
      "num_param value is 27024\n",
      "Training time: 220.76591396331787\n",
      "Fitness: 16.588631054779196\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: 16.588631054779196, IoU: 0.708678662776947, FPS: 363.4946603133376, Model Size: 27024\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:19.235805392 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.242841834 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.250233228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.250718141 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c41c41a758a4c6c8c278f92888bd1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:55:52.568293315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569084372 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569099433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569504989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab27ff48be14c2ca60e6451ceb36e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.767717719078064     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9203417301177979     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08647586405277252    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.767717719078064    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9203417301177979    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08647586405277252   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:55:59.427156148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.428111109 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.428693587 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.431000573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9b801c3f054ee0a7a4f4508662bc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7573432326316833     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9314648509025574     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09170122444629669    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7573432326316833    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9314648509025574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09170122444629669   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9314648509025574, 'test_mse': 0.09170122444629669, 'test_iou': 0.7573432326316833}]\n",
      "MSE value is 0.09170122444629669\n",
      "IoU value is 0.7573432326316833\n",
      "num_param value is 155516\n",
      "Training time: 272.31300687789917\n",
      "Fitness: 16.57793170055252\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.57793170055252, IoU: 0.7573432326316833, FPS: 281.2294427896797, Model Size: 155516\n",
      "\n",
      "Architecture: Lco09k5s1p2arn1EPa2ELeo05k5s1p2agn1EUf2mnearestES0ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 22854384 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.28n1EPM2ELdo08agn1EPM2ELRr3arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELDd0.28n1EHSasmEE\n",
      "Chromosome: ['LDd0.28n1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LDd0.28n1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3190430\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:56:07.865988635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.874702365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.932410402 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.932454163 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.762    Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f89116f0f854e81add48baa79cac12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:37:03.158565631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.180562690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.203799652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.206610955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b5d3ac4d43479b9ea06c4efcb13811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5179244875907898     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1692701578140259     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3584161698818207     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5179244875907898    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1692701578140259    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3584161698818207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:37:45.680549024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.682149070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.691880979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.695050861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a9ebc4ae7b4accbd1472d7e0bba98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5040837526321411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1736341714859009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3841129541397095     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5040837526321411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1736341714859009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3841129541397095    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1736341714859009, 'test_mse': 0.3841129541397095, 'test_iou': 0.5040837526321411}]\n",
      "MSE value is 0.3841129541397095\n",
      "IoU value is 0.5040837526321411\n",
      "num_param value is 3190430\n",
      "Training time: 2456.3301653862\n",
      "Fitness: 9.07525140202624\n",
      "********\n",
      "chromosome: ['LDd0.28n1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LDd0.28n1', 'HSasm'], fitness: 9.07525140202624, IoU: 0.5040837526321411, FPS: 55.789499845675536, Model Size: 3190430\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:38:21.653297367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.654625618 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.665053112 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.666936160 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bafb2a0d01048c086219f4fa411cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:25.405577609 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.407114543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.407907741 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.408448564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c037f4d93a84e91b416f39cc41168a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7331038117408752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8674980998039246     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.057588350027799606    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7331038117408752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8674980998039246    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.057588350027799606   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:31.632722798 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.640428310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.640428352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.647472538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271b89f509084ffeb709f3d0e896aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7281439304351807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8588637113571167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052786875516176224    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7281439304351807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8588637113571167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052786875516176224   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8588637113571167, 'test_mse': 0.052786875516176224, 'test_iou': 0.7281439304351807}]\n",
      "MSE value is 0.052786875516176224\n",
      "IoU value is 0.7281439304351807\n",
      "num_param value is 18862\n",
      "Training time: 184.8819441795349\n",
      "Fitness: 16.761175959561154\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 16.761175959561154, IoU: 0.7281439304351807, FPS: 405.26818180632347, Model Size: 18862\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES0ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:36.664343660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.669079016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.669210421 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.678178050 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa544cbc0844ae289250f5464a88f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:53:42.212911751 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.213871733 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.215844828 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.220198886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cc3e31130e497dab1b5cf3ec7c80f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7589005827903748     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8628867268562317     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05386950448155403    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7589005827903748    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8628867268562317    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05386950448155403   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:53:55.277674214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.293429410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.294343352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.298394710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcf938e258645d496108f729d075ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7478986978530884     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.867072582244873     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05581127852201462    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7478986978530884    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.867072582244873    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05581127852201462   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.867072582244873, 'test_mse': 0.05581127852201462, 'test_iou': 0.7478986978530884}]\n",
      "MSE value is 0.05581127852201462\n",
      "IoU value is 0.7478986978530884\n",
      "num_param value is 189886\n",
      "Training time: 726.5062062740326\n",
      "Fitness: 16.760490613616593\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm'], fitness: 16.760490613616593, IoU: 0.7478986978530884, FPS: 172.48639958599685, Model Size: 189886\n",
      "\n",
      "Architecture: Lbo15k5s1p2arn1EPM2ELeo08k5s1p2agn1EUf2mnearestES0ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo15k5s1p2arn1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 266925960 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo15k5s1p2arn1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES2ELDd0.30n1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 28910568 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELDd0.50n1EPM2ELdo13agn1EUf2mnearestES1ELDd0.50n1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LDd0.50n1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 30169930 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LDd0.50n1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELne3arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 129322\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:54:10.917835729 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.933905433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.984475396 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.984493880 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 129 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4a0736cf3b4230a618a08138cf8700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:03:48.030867486 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.049322628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.054848553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.061400055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dafed8db404affb7dbe1fb5b93fea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8053724765777588     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8387914896011353     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054916366934776306    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8053724765777588    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8387914896011353    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054916366934776306   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:03:59.855234223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.862962026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.890734134 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.892905377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab353763aa1146efaf4ed4fbfb9be1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8004068732261658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8343129754066467     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.051597580313682556    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8004068732261658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8343129754066467    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.051597580313682556   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8343129754066467, 'test_mse': 0.051597580313682556, 'test_iou': 0.8004068732261658}]\n",
      "MSE value is 0.051597580313682556\n",
      "IoU value is 0.8004068732261658\n",
      "num_param value is 129322\n",
      "Training time: 578.4766125679016\n",
      "Fitness: 17.38408774559595\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 17.38408774559595, IoU: 0.8004068732261658, FPS: 205.8732752859242, Model Size: 129322\n",
      "\n",
      "Architecture: Leo15k3s1p1arn1EPM2ELbo08k3s1p1agn1EUf2mnearestES0ELeo15k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 115929030 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco10k5s1p2agn1EPM2ELRr3agn1EPa2ELme3agn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco10k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco10k5s1p2agn1', 'PM2', 'LRr3agn1', 'Pa2', 'Lme3agn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco10k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 5696410 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco10k5s1p2agn1', 'PM2', 'LRr3agn1', 'Pa2', 'Lme3agn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco10k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne4arn1EPa2ELco09k5s1p2arn1EPa2ELne3agn1EPa2ELme6arn1EUf2mnearestES2ELne3agn1EUf2mnearestES1ELco09k5s1p2arn1EUf2mnearestES0ELne4arn1EHSasmEE\n",
      "Chromosome: ['Lne4arn1', 'Pa2', 'Lco09k5s1p2arn1', 'Pa2', 'Lne3agn1', 'Pa2', 'Lme6arn1', 'Uf2mnearest', 'S2', 'Lne3agn1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne4arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 6517809 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne4arn1', 'Pa2', 'Lco09k5s1p2arn1', 'Pa2', 'Lne3agn1', 'Pa2', 'Lme6arn1', 'Uf2mnearest', 'S2', 'Lne3agn1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne4arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo07k5s1p2arn1EPa2ELne6agn1EPM2ELbo09k5s1p2agn1EPM2ELbo06k5s1p2arn1EUf2mnearestES2ELbo09k5s1p2agn1EUf2mnearestES1ELne6agn1EUf2mnearestES0ELeo07k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo07k5s1p2arn1', 'Pa2', 'Lne6agn1', 'PM2', 'Lbo09k5s1p2agn1', 'PM2', 'Lbo06k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne6agn1', 'Uf2mnearest', 'S0', 'Leo07k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 29757847 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo07k5s1p2arn1', 'Pa2', 'Lne6agn1', 'PM2', 'Lbo09k5s1p2agn1', 'PM2', 'Lbo06k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne6agn1', 'Uf2mnearest', 'S0', 'Leo07k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.39n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES2ELme6agn1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.39n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'Lme6agn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3108\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:04:10.222278154 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.226157615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.268435801 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.268486623 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.1 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c281a39f9849edb154f040caaf59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:32.942618334 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.962522604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.968303409 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.968670153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca11e5bc48e34d26ad91a122123d7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.574451744556427     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1066254377365112     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17277945578098297    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.574451744556427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1066254377365112    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17277945578098297   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:37.932210188 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.933675369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.934661286 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.938728713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c36ae36964d67a1937887a61427be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5718826055526733     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1178900003433228     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17829488217830658    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5718826055526733    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1178900003433228    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17829488217830658   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1178900003433228, 'test_mse': 0.17829488217830658, 'test_iou': 0.5718826055526733}]\n",
      "MSE value is 0.17829488217830658\n",
      "IoU value is 0.5718826055526733\n",
      "num_param value is 3108\n",
      "Training time: 81.93872928619385\n",
      "Fitness: 14.20255793852195\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.39n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'Lme6agn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 14.20255793852195, IoU: 0.5718826055526733, FPS: 431.22873185788535, Model Size: 3108\n",
      "\n",
      "Architecture: Lbo06k5s1p2agn1EPM2ELRr2agn1EPa2ELco16k5s1p2agn1EPM2ELbo13k5s1p2agn1EUf2mnearestES2ELco16k5s1p2agn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELbo06k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lbo06k5s1p2agn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco16k5s1p2agn1', 'PM2', 'Lbo13k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco16k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo06k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 147490470 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo06k5s1p2agn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco16k5s1p2agn1', 'PM2', 'Lbo13k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco16k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo06k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.40n1EPM2ELme3arn1EUf2mnearestES0ELDd0.40n1EHSasmEE\n",
      "Chromosome: ['LDd0.40n1', 'PM2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1110\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:43.019880579 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.050562853 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.120524364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.120524382 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.1 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1380529b24405ba1221b6444a5747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:44.264312371 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.267353983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.272863886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.281501690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455dec8513a2489eaab67bc4cf9e3ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.449891597032547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1905184984207153     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19179224967956543    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.449891597032547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1905184984207153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19179224967956543   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:49.966666864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.978881694 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.991112518 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.992764932 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca07e256eee4720abbf48a9daf42fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4438057839870453     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1956515312194824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19484706223011017    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4438057839870453    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1956515312194824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19484706223011017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1956515312194824, 'test_mse': 0.19484706223011017, 'test_iou': 0.4438057839870453}]\n",
      "MSE value is 0.19484706223011017\n",
      "IoU value is 0.4438057839870453\n",
      "num_param value is 1110\n",
      "Training time: 61.43058490753174\n",
      "Fitness: 12.806219787809633\n",
      "********\n",
      "chromosome: ['LDd0.40n1', 'PM2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm'], fitness: 12.806219787809633, IoU: 0.4438057839870453, FPS: 455.6030002009548, Model Size: 1110\n",
      "\n",
      "Text file saved: ./logs/GA_logs/GA_generation_0.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 1 ***\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:54.703126563 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.707844391 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.776412364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.776515957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3633db7b76477d9ab1ed30707bd576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:22.942807369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.948154748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.967361358 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.975719269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c06b76d11d4a19815e9e95b9606e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6555923819541931     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0221272706985474     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13613061606884003    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6555923819541931    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0221272706985474    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13613061606884003   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:27.200638628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.217590171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.240737963 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.250554244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1caf38210e842289c3d83466381013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6471068859100342     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.016931414604187     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13348297774791718    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6471068859100342    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.016931414604187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13348297774791718   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.016931414604187, 'test_mse': 0.13348297774791718, 'test_iou': 0.6471068859100342}]\n",
      "MSE value is 0.13348297774791718\n",
      "IoU value is 0.6471068859100342\n",
      "num_param value is 18862\n",
      "Training time: 148.26383066177368\n",
      "Fitness: 15.274571373006578\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.274571373006578, IoU: 0.6471068859100342, FPS: 404.7812062339122, Model Size: 18862\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES0ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:32.278051479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.281733763 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.336433547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.336484984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feffe8b7dbf24b129b75994a52a86354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:21:39.576358681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.587919424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.603991499 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.606611630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f7aeee8ed34060a135b231c6804b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7696115374565125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8554146885871887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05176108703017235    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7696115374565125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8554146885871887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05176108703017235   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:21:52.655028285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.672557361 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.676276144 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.678762074 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0030beb7c1b24b9195098e276796a4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7664128541946411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.853529155254364     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05047934502363205    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7664128541946411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.853529155254364    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05047934502363205   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.853529155254364, 'test_mse': 0.05047934502363205, 'test_iou': 0.7664128541946411}]\n",
      "MSE value is 0.05047934502363205\n",
      "IoU value is 0.7664128541946411\n",
      "num_param value is 189886\n",
      "Training time: 726.3131926059723\n",
      "Fitness: 16.993706249036276\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm'], fitness: 16.993706249036276, IoU: 0.7664128541946411, FPS: 172.79946672527853, Model Size: 189886\n",
      "\n",
      "Architecture: Lme3agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27024\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:22:03.330555101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.331814561 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.352823007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.356904994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.0 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.0 K    Total params\n",
      "0.108     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ce8be23b0433eae9763d73c00faba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:08.423361890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.426320805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.427103407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.428404533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55052894dcb44a338474fc23fffec737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7640599012374878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8465728163719177     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04766015335917473    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7640599012374878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8465728163719177    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04766015335917473   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:15.461053229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.461765991 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.462940243 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.471904344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622f313c417e402295a266ba201ec379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7568902373313904     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.839374840259552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04388625919818878    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7568902373313904    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.839374840259552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04388625919818878   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.839374840259552, 'test_mse': 0.04388625919818878, 'test_iou': 0.7568902373313904}]\n",
      "MSE value is 0.04388625919818878\n",
      "IoU value is 0.7568902373313904\n",
      "num_param value is 27024\n",
      "Training time: 245.0867509841919\n",
      "Fitness: 17.121466103188823\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: 17.121466103188823, IoU: 0.7568902373313904, FPS: 358.3099129623739, Model Size: 27024\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:20.185189822 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.194953223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.196904092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.201861616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce2338f05a7406ab7c182e50cb2af6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:33.820231146 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.822147967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.823245865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.830429213 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64a5cc8a64844cb8de15b71fde1fff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8025988340377808     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8696420192718506     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06096779182553291    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8025988340377808    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8696420192718506    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06096779182553291   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:41.906065983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.906905401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.907049164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.910872594 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafc90a5f17d4b1abe7a8e01699f8d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7881118059158325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8763682246208191     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0641445443034172     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7881118059158325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8763682246208191    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0641445443034172    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8763682246208191, 'test_mse': 0.0641445443034172, 'test_iou': 0.7881118059158325}]\n",
      "MSE value is 0.0641445443034172\n",
      "IoU value is 0.7881118059158325\n",
      "num_param value is 155516\n",
      "Training time: 372.6139988899231\n",
      "Fitness: 17.122821688326226\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 17.122821688326226, IoU: 0.7881118059158325, FPS: 268.1744386008166, Model Size: 155516\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 857212\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:48.417225888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:48.417573605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:49.464408698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:49.464452775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 857 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "857 K     Trainable params\n",
      "0         Non-trainable params\n",
      "857 K     Total params\n",
      "3.429     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec3a86477749e1b92f4330fa9cb053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:46:55.959899846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.963261606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.985854717 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.994892042 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30521322b9b04e808eb8b0778f4189a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7760270833969116     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8850160241127014     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10006896406412125    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7760270833969116    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8850160241127014    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10006896406412125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:47:12.924992191 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.954028180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.965585984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.970498076 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c662a3204b4803b8f44a4da5be90cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7684730291366577     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8741776347160339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09866837412118912    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7684730291366577    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8741776347160339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09866837412118912   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8741776347160339, 'test_mse': 0.09866837412118912, 'test_iou': 0.7684730291366577}]\n",
      "MSE value is 0.09866837412118912\n",
      "IoU value is 0.7684730291366577\n",
      "num_param value is 857212\n",
      "Training time: 846.5568082332611\n",
      "Fitness: 15.929445893495721\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.929445893495721, IoU: 0.7684730291366577, FPS: 133.6995172279934, Model Size: 857212\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES2ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:47:27.995200563 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.006020537 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.027911443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.035911101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c2e49a159d4d769565a110b798bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:06.196278269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.197098088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.199061124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.201929959 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dc34b5196047dd906ade84ca6555cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7301934361457825     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8738117814064026     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06117952615022659    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7301934361457825    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8738117814064026    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06117952615022659   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:11.455558817 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.470810092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.470822194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.479889724 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f287f95dc5420889aa29aea1ea7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.716360330581665     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.873680830001831     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06103265658020973    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.716360330581665    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.873680830001831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06103265658020973   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.873680830001831, 'test_mse': 0.06103265658020973, 'test_iou': 0.716360330581665}]\n",
      "MSE value is 0.06103265658020973\n",
      "IoU value is 0.716360330581665\n",
      "num_param value is 2855\n",
      "Training time: 99.1759283542633\n",
      "Fitness: 16.585528907980933\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.585528907980933, IoU: 0.716360330581665, FPS: 411.84894055513195, Model Size: 2855\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELme3arn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91684\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:16.410407386 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.410875171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.444399189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.444455953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.7 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.7 K    Total params\n",
      "0.367     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f579fe6ad0a2402c91ce9bdcf2c7e206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:10.456511875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.470724580 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.482578667 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.483941694 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d29e6b194b04a418ce3df0cdcf3b4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6319677829742432     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9113056659698486     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08100445568561554    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6319677829742432    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9113056659698486    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08100445568561554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:15.241091273 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.261956443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.263940163 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.266796158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11a8a585ef3490ab4c307958e0efd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6134526133537292     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9139183759689331     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0822879821062088     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6134526133537292    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9139183759689331    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0822879821062088    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9139183759689331, 'test_mse': 0.0822879821062088, 'test_iou': 0.6134526133537292}]\n",
      "MSE value is 0.0822879821062088\n",
      "IoU value is 0.6134526133537292\n",
      "num_param value is 91684\n",
      "Training time: 173.07466959953308\n",
      "Fitness: 15.28252710217133\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.28252710217133, IoU: 0.6134526133537292, FPS: 375.8220736007713, Model Size: 91684\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPM2ELdo08agn1EPM2ELRr3arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 23784678 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELne3arn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 445414\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:21.880719285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.892576194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.917588512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.926710945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 445 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "445 K     Trainable params\n",
      "0         Non-trainable params\n",
      "445 K     Total params\n",
      "1.782     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8255a2b09a42d48fc898dc715a86a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:04.264097296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.266837342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.269819143 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.275619831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458c85fd24948189450a7c5a818f9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7328166961669922     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8875967860221863     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0706053376197815     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7328166961669922    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8875967860221863    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0706053376197815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:16.196394979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.202286852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.204248005 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.211238422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d058e7e33d1c4361923703da87b76210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7281855344772339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8844615817070007     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06893975287675858    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7281855344772339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8844615817070007    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06893975287675858   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8844615817070007, 'test_mse': 0.06893975287675858, 'test_iou': 0.7281855344772339}]\n",
      "MSE value is 0.06893975287675858\n",
      "IoU value is 0.7281855344772339\n",
      "num_param value is 445414\n",
      "Training time: 823.3432140350342\n",
      "Fitness: 16.191505531587115\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: 16.191505531587115, IoU: 0.7281855344772339, FPS: 188.5925089596307, Model Size: 445414\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 40213537 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco09k5s1p2arn1EPa2ELeo05k5s1p2agn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 10694754 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELeo08k5s1p2agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7541748 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES0ELDd0.30n1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 28910568 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELdo12agn1EPM2ELdo13agn1EUf2mnearestES0ELeo15k3s1p1arn1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 24367770 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo15k3s1p1arn1EPM2ELbo08k3s1p1agn1EUf2mnearestES1ELDd0.50n1EHSasmEE\n",
      "Chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7157434 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 27219759 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES2ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4239\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:28.447225608 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:28.454108401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:28.455143533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:29.461910982 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.2 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "81        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e52c7611878497f87f81932e1c1b029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:42.763016994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.774223520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.776274012 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.776451818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7cf362c5e14cb8b31534c86669ece2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46204930543899536    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1784340143203735     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27496302127838135    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46204930543899536   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1784340143203735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27496302127838135   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:48.563070925 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.574196214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.575036397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.576375860 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a9a8f2430463f9af3c94344b45cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46562784910202026    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1850876808166504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28166523575782776    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46562784910202026   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1850876808166504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28166523575782776   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1850876808166504, 'test_mse': 0.28166523575782776, 'test_iou': 0.46562784910202026}]\n",
      "MSE value is 0.28166523575782776\n",
      "IoU value is 0.46562784910202026\n",
      "num_param value is 4239\n",
      "Training time: 133.51136541366577\n",
      "Fitness: 12.454388904115707\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: 12.454388904115707, IoU: 0.46562784910202026, FPS: 376.5758600137161, Model Size: 4239\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 1, the best fitness of the population is 17.122821688326226.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_1.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 2 ***\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:54.523219229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.540329040 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.541038467 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.544383706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4850948491ae44839f870ad5691881b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:18.997607766 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.998018456 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.998771098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.999060980 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794b913311d744f58d02a9d57e27546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7786670923233032     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8679985404014587     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05967839062213898    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7786670923233032    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8679985404014587    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05967839062213898   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:26.153915519 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.161320394 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.161961846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.165919585 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa064a8e322241eea71b73d3e9171d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7643353939056396     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8672610521316528     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05922425165772438    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7643353939056396    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8672610521316528    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05922425165772438   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8672610521316528, 'test_mse': 0.05922425165772438, 'test_iou': 0.7643353939056396}]\n",
      "MSE value is 0.05922425165772438\n",
      "IoU value is 0.7643353939056396\n",
      "num_param value is 155516\n",
      "Training time: 204.56607103347778\n",
      "Fitness: 16.928709392244556\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.928709392244556, IoU: 0.7643353939056396, FPS: 268.8005344346563, Model Size: 155516\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 6321956 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:34.760716287 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.776935658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.780727354 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.790032904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfa0faa29e6419a822dec1009942502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:24:40.592274899 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.594092691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.595121006 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.603815523 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a87f06d03ff4af98b26d37ce5689010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7646944522857666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8393237590789795     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04351936653256416    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7646944522857666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8393237590789795    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04351936653256416   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:24:53.750198059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.756993460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.757106989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.763061699 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a9bea482024f888cc602d48786846e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7541961669921875     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8390940427780151     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04316077008843422    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7541961669921875    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8390940427780151    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04316077008843422   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8390940427780151, 'test_mse': 0.04316077008843422, 'test_iou': 0.7541961669921875}]\n",
      "MSE value is 0.04316077008843422\n",
      "IoU value is 0.7541961669921875\n",
      "num_param value is 189886\n",
      "Training time: 725.824999332428\n",
      "Fitness: 16.93832573485889\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: 16.93832573485889, IoU: 0.7541961669921875, FPS: 170.70178847629518, Model Size: 189886\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES0ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:25:05.577849985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.577921265 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.579904102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.580946768 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243110dd1b654b1483ff726d5af0dba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:43.844331508 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.852434856 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.853458845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.861171093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec288bb22723418b9c0b8e0959ca2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7495232820510864     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8797957301139832     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06333170086145401    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7495232820510864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8797957301139832    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06333170086145401   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:48.284246091 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.292026792 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.292034578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.294712990 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5600b06265b465ca7d5891e0cfa5c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7487450838088989     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8772498369216919     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06117401644587517    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7487450838088989    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8772498369216919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06117401644587517   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8772498369216919, 'test_mse': 0.06117401644587517, 'test_iou': 0.7487450838088989}]\n",
      "MSE value is 0.06117401644587517\n",
      "IoU value is 0.7487450838088989\n",
      "num_param value is 2855\n",
      "Training time: 98.26789474487305\n",
      "Fitness: 16.908120957458557\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.908120957458557, IoU: 0.7487450838088989, FPS: 388.2184337724817, Model Size: 2855\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 448389\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:54.527812576 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.533997597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.538257654 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.543382523 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 448 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "448 K     Trainable params\n",
      "0         Non-trainable params\n",
      "448 K     Total params\n",
      "1.794     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c51565f6bb412e89e95b19c9d9f344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:27.941914825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.944604870 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.945036039 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.953672364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46917014b5474f019d94a7d5a2e6b332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7279489040374756     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8697322607040405     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060768406838178635    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7279489040374756    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8697322607040405    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060768406838178635   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:39.436357176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.441750852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.446725461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.450277527 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810f9244cb44a0fadb80e1603cc5bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7172728180885315     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8685995936393738     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060260165482759476    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7172728180885315    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8685995936393738    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060260165482759476   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8685995936393738, 'test_mse': 0.060260165482759476, 'test_iou': 0.7172728180885315}]\n",
      "MSE value is 0.060260165482759476\n",
      "IoU value is 0.7172728180885315\n",
      "num_param value is 448389\n",
      "Training time: 753.3821873664856\n",
      "Fitness: 16.15598654966747\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: 16.15598654966747, IoU: 0.7172728180885315, FPS: 179.93305036614836, Model Size: 448389\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:51.593161770 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.605200116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.605419042 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.611003943 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557505c66d8d40feadebc2d332430f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:02:54.861192073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.868181327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.868439808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.870626095 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623abf9e00b54f64907b13427b71b6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.75431889295578      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8948533535003662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09603867679834366    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.75431889295578     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8948533535003662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09603867679834366   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:03:12.592821941 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.593443601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.593986117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.602369997 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c380382fa4ffea1b6491c44b95fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7345479130744934     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8998154401779175     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10632448643445969    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7345479130744934    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8998154401779175    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10632448643445969   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8998154401779175, 'test_mse': 0.10632448643445969, 'test_iou': 0.7345479130744934}]\n",
      "MSE value is 0.10632448643445969\n",
      "IoU value is 0.7345479130744934\n",
      "num_param value is 876202\n",
      "Training time: 1383.218773841858\n",
      "Fitness: 15.508216540129883\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.508216540129883, IoU: 0.7345479130744934, FPS: 128.51886826042616, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELme3arn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91684\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:03:27.244904503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.246881297 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.248817509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.257996893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.7 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.7 K    Total params\n",
      "0.367     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce29b214bb14421aa1c7260e13628e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:38.009277739 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.011546666 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.014095101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.018616722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b72885dd0b44de99113dfeae2b4dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.648859977722168     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9115615487098694     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08111194521188736    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.648859977722168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9115615487098694    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08111194521188736   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:44.275046637 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.278382347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.280293385 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.287423806 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c67867c7b144f7a47c261bac1740bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6499044895172119     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9110153913497925     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08094775676727295    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6499044895172119    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9110153913497925    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08094775676727295   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9110153913497925, 'test_mse': 0.08094775676727295, 'test_iou': 0.6499044895172119}]\n",
      "MSE value is 0.08094775676727295\n",
      "IoU value is 0.6499044895172119\n",
      "num_param value is 91684\n",
      "Training time: 130.75279068946838\n",
      "Fitness: 15.658501792033235\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.658501792033235, IoU: 0.6499044895172119, FPS: 343.6689847210305, Model Size: 91684\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:50.193996431 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.199889230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.200184992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.204690327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb86417adb2d4c3089e686df8ace4074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:08:56.564630036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.566857878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.567973826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.575975957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e592e2d014e84f5691ca8c803fb20372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7724882960319519     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8434401154518127     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045673616230487823    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7724882960319519    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8434401154518127    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045673616230487823   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:09:01.344591875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.348479921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.349930955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.350515255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e73c80923b401c92389617808e9070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7665195465087891     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8429293036460876     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045077964663505554    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7665195465087891    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8429293036460876    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045077964663505554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8429293036460876, 'test_mse': 0.045077964663505554, 'test_iou': 0.7665195465087891}]\n",
      "MSE value is 0.045077964663505554\n",
      "IoU value is 0.7665195465087891\n",
      "num_param value is 18862\n",
      "Training time: 185.42162656784058\n",
      "Fitness: 17.214997563005028\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 17.214997563005028, IoU: 0.7665195465087891, FPS: 374.4654834629315, Model Size: 18862\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES2ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 10107519 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELeo05k5s1p2agn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1236624\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:09:08.686595672 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.686648921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.687688847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.695652874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.946     Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985e58afe1f41f89e0231b47d73c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:34:26.964499905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.970954501 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.974106635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.981389376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ab2934d5e145d4b77e0c5c983dd8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8193681240081787     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.876876711845398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06460625678300858    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8193681240081787    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.876876711845398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06460625678300858   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:34:51.599770014 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.601739488 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.603691842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.611084875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6270dde86a1441b0bae877ad793f3716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8094890713691711     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8869012594223022     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06989122927188873    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8094890713691711    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8869012594223022    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06989122927188873   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8869012594223022, 'test_mse': 0.06989122927188873, 'test_iou': 0.8094890713691711}]\n",
      "MSE value is 0.06989122927188873\n",
      "IoU value is 0.8094890713691711\n",
      "num_param value is 1236624\n",
      "Training time: 1518.299451828003\n",
      "Fitness: 16.205011248466025\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 16.205011248466025, IoU: 0.8094890713691711, FPS: 92.96105844518428, Model Size: 1236624\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELeo08k5s1p2agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7541748 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES0ELeo15k3s1p1arn1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 34089378 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELdo12agn1EPM2ELdo13agn1EUf2mnearestES0ELDd0.30n1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 24367770 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 248712443 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 86538\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:35:15.035707967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.055409283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.056958847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.064881269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 86.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "86.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 K    Total params\n",
      "0.346     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24cee98359340e3a00c4e80190cb51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:38:56.752435849 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.759818329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.760916009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.770416799 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1127ca3b304fa197486e06b34e356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5709845423698425     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9033698439598083     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09791910648345947    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5709845423698425    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9033698439598083    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09791910648345947   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:39:05.488508404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.489352132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.489420604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.497082022 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49187bbf81a44f82b574458ca2a7bd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5471180081367493     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9005675911903381     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09943404793739319    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5471180081367493    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9005675911903381    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09943404793739319   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9005675911903381, 'test_mse': 0.09943404793739319, 'test_iou': 0.5471180081367493}]\n",
      "MSE value is 0.09943404793739319\n",
      "IoU value is 0.5471180081367493\n",
      "num_param value is 86538\n",
      "Training time: 220.97202706336975\n",
      "Fitness: 14.480230869763325\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 14.480230869763325, IoU: 0.5471180081367493, FPS: 251.0198813804566, Model Size: 86538\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne6arn1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2017775\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:39:13.867801710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.869177707 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.870726833 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.874104955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.0 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.071     Total estimated model params size (MB)\n",
      "59        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b1666232c416a86100f05272462e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:04:48.644077830 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.647544550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.648432302 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.657765127 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a33f810b6f41528a97ca030d31a6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7768922448158264     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8403710722923279     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11396994441747665    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7768922448158264    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8403710722923279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11396994441747665   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:05:21.743013181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.746614879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.747645314 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.757727998 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3625c4338c476bab40cd831722ab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7706284523010254     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8351418375968933     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11580067127943039    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7706284523010254    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8351418375968933    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11580067127943039   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8351418375968933, 'test_mse': 0.11580067127943039, 'test_iou': 0.7706284523010254}]\n",
      "MSE value is 0.11580067127943039\n",
      "IoU value is 0.7706284523010254\n",
      "num_param value is 2017775\n",
      "Training time: 1534.8301301002502\n",
      "Fitness: 14.650683733331817\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: 14.650683733331817, IoU: 0.7706284523010254, FPS: 69.45987229765886, Model Size: 2017775\n",
      "\n",
      "For generation 2, the best fitness of the population is 17.214997563005028.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_2.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 3 ***\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:05:50.764708038 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.765753624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.767650456 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.769973666 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe715e847c24638ac226b3ec7ab52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:18.377625771 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.377707799 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.381609824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.389759357 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c866f8f3de804d5d9107c224cfe25920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6911529898643494     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9236199259757996     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0851404070854187     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6911529898643494    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9236199259757996    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0851404070854187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:24.194169418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.196253847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.201083966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.205218433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963d2d3b7d604eb68415f2836b4f023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6805527806282043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9368762373924255     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09136483818292618    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6805527806282043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9368762373924255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09136483818292618   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9368762373924255, 'test_mse': 0.09136483818292618, 'test_iou': 0.6805527806282043}]\n",
      "MSE value is 0.09136483818292618\n",
      "IoU value is 0.6805527806282043\n",
      "num_param value is 18862\n",
      "Training time: 148.70190143585205\n",
      "Fitness: 15.949504529077577\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.949504529077577, IoU: 0.6805527806282043, FPS: 371.4892646143948, Model Size: 18862\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELbo13k3s1p1agn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 27063456 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:30.915500444 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.918574631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.919545809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.923563022 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560868a1268a4c6ca969e5bb92eec4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:35.328839448 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.335034411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.335245138 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.337207011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfecb5dd0ce4d6eb7432e50eb17c50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7959802746772766     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8919023275375366     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07192771881818771    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7959802746772766    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8919023275375366    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07192771881818771   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:44.687067535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.688519228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.689987485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.697797184 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16710320494db1af8f208820ab6f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7837731242179871     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8980788588523865     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07474220544099808    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7837731242179871    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8980788588523865    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07474220544099808   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8980788588523865, 'test_mse': 0.07474220544099808, 'test_iou': 0.7837731242179871}]\n",
      "MSE value is 0.07474220544099808\n",
      "IoU value is 0.7837731242179871\n",
      "num_param value is 155516\n",
      "Training time: 305.4734237194061\n",
      "Fitness: 16.986772139056093\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.986772139056093, IoU: 0.7837731242179871, FPS: 260.69257777992414, Model Size: 155516\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES1ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:52.492425270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.493369774 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.495756254 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.499871545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536e3f1511d946388e1109d2fd9a00e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:15:49.373181644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.378475488 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.383954073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.391531578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5ab83171ad4b07819a55c9cf1ee775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7057086825370789     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.877724826335907     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06278485804796219    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7057086825370789    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.877724826335907    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06278485804796219   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:15:55.697117624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.698857663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.700293005 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.703640079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622dfac3eb3749819392ff22e2c35499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6862832307815552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8808153867721558     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06416567414999008    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6862832307815552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8808153867721558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06416567414999008   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8808153867721558, 'test_mse': 0.06416567414999008, 'test_iou': 0.6862832307815552}]\n",
      "MSE value is 0.06416567414999008\n",
      "IoU value is 0.6862832307815552\n",
      "num_param value is 2855\n",
      "Training time: 117.87220668792725\n",
      "Fitness: 16.257010347795504\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.257010347795504, IoU: 0.6862832307815552, FPS: 399.26960091735873, Model Size: 2855\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELme4arn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50467\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:16:00.816382066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.824084562 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.824949305 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.827561939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 50.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "50.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.5 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f2146bbfd945ce92d25aaacda2f3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:23.537045689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.538061677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.538995155 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.543148205 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cc8e3a88a24ba2a3ca22567531654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7190388441085815     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9395378828048706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09387846291065216    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7190388441085815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9395378828048706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09387846291065216   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:28.215054615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.221205505 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.221370257 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.223594836 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57be8a97f0b54140ada4bc9daf8dd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7106996178627014     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9573715925216675     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10259950906038284    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7106996178627014    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9573715925216675    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10259950906038284   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9573715925216675, 'test_mse': 0.10259950906038284, 'test_iou': 0.7106996178627014}]\n",
      "MSE value is 0.10259950906038284\n",
      "IoU value is 0.7106996178627014\n",
      "num_param value is 50467\n",
      "Training time: 202.77884531021118\n",
      "Fitness: 16.126005373589077\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 16.126005373589077, IoU: 0.7106996178627014, FPS: 381.71282169078336, Model Size: 50467\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:34.567928851 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.578223453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.579072459 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.587599436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dda8116493d4e62ad9a68eaa262bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:24:52.684659948 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.690333259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.692100613 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.697191463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9503deaec74f97a85f34df6d5d1f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6649729013442993     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8976973295211792     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07292557507753372    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6649729013442993    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8976973295211792    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07292557507753372   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:25:00.543315350 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.545012214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.547977498 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.549280107 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27a52b02bdd4d70b1e3e2de85403258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6736959218978882     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8867667317390442     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06691915541887283    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6736959218978882    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8867667317390442    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06691915541887283   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8867667317390442, 'test_mse': 0.06691915541887283, 'test_iou': 0.6736959218978882}]\n",
      "MSE value is 0.06691915541887283\n",
      "IoU value is 0.6736959218978882\n",
      "num_param value is 47394\n",
      "Training time: 318.12419986724854\n",
      "Fitness: 16.062346604719394\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.062346604719394, IoU: 0.6736959218978882, FPS: 277.23487313011805, Model Size: 47394\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:25:07.916104147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.918478977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.918491018 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.925830628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3069e86bedf34f529bc4b02a183c4d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:36.608987815 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.614563622 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.615421581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.624502170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf78757dfc04b58809686dab30539fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6375889778137207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9469380974769592     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09058068692684174    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6375889778137207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9469380974769592    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09058068692684174   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:42.927658561 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.927667037 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.929952530 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.932060807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7c8964fd644d14aa8b59e705570360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.620185136795044     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9420939087867737     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08805166929960251    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.620185136795044    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9420939087867737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08805166929960251   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9420939087867737, 'test_mse': 0.08805166929960251, 'test_iou': 0.620185136795044}]\n",
      "MSE value is 0.08805166929960251\n",
      "IoU value is 0.620185136795044\n",
      "num_param value is 91054\n",
      "Training time: 148.73982191085815\n",
      "Fitness: 15.301537368778867\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.301537368778867, IoU: 0.620185136795044, FPS: 337.0618804455677, Model Size: 91054\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:48.970239449 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.973327833 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.973359057 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.975737855 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d0a25cba574898ae61c99d819d9ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:42:30.917544839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.918501787 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.919455375 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.922577189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c571415fc1a478fbf6ee81b223f8ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.749896764755249     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9079797863960266     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10712637007236481    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.749896764755249    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9079797863960266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10712637007236481   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:42:48.651930721 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.652439113 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.653981983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.657021571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b78a4bfaa274bd09ea965a4375c401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7347415685653687     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.910155713558197     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11219007521867752    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7347415685653687    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.910155713558197    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11219007521867752   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.910155713558197, 'test_mse': 0.11219007521867752, 'test_iou': 0.7347415685653687}]\n",
      "MSE value is 0.11219007521867752\n",
      "IoU value is 0.7347415685653687\n",
      "num_param value is 876202\n",
      "Training time: 881.9403738975525\n",
      "Fitness: 15.462482554901431\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.462482554901431, IoU: 0.7347415685653687, FPS: 128.0235844228323, Model Size: 876202\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne6arn1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3196505\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:43:03.398073782 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.398753988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.400672424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.404952732 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.786    Total estimated model params size (MB)\n",
      "60        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb363885b114923a217efd81da3166a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:09:51.669508510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.670318200 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.671200764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.671886624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa78749f9f754a72bdb92e54fc550a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5265118479728699     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9190140962600708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14735545217990875    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5265118479728699    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9190140962600708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14735545217990875   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:10:36.631395807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.638398055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.643588232 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.646392326 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28ad5e8111b41e1a678737eef172111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5125477910041809     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9170017242431641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1476600617170334     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5125477910041809    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9170017242431641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1476600617170334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9170017242431641, 'test_mse': 0.1476600617170334, 'test_iou': 0.5125477910041809}]\n",
      "MSE value is 0.1476600617170334\n",
      "IoU value is 0.5125477910041809\n",
      "num_param value is 3196505\n",
      "Training time: 1607.2766788005829\n",
      "Fitness: 10.642354453561616\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 10.642354453561616, IoU: 0.5125477910041809, FPS: 51.496086783647456, Model Size: 3196505\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 610197\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:11:15.571812553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.574880102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.574961049 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.579993777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 610 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "610 K     Trainable params\n",
      "0         Non-trainable params\n",
      "610 K     Total params\n",
      "2.441     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e0ba89ce264b98987b8d1d5e895ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:20.867839100 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.873004859 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.876500966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.879213985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a79bec4f9704dc7acd71725d1b85e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6371888518333435     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8643619418144226     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0882449746131897     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6371888518333435    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8643619418144226    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0882449746131897    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:35.694612980 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.696570654 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.697437103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.706095541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc3f18e357c41b4b7f1606b798b9c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6309760212898254     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8680739402770996     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09702488034963608    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6309760212898254    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8680739402770996    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09702488034963608   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8680739402770996, 'test_mse': 0.09702488034963608, 'test_iou': 0.6309760212898254}]\n",
      "MSE value is 0.09702488034963608\n",
      "IoU value is 0.6309760212898254\n",
      "num_param value is 610197\n",
      "Training time: 785.3572561740875\n",
      "Fitness: 14.815126751268387\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 14.815126751268387, IoU: 0.6309760212898254, FPS: 152.60105730969573, Model Size: 610197\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES2ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 10107519 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELdo09agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 11770350 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3505016\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:49.452311378 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.452330408 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.452543351 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.456928660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.020    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34812a87da9c4995aefffe8fcf3e1620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:18:14.884987540 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.890383692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.890414255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.895258127 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e5232755b4f358e3a78dfb71aaf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4363898038864136     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0084519386291504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3988874554634094     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4363898038864136    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0084519386291504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3988874554634094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:19:04.119647041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.128291377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.128333550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.137589404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c86aa43ff44cb8e25a8a307b4a1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4341442584991455     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9872403740882874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37467679381370544    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4341442584991455    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9872403740882874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37467679381370544   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9872403740882874, 'test_mse': 0.37467679381370544, 'test_iou': 0.4341442584991455}]\n",
      "MSE value is 0.37467679381370544\n",
      "IoU value is 0.4341442584991455\n",
      "num_param value is 3505016\n",
      "Training time: 3204.7224490642548\n",
      "Fitness: 8.110863779975622\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 8.110863779975622, IoU: 0.4341442584991455, FPS: 46.09833061401471, Model Size: 3505016\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 3, the best fitness of the population is 16.986772139056093.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_3.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 4 ***\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:19:48.092781775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.098118291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.099285855 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.104663904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa31090c3dd4d63aeee0089026f678f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:20.708815029 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.737854026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.739891460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.743492727 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387f3899170d4143b2d7c8e28780797e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6175004243850708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.133171796798706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19043885171413422    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6175004243850708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.133171796798706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19043885171413422   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:28.985816423 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.986802455 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.986905806 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.987849525 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f467b185a8d34635b4830bbb2907f061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6111463904380798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.129359245300293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18758484721183777    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6111463904380798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.129359245300293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18758484721183777   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.129359245300293, 'test_mse': 0.18758484721183777, 'test_iou': 0.6111463904380798}]\n",
      "MSE value is 0.18758484721183777\n",
      "IoU value is 0.6111463904380798\n",
      "num_param value is 155516\n",
      "Training time: 271.78137254714966\n",
      "Fitness: 14.376398892348169\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 14.376398892348169, IoU: 0.6111463904380798, FPS: 265.5517089014598, Model Size: 155516\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES1ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 321780\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:36.626655512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.629465242 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.632597848 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.640667759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 321 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "321 K     Trainable params\n",
      "0         Non-trainable params\n",
      "321 K     Total params\n",
      "1.287     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60708011332247b7a04dd18549614dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:38.863090208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.863219175 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.864382315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.869860069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367bb6d4f0464aeb8ded3f47931e671a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3283042907714844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3283042907714844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:46.348024624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.353437633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.353694655 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.357434681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e017320527ca460487e09ab9c25a7f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3244633674621582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3244633674621582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.3244633674621582, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 321780\n",
      "Training time: 302.2469789981842\n",
      "Fitness: 13.450787658357372\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 13.450787658357372, IoU: 0.6023015975952148, FPS: 260.35047001988954, Model Size: 321780\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELme4arn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50467\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:54.102735349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.111041249 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.113094697 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.122484691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 50.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "50.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.5 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316e998f720b41e2afe1f933295551e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:17.095836858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.098329709 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.115232333 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.120214120 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccd30c26ef465abaf7d2b5d028868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6906546950340271     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.964706540107727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10612887889146805    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6906546950340271    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.964706540107727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10612887889146805   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:23.808125069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.808126573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.810844536 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.815908137 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e1b56501934f60b4a33c2f58ef504a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6790745258331299     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9789044857025146     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11318682134151459    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6790745258331299    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9789044857025146    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11318682134151459   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9789044857025146, 'test_mse': 0.11318682134151459, 'test_iou': 0.6790745258331299}]\n",
      "MSE value is 0.11318682134151459\n",
      "IoU value is 0.6790745258331299\n",
      "num_param value is 50467\n",
      "Training time: 202.97309684753418\n",
      "Fitness: 15.723496356394014\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 15.723496356394014, IoU: 0.6790745258331299, FPS: 376.58654427383703, Model Size: 50467\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:28.211591686 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.212609680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.213619593 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.221742865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb1d8d3e6c94859b19110e2d6e8e0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:38:46.331257867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.351821128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.352158646 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.361608196 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39741271e6b4d9db4e8d135de3e51eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6475337147712708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8990762829780579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0742703229188919     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6475337147712708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8990762829780579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0742703229188919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:38:54.221483304 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.229355131 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.230113035 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.236406280 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4cf5c82d274f39b43bad91c2b9a10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6350592970848083     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9012433290481567     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07496412098407745    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6350592970848083    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9012433290481567    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07496412098407745   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9012433290481567, 'test_mse': 0.07496412098407745, 'test_iou': 0.6350592970848083}]\n",
      "MSE value is 0.07496412098407745\n",
      "IoU value is 0.6350592970848083\n",
      "num_param value is 47394\n",
      "Training time: 318.1243939399719\n",
      "Fitness: 15.605835035431788\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 15.605835035431788, IoU: 0.6350592970848083, FPS: 277.60163088734316, Model Size: 47394\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELme4arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:39:02.515035466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.518134464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.521071945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.522017605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f46de3e0ed840da86095272eb72e7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:40:51.963522560 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.964459441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.966895208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.970378393 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22d4315386b40728c52c9275454c693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6498749852180481     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.916018545627594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0806988850235939     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6498749852180481    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.916018545627594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0806988850235939    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:40:56.171118158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.173093893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.175861240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.177200917 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535b13736a424e22915202404de4c7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6553024053573608     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.906862735748291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07563789933919907    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6553024053573608    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.906862735748291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07563789933919907   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.906862735748291, 'test_mse': 0.07563789933919907, 'test_iou': 0.6553024053573608}]\n",
      "MSE value is 0.07563789933919907\n",
      "IoU value is 0.6553024053573608\n",
      "num_param value is 2573\n",
      "Training time: 109.43885493278503\n",
      "Fitness: 15.847259957521063\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.847259957521063, IoU: 0.6553024053573608, FPS: 405.761374558758, Model Size: 2573\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:41:01.202030693 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.204430937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.208177209 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.216130513 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab7ccc2417f4e6abfc23df7df3b3886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:55:41.436454858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.436454597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.440632807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.440726031 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd73cb059af9410382d166c9f7552dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7620817422866821     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.896282434463501     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1342364102602005     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7620817422866821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.896282434463501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1342364102602005    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:55:59.181416123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.189089629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.190140194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.191233177 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f088626d7946a19cb437e0a8b20caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7587275505065918     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8839991688728333     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13036616146564484    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7587275505065918    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8839991688728333    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13036616146564484   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8839991688728333, 'test_mse': 0.13036616146564484, 'test_iou': 0.7587275505065918}]\n",
      "MSE value is 0.13036616146564484\n",
      "IoU value is 0.7587275505065918\n",
      "num_param value is 876202\n",
      "Training time: 880.2447843551636\n",
      "Fitness: 15.557764374716417\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.557764374716417, IoU: 0.7587275505065918, FPS: 127.42829734608182, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:56:15.987005853 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.994112010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.994158735 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.002484796 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef55fd7a9b6c44a29cac74359a7707c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:43.017431101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.020331839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.023171568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.025648222 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0750abde3a7436085394c48fec3dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6436501145362854     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9415942430496216     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08751361072063446    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6436501145362854    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9415942430496216    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08751361072063446   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:49.057994167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.060401554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.060909288 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.063389124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7417d08355c4627bbe0bdcb43b8b9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6219373941421509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9371283054351807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08504777401685715    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6219373941421509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9371283054351807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08504777401685715   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9371283054351807, 'test_mse': 0.08504777401685715, 'test_iou': 0.6219373941421509}]\n",
      "MSE value is 0.08504777401685715\n",
      "IoU value is 0.6219373941421509\n",
      "num_param value is 91054\n",
      "Training time: 148.04842376708984\n",
      "Fitness: 15.34450400212872\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.34450400212872, IoU: 0.6219373941421509, FPS: 352.9902265655968, Model Size: 91054\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4543231\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:55.845939023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.846896148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.846949281 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.856029451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "18.173    Total estimated model params size (MB)\n",
      "67        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a0b18c8cd04cb6be2ac091c07c3add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:05:52.356491216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.377810453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.432427252 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.432447353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c6ff735f964eb0ae5f6b81a44073a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5579782128334045     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9120903611183167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14606435596942902    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5579782128334045    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9120903611183167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14606435596942902   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:06:37.972698240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.987547531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.036398891 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.036437947 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5498ede13ac04b28b918889d39f54b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5482544898986816     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9067445993423462     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13763146102428436    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5482544898986816    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9067445993423462    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13763146102428436   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9067445993423462, 'test_mse': 0.13763146102428436, 'test_iou': 0.5482544898986816}]\n",
      "MSE value is 0.13763146102428436\n",
      "IoU value is 0.5482544898986816\n",
      "num_param value is 3196099\n",
      "Training time: 1601.644122838974\n",
      "Fitness: 11.076638806447676\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 11.076638806447676, IoU: 0.5482544898986816, FPS: 51.75045407762942, Model Size: 3196099\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne5arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 6205920 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELco16k3s1p1arn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 40533248 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES2ELdo08agn1EUf2mnearestES0ELdo12agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo12agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo12agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1280062\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:07:17.372022627 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.376750966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.378572485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.379814753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.3 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.120     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a01745870474921a8ef278648386844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO CONFIG.INI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: most sanity checks are still missing. Be careful please."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the [Mode] section, select the desired mode for pynattas. If both are true, nas will be done first, then ht will be done on the winning architecture of nas. If only ht is true, then tuning will be done on the architecture written in architecture_code under the [NAS] section.\n",
    "- max_layers in [NAS] section refers to the maximum size of the chromosomes (aka, maximum number of convolutions-type layers).\n",
    "- In the [GA] section, change the parameters for NAS search.\n",
    "- In the [Computation] section, be careful about the num_workers value. Currently set to 1 for safety when testing parallelization. In computation, also change the accellerator to either \"cpu\" or \"gpu\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO PARALLELIZATION (currently broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Mostly untested.\n",
    "- In main.py, change line 54 (\"nas_result = pnas.optimizers.ga.ga_optimizer(\") to:\n",
    "    - nas_result = pnas.optimizers.ga_concurrent.ga_optimizer(\" for nas parallelization using a ThreadPoolExecutor\n",
    "    - nas_result = pnas.optimizers.ga_concurrent_pp.ga_optimizer(\" for nas parallelization using a ProcessPoolExecutor\n",
    "\n",
    "Currently, it looks like there are issues with ProcessPoolExecutor. Regardless, be careful when selecting num_workers in the config.ini when testing these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO ADD NEW BLOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in pynattas.blocks add the new block to the related .py file depending on type.\n",
    "- in config.ini add the new block as a section with all related parameters. Use \"default_\" for default values that are used during NAS, and \"min_\" and \"max_\" for range values to be used during tuning. Also, update the commented vocabulary at the start for clarity purposes.\n",
    "- in pynattas.configuration.vocabulary, update relative vocabularies.\n",
    "- in pynattas.classes.generic_network, add the layer construction to the list making sure that the current_layers, current_height, and current_width is calculated correctly.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO WORK ON NEW DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add dataset to the \"data\" folder\n",
    "- Add compatible datamodule to the \"datasets\" folder\n",
    "- in pynattas.functions.fitness, import the desired datamodule. Also, around line 59, update the datahandling to be compatible with your datamodule. For the ClassificationHead, Make sure the data is resized to 256x256 sized HxW images, that the number of channels passed to the model is correct.\n",
    "- change config.ini in the [Dataset] section. \"data_path\" should point to the dataset, \"csv_path\" is for a .csv for labels if required. If it's not required, imput None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO LOGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs are stored in the \"logs\" folder and in the \"lightning_logs\" folder. In \"logs\", you will find:\n",
    "- logs about NAS iterations and results in the GA_logs subfolder\n",
    "- logs about HT iterations and results in either the GWO_logs or PSO_logs subfolder depending on the selected HT algorithm\n",
    "- logs about the final run comprised of the saved checkpoint .ckpt file in the \"tb_logs\" subfolder, together with all the confusion matrixes generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE (Coming soon...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
