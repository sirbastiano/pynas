{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Pynattas (old version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: assuming dependencies already in place. A guide for dependencies will be created on a later date. For now, make sure to have the latest compatible versions of:\n",
    "- pytorch and pytorch lightning, torchmetrics and torchvision, cuda\n",
    "- tensorflow and tensorboard\n",
    "- tqdm\n",
    "- datetime\n",
    "- matplotlib and numpy\n",
    "\n",
    "Solve any further incompatibilities as they are raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code with current configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: There are possible combinations of blocks that will crash the run. A saner block selection logic will be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard tensorboardX\n",
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynattas as pnas\n",
    "import torch\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Network Architecture Search ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chromosome pool:\n",
      "Architecture: Lco05k5s1p2agn1EPM2ELeo09k3s1p1agn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'PM2', 'Leo09k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 12526220 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2agn1', 'PM2', 'Leo09k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELeo10k3s1p1agn1EPa2ELRr2arn1EUf2mnearestES1ELeo10k3s1p1agn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Leo10k3s1p1agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 73832542 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Leo10k3s1p1agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 857212\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:32:48.265121660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.273538706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.292180327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:32:48.302222353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 857 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "857 K     Trainable params\n",
      "0         Non-trainable params\n",
      "857 K     Total params\n",
      "3.429     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9def9092480d4fc1896abae62d9e14b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:46:55.106376010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.119434068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.184409918 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:46:55.184455339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a867b837f173458eb19e4a5bb99a2d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7712280750274658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9056116342544556     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1125316247344017     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7712280750274658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9056116342544556    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1125316247344017    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:47:12.991074479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.005128139 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.048403622 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:12.048443617 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941c0a3fef4a43c1ab6284b344961b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7479709982872009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9219234585762024     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12203318625688553    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7479709982872009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9219234585762024    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12203318625688553   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9219234585762024, 'test_mse': 0.12203318625688553, 'test_iou': 0.7479709982872009}]\n",
      "MSE value is 0.12203318625688553\n",
      "IoU value is 0.7479709982872009\n",
      "num_param value is 857212\n",
      "Training time: 847.482387304306\n",
      "Fitness: 15.53489034566843\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.53489034566843, IoU: 0.7479709982872009, FPS: 134.66454063656684, Model Size: 857212\n",
      "\n",
      "Architecture: Lme3agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27024\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:47:27.934823878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.955251517 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.988398236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:47:27.988430987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.0 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.0 K    Total params\n",
      "0.108     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062d545b4f094f5a97a8913993d4b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:08.716114957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.716321952 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.719653630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:08.726814625 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28da911faf7c4503a52e9f21f33fe2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7175394892692566     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.855086624622345     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05018816515803337    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7175394892692566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.855086624622345    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05018816515803337   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:14.626298514 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.630881429 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.654446170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:14.656787283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e985e83e09e431982912dca8ec4269a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.708678662776947     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8545005321502686     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04944255203008652    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.708678662776947    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8545005321502686    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04944255203008652   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8545005321502686, 'test_mse': 0.04944255203008652, 'test_iou': 0.708678662776947}]\n",
      "MSE value is 0.04944255203008652\n",
      "IoU value is 0.708678662776947\n",
      "num_param value is 27024\n",
      "Training time: 220.76591396331787\n",
      "Fitness: 16.588631054779196\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: 16.588631054779196, IoU: 0.708678662776947, FPS: 363.4946603133376, Model Size: 27024\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:51:19.235805392 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.242841834 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.250233228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:51:19.250718141 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c41c41a758a4c6c8c278f92888bd1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:55:52.568293315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569084372 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569099433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:52.569504989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab27ff48be14c2ca60e6451ceb36e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.767717719078064     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9203417301177979     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08647586405277252    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.767717719078064    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9203417301177979    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08647586405277252   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:55:59.427156148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.428111109 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.428693587 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:55:59.431000573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9b801c3f054ee0a7a4f4508662bc8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7573432326316833     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9314648509025574     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09170122444629669    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7573432326316833    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9314648509025574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09170122444629669   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9314648509025574, 'test_mse': 0.09170122444629669, 'test_iou': 0.7573432326316833}]\n",
      "MSE value is 0.09170122444629669\n",
      "IoU value is 0.7573432326316833\n",
      "num_param value is 155516\n",
      "Training time: 272.31300687789917\n",
      "Fitness: 16.57793170055252\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.57793170055252, IoU: 0.7573432326316833, FPS: 281.2294427896797, Model Size: 155516\n",
      "\n",
      "Architecture: Lco09k5s1p2arn1EPa2ELeo05k5s1p2agn1EUf2mnearestES0ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 22854384 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.28n1EPM2ELdo08agn1EPM2ELRr3arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELDd0.28n1EHSasmEE\n",
      "Chromosome: ['LDd0.28n1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LDd0.28n1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3190430\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 21:56:07.865988635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.874702365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.932410402 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 21:56:07.932454163 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.762    Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f89116f0f854e81add48baa79cac12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:37:03.158565631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.180562690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.203799652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:03.206610955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b5d3ac4d43479b9ea06c4efcb13811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5179244875907898     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1692701578140259     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3584161698818207     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5179244875907898    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1692701578140259    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3584161698818207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:37:45.680549024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.682149070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.691880979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:37:45.695050861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a9ebc4ae7b4accbd1472d7e0bba98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5040837526321411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1736341714859009     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3841129541397095     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5040837526321411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1736341714859009    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3841129541397095    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1736341714859009, 'test_mse': 0.3841129541397095, 'test_iou': 0.5040837526321411}]\n",
      "MSE value is 0.3841129541397095\n",
      "IoU value is 0.5040837526321411\n",
      "num_param value is 3190430\n",
      "Training time: 2456.3301653862\n",
      "Fitness: 9.07525140202624\n",
      "********\n",
      "chromosome: ['LDd0.28n1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LDd0.28n1', 'HSasm'], fitness: 9.07525140202624, IoU: 0.5040837526321411, FPS: 55.789499845675536, Model Size: 3190430\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:38:21.653297367 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.654625618 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.665053112 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:38:21.666936160 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bafb2a0d01048c086219f4fa411cbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:25.405577609 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.407114543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.407907741 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:25.408448564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c037f4d93a84e91b416f39cc41168a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7331038117408752     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8674980998039246     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.057588350027799606    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7331038117408752    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8674980998039246    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.057588350027799606   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:31.632722798 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.640428310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.640428352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:31.647472538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271b89f509084ffeb709f3d0e896aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7281439304351807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8588637113571167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.052786875516176224    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7281439304351807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8588637113571167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.052786875516176224   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8588637113571167, 'test_mse': 0.052786875516176224, 'test_iou': 0.7281439304351807}]\n",
      "MSE value is 0.052786875516176224\n",
      "IoU value is 0.7281439304351807\n",
      "num_param value is 18862\n",
      "Training time: 184.8819441795349\n",
      "Fitness: 16.761175959561154\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 16.761175959561154, IoU: 0.7281439304351807, FPS: 405.26818180632347, Model Size: 18862\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES0ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:41:36.664343660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.669079016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.669210421 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:41:36.678178050 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa544cbc0844ae289250f5464a88f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:53:42.212911751 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.213871733 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.215844828 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:42.220198886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cc3e31130e497dab1b5cf3ec7c80f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7589005827903748     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8628867268562317     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05386950448155403    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7589005827903748    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8628867268562317    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05386950448155403   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:53:55.277674214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.293429410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.294343352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:53:55.298394710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcf938e258645d496108f729d075ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7478986978530884     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.867072582244873     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05581127852201462    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7478986978530884    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.867072582244873    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05581127852201462   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.867072582244873, 'test_mse': 0.05581127852201462, 'test_iou': 0.7478986978530884}]\n",
      "MSE value is 0.05581127852201462\n",
      "IoU value is 0.7478986978530884\n",
      "num_param value is 189886\n",
      "Training time: 726.5062062740326\n",
      "Fitness: 16.760490613616593\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm'], fitness: 16.760490613616593, IoU: 0.7478986978530884, FPS: 172.48639958599685, Model Size: 189886\n",
      "\n",
      "Architecture: Lbo15k5s1p2arn1EPM2ELeo08k5s1p2agn1EUf2mnearestES0ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo15k5s1p2arn1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 266925960 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo15k5s1p2arn1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES2ELDd0.30n1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 28910568 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S2', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELDd0.50n1EPM2ELdo13agn1EUf2mnearestES1ELDd0.50n1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LDd0.50n1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 30169930 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'LDd0.50n1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELne3arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 129322\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 22:54:10.917835729 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.933905433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.984475396 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 22:54:10.984493880 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 129 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4a0736cf3b4230a618a08138cf8700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:03:48.030867486 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.049322628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.054848553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:48.061400055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dafed8db404affb7dbe1fb5b93fea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8053724765777588     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8387914896011353     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.054916366934776306    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8053724765777588    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8387914896011353    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.054916366934776306   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:03:59.855234223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.862962026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.890734134 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:03:59.892905377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab353763aa1146efaf4ed4fbfb9be1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8004068732261658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8343129754066467     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.051597580313682556    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8004068732261658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8343129754066467    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.051597580313682556   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8343129754066467, 'test_mse': 0.051597580313682556, 'test_iou': 0.8004068732261658}]\n",
      "MSE value is 0.051597580313682556\n",
      "IoU value is 0.8004068732261658\n",
      "num_param value is 129322\n",
      "Training time: 578.4766125679016\n",
      "Fitness: 17.38408774559595\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 17.38408774559595, IoU: 0.8004068732261658, FPS: 205.8732752859242, Model Size: 129322\n",
      "\n",
      "Architecture: Leo15k3s1p1arn1EPM2ELbo08k3s1p1agn1EUf2mnearestES0ELeo15k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 115929030 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco10k5s1p2agn1EPM2ELRr3agn1EPa2ELme3agn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco10k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco10k5s1p2agn1', 'PM2', 'LRr3agn1', 'Pa2', 'Lme3agn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco10k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 5696410 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco10k5s1p2agn1', 'PM2', 'LRr3agn1', 'Pa2', 'Lme3agn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco10k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne4arn1EPa2ELco09k5s1p2arn1EPa2ELne3agn1EPa2ELme6arn1EUf2mnearestES2ELne3agn1EUf2mnearestES1ELco09k5s1p2arn1EUf2mnearestES0ELne4arn1EHSasmEE\n",
      "Chromosome: ['Lne4arn1', 'Pa2', 'Lco09k5s1p2arn1', 'Pa2', 'Lne3agn1', 'Pa2', 'Lme6arn1', 'Uf2mnearest', 'S2', 'Lne3agn1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne4arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 6517809 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne4arn1', 'Pa2', 'Lco09k5s1p2arn1', 'Pa2', 'Lne3agn1', 'Pa2', 'Lme6arn1', 'Uf2mnearest', 'S2', 'Lne3agn1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne4arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo07k5s1p2arn1EPa2ELne6agn1EPM2ELbo09k5s1p2agn1EPM2ELbo06k5s1p2arn1EUf2mnearestES2ELbo09k5s1p2agn1EUf2mnearestES1ELne6agn1EUf2mnearestES0ELeo07k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo07k5s1p2arn1', 'Pa2', 'Lne6agn1', 'PM2', 'Lbo09k5s1p2agn1', 'PM2', 'Lbo06k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne6agn1', 'Uf2mnearest', 'S0', 'Leo07k5s1p2arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 29757847 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo07k5s1p2arn1', 'Pa2', 'Lne6agn1', 'PM2', 'Lbo09k5s1p2agn1', 'PM2', 'Lbo06k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo09k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lne6agn1', 'Uf2mnearest', 'S0', 'Leo07k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.39n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES2ELme6agn1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.39n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'Lme6agn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3108\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:04:10.222278154 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.226157615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.268435801 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:04:10.268486623 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.1 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c281a39f9849edb154f040caaf59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:32.942618334 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.962522604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.968303409 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:32.968670153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca11e5bc48e34d26ad91a122123d7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.574451744556427     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1066254377365112     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17277945578098297    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.574451744556427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1066254377365112    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17277945578098297   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:37.932210188 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.933675369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.934661286 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:37.938728713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c36ae36964d67a1937887a61427be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5718826055526733     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1178900003433228     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17829488217830658    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5718826055526733    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1178900003433228    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17829488217830658   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1178900003433228, 'test_mse': 0.17829488217830658, 'test_iou': 0.5718826055526733}]\n",
      "MSE value is 0.17829488217830658\n",
      "IoU value is 0.5718826055526733\n",
      "num_param value is 3108\n",
      "Training time: 81.93872928619385\n",
      "Fitness: 14.20255793852195\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.39n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'Lme6agn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 14.20255793852195, IoU: 0.5718826055526733, FPS: 431.22873185788535, Model Size: 3108\n",
      "\n",
      "Architecture: Lbo06k5s1p2agn1EPM2ELRr2agn1EPa2ELco16k5s1p2agn1EPM2ELbo13k5s1p2agn1EUf2mnearestES2ELco16k5s1p2agn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELbo06k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lbo06k5s1p2agn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco16k5s1p2agn1', 'PM2', 'Lbo13k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco16k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo06k5s1p2agn1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 147490470 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo06k5s1p2agn1', 'PM2', 'LRr2agn1', 'Pa2', 'Lco16k5s1p2agn1', 'PM2', 'Lbo13k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lco16k5s1p2agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo06k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.40n1EPM2ELme3arn1EUf2mnearestES0ELDd0.40n1EHSasmEE\n",
      "Chromosome: ['LDd0.40n1', 'PM2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm']\n",
      "Inside the for loop of ga_optimizer the value of parsed_layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1110\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:05:43.019880579 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.050562853 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.120524364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:05:43.120524382 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.1 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1380529b24405ba1221b6444a5747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:44.264312371 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.267353983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.272863886 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:44.281501690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455dec8513a2489eaab67bc4cf9e3ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.449891597032547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1905184984207153     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19179224967956543    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.449891597032547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1905184984207153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19179224967956543   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:49.966666864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.978881694 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.991112518 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:49.992764932 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca07e256eee4720abbf48a9daf42fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4438057839870453     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1956515312194824     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19484706223011017    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4438057839870453    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1956515312194824    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19484706223011017   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1956515312194824, 'test_mse': 0.19484706223011017, 'test_iou': 0.4438057839870453}]\n",
      "MSE value is 0.19484706223011017\n",
      "IoU value is 0.4438057839870453\n",
      "num_param value is 1110\n",
      "Training time: 61.43058490753174\n",
      "Fitness: 12.806219787809633\n",
      "********\n",
      "chromosome: ['LDd0.40n1', 'PM2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm'], fitness: 12.806219787809633, IoU: 0.4438057839870453, FPS: 455.6030002009548, Model Size: 1110\n",
      "\n",
      "Text file saved: ./logs/GA_logs/GA_generation_0.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 1 ***\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:06:54.703126563 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.707844391 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.776412364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:06:54.776515957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3633db7b76477d9ab1ed30707bd576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:22.942807369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.948154748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.967361358 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:22.975719269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c06b76d11d4a19815e9e95b9606e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6555923819541931     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0221272706985474     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13613061606884003    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6555923819541931    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0221272706985474    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13613061606884003   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:27.200638628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.217590171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.240737963 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:27.250554244 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1caf38210e842289c3d83466381013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6471068859100342     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.016931414604187     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13348297774791718    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6471068859100342    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.016931414604187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13348297774791718   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.016931414604187, 'test_mse': 0.13348297774791718, 'test_iou': 0.6471068859100342}]\n",
      "MSE value is 0.13348297774791718\n",
      "IoU value is 0.6471068859100342\n",
      "num_param value is 18862\n",
      "Training time: 148.26383066177368\n",
      "Fitness: 15.274571373006578\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.274571373006578, IoU: 0.6471068859100342, FPS: 404.7812062339122, Model Size: 18862\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES0ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:09:32.278051479 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.281733763 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.336433547 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:09:32.336484984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feffe8b7dbf24b129b75994a52a86354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:21:39.576358681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.587919424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.603991499 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:39.606611630 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f7aeee8ed34060a135b231c6804b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7696115374565125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8554146885871887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05176108703017235    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7696115374565125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8554146885871887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05176108703017235   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:21:52.655028285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.672557361 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.676276144 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:21:52.678762074 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0030beb7c1b24b9195098e276796a4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7664128541946411     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.853529155254364     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05047934502363205    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7664128541946411    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.853529155254364    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05047934502363205   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.853529155254364, 'test_mse': 0.05047934502363205, 'test_iou': 0.7664128541946411}]\n",
      "MSE value is 0.05047934502363205\n",
      "IoU value is 0.7664128541946411\n",
      "num_param value is 189886\n",
      "Training time: 726.3131926059723\n",
      "Fitness: 16.993706249036276\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'HSasm'], fitness: 16.993706249036276, IoU: 0.7664128541946411, FPS: 172.79946672527853, Model Size: 189886\n",
      "\n",
      "Architecture: Lme3agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27024\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:22:03.330555101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.331814561 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.352823007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:22:03.356904994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.0 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.0 K    Total params\n",
      "0.108     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011ce8be23b0433eae9763d73c00faba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:08.423361890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.426320805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.427103407 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:08.428404533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55052894dcb44a338474fc23fffec737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7640599012374878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8465728163719177     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04766015335917473    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7640599012374878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8465728163719177    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04766015335917473   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:15.461053229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.461765991 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.462940243 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:15.471904344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622f313c417e402295a266ba201ec379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7568902373313904     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.839374840259552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04388625919818878    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7568902373313904    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.839374840259552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04388625919818878   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.839374840259552, 'test_mse': 0.04388625919818878, 'test_iou': 0.7568902373313904}]\n",
      "MSE value is 0.04388625919818878\n",
      "IoU value is 0.7568902373313904\n",
      "num_param value is 27024\n",
      "Training time: 245.0867509841919\n",
      "Fitness: 17.121466103188823\n",
      "********\n",
      "chromosome: ['Lme3agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: 17.121466103188823, IoU: 0.7568902373313904, FPS: 358.3099129623739, Model Size: 27024\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:26:20.185189822 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.194953223 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.196904092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:26:20.201861616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce2338f05a7406ab7c182e50cb2af6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:33.820231146 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.822147967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.823245865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:33.830429213 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64a5cc8a64844cb8de15b71fde1fff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8025988340377808     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8696420192718506     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06096779182553291    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8025988340377808    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8696420192718506    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06096779182553291   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:41.906065983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.906905401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.907049164 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:41.910872594 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafc90a5f17d4b1abe7a8e01699f8d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7881118059158325     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8763682246208191     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0641445443034172     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7881118059158325    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8763682246208191    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0641445443034172    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8763682246208191, 'test_mse': 0.0641445443034172, 'test_iou': 0.7881118059158325}]\n",
      "MSE value is 0.0641445443034172\n",
      "IoU value is 0.7881118059158325\n",
      "num_param value is 155516\n",
      "Training time: 372.6139988899231\n",
      "Fitness: 17.122821688326226\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 17.122821688326226, IoU: 0.7881118059158325, FPS: 268.1744386008166, Model Size: 155516\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELRr2arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 857212\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:32:48.417225888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:48.417573605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:49.464408698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:32:49.464452775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 857 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "857 K     Trainable params\n",
      "0         Non-trainable params\n",
      "857 K     Total params\n",
      "3.429     Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec3a86477749e1b92f4330fa9cb053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:46:55.959899846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.963261606 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.985854717 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:46:55.994892042 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30521322b9b04e808eb8b0778f4189a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7760270833969116     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8850160241127014     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10006896406412125    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7760270833969116    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8850160241127014    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10006896406412125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:47:12.924992191 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.954028180 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.965585984 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:12.970498076 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c662a3204b4803b8f44a4da5be90cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7684730291366577     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8741776347160339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09866837412118912    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7684730291366577    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8741776347160339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09866837412118912   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8741776347160339, 'test_mse': 0.09866837412118912, 'test_iou': 0.7684730291366577}]\n",
      "MSE value is 0.09866837412118912\n",
      "IoU value is 0.7684730291366577\n",
      "num_param value is 857212\n",
      "Training time: 846.5568082332611\n",
      "Fitness: 15.929445893495721\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.929445893495721, IoU: 0.7684730291366577, FPS: 133.6995172279934, Model Size: 857212\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES2ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:47:27.995200563 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.006020537 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.027911443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:47:27.035911101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c2e49a159d4d769565a110b798bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:06.196278269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.197098088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.199061124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:06.201929959 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dc34b5196047dd906ade84ca6555cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7301934361457825     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8738117814064026     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06117952615022659    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7301934361457825    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8738117814064026    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06117952615022659   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:11.455558817 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.470810092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.470822194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:12.479889724 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f287f95dc5420889aa29aea1ea7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.716360330581665     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.873680830001831     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06103265658020973    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.716360330581665    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.873680830001831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06103265658020973   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.873680830001831, 'test_mse': 0.06103265658020973, 'test_iou': 0.716360330581665}]\n",
      "MSE value is 0.06103265658020973\n",
      "IoU value is 0.716360330581665\n",
      "num_param value is 2855\n",
      "Training time: 99.1759283542633\n",
      "Fitness: 16.585528907980933\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.585528907980933, IoU: 0.716360330581665, FPS: 411.84894055513195, Model Size: 2855\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELme3arn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91684\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:49:16.410407386 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.410875171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.444399189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:49:16.444455953 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.7 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.7 K    Total params\n",
      "0.367     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f579fe6ad0a2402c91ce9bdcf2c7e206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:10.456511875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.470724580 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.482578667 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:10.483941694 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d29e6b194b04a418ce3df0cdcf3b4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6319677829742432     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9113056659698486     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08100445568561554    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6319677829742432    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9113056659698486    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08100445568561554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:15.241091273 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.261956443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.263940163 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:15.266796158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11a8a585ef3490ab4c307958e0efd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6134526133537292     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9139183759689331     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0822879821062088     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6134526133537292    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9139183759689331    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0822879821062088    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9139183759689331, 'test_mse': 0.0822879821062088, 'test_iou': 0.6134526133537292}]\n",
      "MSE value is 0.0822879821062088\n",
      "IoU value is 0.6134526133537292\n",
      "num_param value is 91684\n",
      "Training time: 173.07466959953308\n",
      "Fitness: 15.28252710217133\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.28252710217133, IoU: 0.6134526133537292, FPS: 375.8220736007713, Model Size: 91684\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPM2ELdo08agn1EPM2ELRr3arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 23784678 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'PM2', 'Ldo08agn1', 'PM2', 'LRr3arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELne3arn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 445414\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W817 23:52:21.880719285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.892576194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.917588512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W817 23:52:21.926710945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 445 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "445 K     Trainable params\n",
      "0         Non-trainable params\n",
      "445 K     Total params\n",
      "1.782     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8255a2b09a42d48fc898dc715a86a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:04.264097296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.266837342 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.269819143 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:04.275619831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458c85fd24948189450a7c5a818f9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7328166961669922     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8875967860221863     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0706053376197815     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7328166961669922    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8875967860221863    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0706053376197815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:16.196394979 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.202286852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.204248005 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:16.211238422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d058e7e33d1c4361923703da87b76210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7281855344772339     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8844615817070007     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06893975287675858    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7281855344772339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8844615817070007    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06893975287675858   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8844615817070007, 'test_mse': 0.06893975287675858, 'test_iou': 0.7281855344772339}]\n",
      "MSE value is 0.06893975287675858\n",
      "IoU value is 0.7281855344772339\n",
      "num_param value is 445414\n",
      "Training time: 823.3432140350342\n",
      "Fitness: 16.191505531587115\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: 16.191505531587115, IoU: 0.7281855344772339, FPS: 188.5925089596307, Model Size: 445414\n",
      "\n",
      "Architecture: Ldo11agn1EPa2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['Ldo11agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 40213537 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo11agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco09k5s1p2arn1EPa2ELeo05k5s1p2agn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 10694754 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco09k5s1p2arn1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELeo08k5s1p2agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7541748 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES0ELDd0.30n1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 28910568 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELdo12agn1EPM2ELdo13agn1EUf2mnearestES0ELeo15k3s1p1arn1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 24367770 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo15k3s1p1arn1EPM2ELbo08k3s1p1agn1EUf2mnearestES1ELDd0.50n1EHSasmEE\n",
      "Chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.5}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.5}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7157434 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo15k3s1p1arn1', 'PM2', 'Lbo08k3s1p1agn1', 'Uf2mnearest', 'S1', 'LDd0.50n1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 27219759 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES2ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4239\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:06:28.447225608 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:28.454108401 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:28.455143533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:06:29.461910982 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.2 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "81        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e52c7611878497f87f81932e1c1b029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:42.763016994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.774223520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.776274012 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:42.776451818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7cf362c5e14cb8b31534c86669ece2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46204930543899536    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1784340143203735     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27496302127838135    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46204930543899536   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1784340143203735    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27496302127838135   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:48.563070925 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.574196214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.575036397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:48.576375860 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a9a8f2430463f9af3c94344b45cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46562784910202026    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1850876808166504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.28166523575782776    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46562784910202026   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1850876808166504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.28166523575782776   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1850876808166504, 'test_mse': 0.28166523575782776, 'test_iou': 0.46562784910202026}]\n",
      "MSE value is 0.28166523575782776\n",
      "IoU value is 0.46562784910202026\n",
      "num_param value is 4239\n",
      "Training time: 133.51136541366577\n",
      "Fitness: 12.454388904115707\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S2', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: 12.454388904115707, IoU: 0.46562784910202026, FPS: 376.5758600137161, Model Size: 4239\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 1, the best fitness of the population is 17.122821688326226.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_1.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 2 ***\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:08:54.523219229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.540329040 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.541038467 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:08:54.544383706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4850948491ae44839f870ad5691881b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:18.997607766 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.998018456 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.998771098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:18.999060980 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794b913311d744f58d02a9d57e27546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7786670923233032     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8679985404014587     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05967839062213898    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7786670923233032    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8679985404014587    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05967839062213898   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:26.153915519 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.161320394 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.161961846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:26.165919585 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa064a8e322241eea71b73d3e9171d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7643353939056396     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8672610521316528     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05922425165772438    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7643353939056396    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8672610521316528    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05922425165772438   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8672610521316528, 'test_mse': 0.05922425165772438, 'test_iou': 0.7643353939056396}]\n",
      "MSE value is 0.05922425165772438\n",
      "IoU value is 0.7643353939056396\n",
      "num_param value is 155516\n",
      "Training time: 204.56607103347778\n",
      "Fitness: 16.928709392244556\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.928709392244556, IoU: 0.7643353939056396, FPS: 268.8005344346563, Model Size: 155516\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELme3agn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 6321956 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lme3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme6arn1EPa2ELbo13k3s1p1agn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 189886\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:12:34.760716287 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.776935658 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.780727354 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:12:34.790032904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 189 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.760     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfa0faa29e6419a822dec1009942502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:24:40.592274899 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.594092691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.595121006 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:40.603815523 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a87f06d03ff4af98b26d37ce5689010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7646944522857666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8393237590789795     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04351936653256416    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7646944522857666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8393237590789795    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04351936653256416   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:24:53.750198059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.756993460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.757106989 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:24:53.763061699 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a9bea482024f888cc602d48786846e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7541961669921875     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8390940427780151     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04316077008843422    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7541961669921875    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8390940427780151    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04316077008843422   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8390940427780151, 'test_mse': 0.04316077008843422, 'test_iou': 0.7541961669921875}]\n",
      "MSE value is 0.04316077008843422\n",
      "IoU value is 0.7541961669921875\n",
      "num_param value is 189886\n",
      "Training time: 725.824999332428\n",
      "Fitness: 16.93832573485889\n",
      "********\n",
      "chromosome: ['Lme6arn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: 16.93832573485889, IoU: 0.7541961669921875, FPS: 170.70178847629518, Model Size: 189886\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES0ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:25:05.577849985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.577921265 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.579904102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:25:05.580946768 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243110dd1b654b1483ff726d5af0dba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:43.844331508 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.852434856 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.853458845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:43.861171093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec288bb22723418b9c0b8e0959ca2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7495232820510864     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8797957301139832     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06333170086145401    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7495232820510864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8797957301139832    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06333170086145401   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:48.284246091 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.292026792 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.292034578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:48.294712990 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5600b06265b465ca7d5891e0cfa5c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7487450838088989     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8772498369216919     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06117401644587517    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7487450838088989    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8772498369216919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06117401644587517   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8772498369216919, 'test_mse': 0.06117401644587517, 'test_iou': 0.7487450838088989}]\n",
      "MSE value is 0.06117401644587517\n",
      "IoU value is 0.7487450838088989\n",
      "num_param value is 2855\n",
      "Training time: 98.26789474487305\n",
      "Fitness: 16.908120957458557\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.908120957458557, IoU: 0.7487450838088989, FPS: 388.2184337724817, Model Size: 2855\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELco05k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 448389\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:26:54.527812576 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.533997597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.538257654 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:26:54.543382523 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 448 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "448 K     Trainable params\n",
      "0         Non-trainable params\n",
      "448 K     Total params\n",
      "1.794     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c51565f6bb412e89e95b19c9d9f344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:27.941914825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.944604870 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.945036039 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:27.953672364 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46917014b5474f019d94a7d5a2e6b332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7279489040374756     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8697322607040405     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060768406838178635    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7279489040374756    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8697322607040405    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060768406838178635   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:39.436357176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.441750852 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.446725461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:39.450277527 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810f9244cb44a0fadb80e1603cc5bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7172728180885315     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8685995936393738     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060260165482759476    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7172728180885315    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8685995936393738    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060260165482759476   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8685995936393738, 'test_mse': 0.060260165482759476, 'test_iou': 0.7172728180885315}]\n",
      "MSE value is 0.060260165482759476\n",
      "IoU value is 0.7172728180885315\n",
      "num_param value is 448389\n",
      "Training time: 753.3821873664856\n",
      "Fitness: 16.15598654966747\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2agn1', 'HSasm'], fitness: 16.15598654966747, IoU: 0.7172728180885315, FPS: 179.93305036614836, Model Size: 448389\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 00:39:51.593161770 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.605200116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.605419042 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 00:39:51.611003943 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557505c66d8d40feadebc2d332430f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:02:54.861192073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.868181327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.868439808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:02:54.870626095 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623abf9e00b54f64907b13427b71b6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.75431889295578      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8948533535003662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09603867679834366    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.75431889295578     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8948533535003662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09603867679834366   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:03:12.592821941 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.593443601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.593986117 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:12.602369997 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c380382fa4ffea1b6491c44b95fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7345479130744934     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8998154401779175     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10632448643445969    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7345479130744934    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8998154401779175    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10632448643445969   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8998154401779175, 'test_mse': 0.10632448643445969, 'test_iou': 0.7345479130744934}]\n",
      "MSE value is 0.10632448643445969\n",
      "IoU value is 0.7345479130744934\n",
      "num_param value is 876202\n",
      "Training time: 1383.218773841858\n",
      "Fitness: 15.508216540129883\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.508216540129883, IoU: 0.7345479130744934, FPS: 128.51886826042616, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELme3arn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91684\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:03:27.244904503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.246881297 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.248817509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:03:27.257996893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.7 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.7 K    Total params\n",
      "0.367     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce29b214bb14421aa1c7260e13628e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:38.009277739 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.011546666 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.014095101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:38.018616722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b72885dd0b44de99113dfeae2b4dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.648859977722168     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9115615487098694     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08111194521188736    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.648859977722168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9115615487098694    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08111194521188736   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:44.275046637 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.278382347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.280293385 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:44.287423806 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c67867c7b144f7a47c261bac1740bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6499044895172119     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9110153913497925     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08094775676727295    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6499044895172119    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9110153913497925    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08094775676727295   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9110153913497925, 'test_mse': 0.08094775676727295, 'test_iou': 0.6499044895172119}]\n",
      "MSE value is 0.08094775676727295\n",
      "IoU value is 0.6499044895172119\n",
      "num_param value is 91684\n",
      "Training time: 130.75279068946838\n",
      "Fitness: 15.658501792033235\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'Lme3arn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.658501792033235, IoU: 0.6499044895172119, FPS: 343.6689847210305, Model Size: 91684\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:05:50.193996431 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.199889230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.200184992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:05:50.204690327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb86417adb2d4c3089e686df8ace4074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:08:56.564630036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.566857878 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.567973826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:08:56.575975957 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e592e2d014e84f5691ca8c803fb20372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7724882960319519     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8434401154518127     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045673616230487823    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7724882960319519    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8434401154518127    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045673616230487823   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:09:01.344591875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.348479921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.349930955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:01.350515255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e73c80923b401c92389617808e9070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7665195465087891     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8429293036460876     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.045077964663505554    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7665195465087891    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8429293036460876    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.045077964663505554   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8429293036460876, 'test_mse': 0.045077964663505554, 'test_iou': 0.7665195465087891}]\n",
      "MSE value is 0.045077964663505554\n",
      "IoU value is 0.7665195465087891\n",
      "num_param value is 18862\n",
      "Training time: 185.42162656784058\n",
      "Fitness: 17.214997563005028\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 17.214997563005028, IoU: 0.7665195465087891, FPS: 374.4654834629315, Model Size: 18862\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES2ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S2', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES1ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 10107519 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELeo05k5s1p2agn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1236624\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:09:08.686595672 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.686648921 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.687688847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:09:08.695652874 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.946     Total estimated model params size (MB)\n",
      "38        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985e58afe1f41f89e0231b47d73c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:34:26.964499905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.970954501 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.974106635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:26.981389376 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ab2934d5e145d4b77e0c5c983dd8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8193681240081787     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.876876711845398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06460625678300858    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8193681240081787    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.876876711845398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06460625678300858   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:34:51.599770014 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.601739488 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.603691842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:34:51.611084875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6270dde86a1441b0bae877ad793f3716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8094890713691711     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8869012594223022     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06989122927188873    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8094890713691711    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8869012594223022    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06989122927188873   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8869012594223022, 'test_mse': 0.06989122927188873, 'test_iou': 0.8094890713691711}]\n",
      "MSE value is 0.06989122927188873\n",
      "IoU value is 0.8094890713691711\n",
      "num_param value is 1236624\n",
      "Training time: 1518.299451828003\n",
      "Fitness: 16.205011248466025\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Leo05k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 16.205011248466025, IoU: 0.8094890713691711, FPS: 92.96105844518428, Model Size: 1236624\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELeo08k5s1p2agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7541748 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Leo08k5s1p2agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr3arn1EPM2ELeo13k3s1p1agn1EPM2ELDd0.30n1EPa2ELdo04arn1EUf2mnearestES0ELeo15k3s1p1arn1EUf2mnearestES1ELeo13k3s1p1agn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 34089378 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr3arn1', 'PM2', 'Leo13k3s1p1agn1', 'PM2', 'LDd0.30n1', 'Pa2', 'Ldo04arn1', 'Uf2mnearest', 'S0', 'Leo15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Leo13k3s1p1agn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2arn1EPa2ELdo12agn1EPM2ELdo13agn1EUf2mnearestES0ELDd0.30n1EUf2mnearestES0ELco05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 24367770 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco05k5s1p2arn1', 'Pa2', 'Ldo12agn1', 'PM2', 'Ldo13agn1', 'Uf2mnearest', 'S0', 'LDd0.30n1', 'Uf2mnearest', 'S0', 'Lco05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 248712443 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 86538\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:35:15.035707967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.055409283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.056958847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:35:15.064881269 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 86.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "86.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.5 K    Total params\n",
      "0.346     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24cee98359340e3a00c4e80190cb51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:38:56.752435849 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.759818329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.760916009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:38:56.770416799 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1127ca3b304fa197486e06b34e356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5709845423698425     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9033698439598083     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09791910648345947    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5709845423698425    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9033698439598083    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09791910648345947   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:39:05.488508404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.489352132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.489420604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:05.497082022 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49187bbf81a44f82b574458ca2a7bd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5471180081367493     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9005675911903381     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09943404793739319    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5471180081367493    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9005675911903381    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09943404793739319   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9005675911903381, 'test_mse': 0.09943404793739319, 'test_iou': 0.5471180081367493}]\n",
      "MSE value is 0.09943404793739319\n",
      "IoU value is 0.5471180081367493\n",
      "num_param value is 86538\n",
      "Training time: 220.97202706336975\n",
      "Fitness: 14.480230869763325\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 14.480230869763325, IoU: 0.5471180081367493, FPS: 251.0198813804566, Model Size: 86538\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne6arn1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2017775\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 01:39:13.867801710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.869177707 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.870726833 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 01:39:13.874104955 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.0 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.071     Total estimated model params size (MB)\n",
      "59        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b1666232c416a86100f05272462e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:04:48.644077830 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.647544550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.648432302 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:04:48.657765127 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a33f810b6f41528a97ca030d31a6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7768922448158264     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8403710722923279     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11396994441747665    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7768922448158264    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8403710722923279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11396994441747665   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:05:21.743013181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.746614879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.747645314 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:21.757727998 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3625c4338c476bab40cd831722ab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7706284523010254     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8351418375968933     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11580067127943039    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7706284523010254    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8351418375968933    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11580067127943039   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8351418375968933, 'test_mse': 0.11580067127943039, 'test_iou': 0.7706284523010254}]\n",
      "MSE value is 0.11580067127943039\n",
      "IoU value is 0.7706284523010254\n",
      "num_param value is 2017775\n",
      "Training time: 1534.8301301002502\n",
      "Fitness: 14.650683733331817\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: 14.650683733331817, IoU: 0.7706284523010254, FPS: 69.45987229765886, Model Size: 2017775\n",
      "\n",
      "For generation 2, the best fitness of the population is 17.214997563005028.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_2.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 3 ***\n",
      "Architecture: Lne3agn1EPM2ELco04k5s1p2arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 18862\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:05:50.764708038 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.765753624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.767650456 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:05:50.769973666 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 18.9 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe715e847c24638ac226b3ec7ab52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:18.377625771 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.377707799 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.381609824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:18.389759357 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c866f8f3de804d5d9107c224cfe25920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6911529898643494     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9236199259757996     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0851404070854187     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6911529898643494    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9236199259757996    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0851404070854187    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:24.194169418 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.196253847 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.201083966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:24.205218433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963d2d3b7d604eb68415f2836b4f023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6805527806282043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9368762373924255     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09136483818292618    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6805527806282043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9368762373924255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09136483818292618   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9368762373924255, 'test_mse': 0.09136483818292618, 'test_iou': 0.6805527806282043}]\n",
      "MSE value is 0.09136483818292618\n",
      "IoU value is 0.6805527806282043\n",
      "num_param value is 18862\n",
      "Training time: 148.70190143585205\n",
      "Fitness: 15.949504529077577\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.949504529077577, IoU: 0.6805527806282043, FPS: 371.4892646143948, Model Size: 18862\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELbo13k3s1p1agn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 27063456 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lbo13k3s1p1agn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:08:30.915500444 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.918574631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.919545809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:08:30.923563022 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560868a1268a4c6ca969e5bb92eec4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:35.328839448 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.335034411 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.335245138 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:35.337207011 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfecb5dd0ce4d6eb7432e50eb17c50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7959802746772766     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8919023275375366     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07192771881818771    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7959802746772766    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8919023275375366    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07192771881818771   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:44.687067535 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.688519228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.689987485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:44.697797184 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16710320494db1af8f208820ab6f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7837731242179871     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8980788588523865     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07474220544099808    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7837731242179871    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8980788588523865    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07474220544099808   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8980788588523865, 'test_mse': 0.07474220544099808, 'test_iou': 0.7837731242179871}]\n",
      "MSE value is 0.07474220544099808\n",
      "IoU value is 0.7837731242179871\n",
      "num_param value is 155516\n",
      "Training time: 305.4734237194061\n",
      "Fitness: 16.986772139056093\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 16.986772139056093, IoU: 0.7837731242179871, FPS: 260.69257777992414, Model Size: 155516\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES1ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2855\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:13:52.492425270 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.493369774 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.495756254 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:13:52.499871545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.9 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536e3f1511d946388e1109d2fd9a00e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:15:49.373181644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.378475488 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.383954073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:49.391531578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5ab83171ad4b07819a55c9cf1ee775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7057086825370789     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.877724826335907     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06278485804796219    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7057086825370789    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.877724826335907    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06278485804796219   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:15:55.697117624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.698857663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.700293005 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:15:55.703640079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622dfac3eb3749819392ff22e2c35499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6862832307815552     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8808153867721558     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06416567414999008    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6862832307815552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8808153867721558    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06416567414999008   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8808153867721558, 'test_mse': 0.06416567414999008, 'test_iou': 0.6862832307815552}]\n",
      "MSE value is 0.06416567414999008\n",
      "IoU value is 0.6862832307815552\n",
      "num_param value is 2855\n",
      "Training time: 117.87220668792725\n",
      "Fitness: 16.257010347795504\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 16.257010347795504, IoU: 0.6862832307815552, FPS: 399.26960091735873, Model Size: 2855\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELme4arn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50467\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:16:00.816382066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.824084562 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.824949305 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:16:00.827561939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 50.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "50.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.5 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f2146bbfd945ce92d25aaacda2f3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:23.537045689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.538061677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.538995155 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:23.543148205 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cc8e3a88a24ba2a3ca22567531654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7190388441085815     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9395378828048706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09387846291065216    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7190388441085815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9395378828048706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09387846291065216   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:28.215054615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.221205505 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.221370257 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:28.223594836 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57be8a97f0b54140ada4bc9daf8dd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7106996178627014     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9573715925216675     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10259950906038284    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7106996178627014    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9573715925216675    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10259950906038284   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9573715925216675, 'test_mse': 0.10259950906038284, 'test_iou': 0.7106996178627014}]\n",
      "MSE value is 0.10259950906038284\n",
      "IoU value is 0.7106996178627014\n",
      "num_param value is 50467\n",
      "Training time: 202.77884531021118\n",
      "Fitness: 16.126005373589077\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 16.126005373589077, IoU: 0.7106996178627014, FPS: 381.71282169078336, Model Size: 50467\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:19:34.567928851 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.578223453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.579072459 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:19:34.587599436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dda8116493d4e62ad9a68eaa262bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:24:52.684659948 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.690333259 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.692100613 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:24:52.697191463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9503deaec74f97a85f34df6d5d1f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6649729013442993     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8976973295211792     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07292557507753372    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6649729013442993    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8976973295211792    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07292557507753372   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:25:00.543315350 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.545012214 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.547977498 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:00.549280107 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27a52b02bdd4d70b1e3e2de85403258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6736959218978882     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8867667317390442     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06691915541887283    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6736959218978882    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8867667317390442    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06691915541887283   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8867667317390442, 'test_mse': 0.06691915541887283, 'test_iou': 0.6736959218978882}]\n",
      "MSE value is 0.06691915541887283\n",
      "IoU value is 0.6736959218978882\n",
      "num_param value is 47394\n",
      "Training time: 318.12419986724854\n",
      "Fitness: 16.062346604719394\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.062346604719394, IoU: 0.6736959218978882, FPS: 277.23487313011805, Model Size: 47394\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:25:07.916104147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.918478977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.918491018 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:25:07.925830628 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3069e86bedf34f529bc4b02a183c4d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:36.608987815 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.614563622 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.615421581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:36.624502170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf78757dfc04b58809686dab30539fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6375889778137207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9469380974769592     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09058068692684174    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6375889778137207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9469380974769592    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09058068692684174   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:42.927658561 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.927667037 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.929952530 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:42.932060807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7c8964fd644d14aa8b59e705570360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.620185136795044     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9420939087867737     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08805166929960251    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.620185136795044    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9420939087867737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08805166929960251   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9420939087867737, 'test_mse': 0.08805166929960251, 'test_iou': 0.620185136795044}]\n",
      "MSE value is 0.08805166929960251\n",
      "IoU value is 0.620185136795044\n",
      "num_param value is 91054\n",
      "Training time: 148.73982191085815\n",
      "Fitness: 15.301537368778867\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.301537368778867, IoU: 0.620185136795044, FPS: 337.0618804455677, Model Size: 91054\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:27:48.970239449 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.973327833 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.973359057 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:27:48.975737855 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d0a25cba574898ae61c99d819d9ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:42:30.917544839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.918501787 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.919455375 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:30.922577189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c571415fc1a478fbf6ee81b223f8ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.749896764755249     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9079797863960266     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10712637007236481    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.749896764755249    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9079797863960266    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10712637007236481   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:42:48.651930721 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.652439113 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.653981983 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:42:48.657021571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b78a4bfaa274bd09ea965a4375c401d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7347415685653687     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.910155713558197     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11219007521867752    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7347415685653687    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.910155713558197    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11219007521867752   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.910155713558197, 'test_mse': 0.11219007521867752, 'test_iou': 0.7347415685653687}]\n",
      "MSE value is 0.11219007521867752\n",
      "IoU value is 0.7347415685653687\n",
      "num_param value is 876202\n",
      "Training time: 881.9403738975525\n",
      "Fitness: 15.462482554901431\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.462482554901431, IoU: 0.7347415685653687, FPS: 128.0235844228323, Model Size: 876202\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne6arn1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3196505\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 02:43:03.398073782 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.398753988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.400672424 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 02:43:03.404952732 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.786    Total estimated model params size (MB)\n",
      "60        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb363885b114923a217efd81da3166a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:09:51.669508510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.670318200 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.671200764 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:09:51.671886624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa78749f9f754a72bdb92e54fc550a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5265118479728699     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9190140962600708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14735545217990875    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5265118479728699    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9190140962600708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14735545217990875   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:10:36.631395807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.638398055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.643588232 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:10:36.646392326 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28ad5e8111b41e1a678737eef172111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5125477910041809     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9170017242431641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1476600617170334     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5125477910041809    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9170017242431641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1476600617170334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9170017242431641, 'test_mse': 0.1476600617170334, 'test_iou': 0.5125477910041809}]\n",
      "MSE value is 0.1476600617170334\n",
      "IoU value is 0.5125477910041809\n",
      "num_param value is 3196505\n",
      "Training time: 1607.2766788005829\n",
      "Fitness: 10.642354453561616\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 10.642354453561616, IoU: 0.5125477910041809, FPS: 51.496086783647456, Model Size: 3196505\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 610197\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:11:15.571812553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.574880102 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.574961049 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:11:15.579993777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 610 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "610 K     Trainable params\n",
      "0         Non-trainable params\n",
      "610 K     Total params\n",
      "2.441     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e0ba89ce264b98987b8d1d5e895ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:20.867839100 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.873004859 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.876500966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:20.879213985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a79bec4f9704dc7acd71725d1b85e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6371888518333435     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8643619418144226     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0882449746131897     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6371888518333435    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8643619418144226    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0882449746131897    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:35.694612980 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.696570654 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.697437103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:35.706095541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc3f18e357c41b4b7f1606b798b9c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6309760212898254     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8680739402770996     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09702488034963608    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6309760212898254    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8680739402770996    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09702488034963608   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8680739402770996, 'test_mse': 0.09702488034963608, 'test_iou': 0.6309760212898254}]\n",
      "MSE value is 0.09702488034963608\n",
      "IoU value is 0.6309760212898254\n",
      "num_param value is 610197\n",
      "Training time: 785.3572561740875\n",
      "Fitness: 14.815126751268387\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 14.815126751268387, IoU: 0.6309760212898254, FPS: 152.60105730969573, Model Size: 610197\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES2ELdo08agn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELdo11agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 10107519 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'Ldo11agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPM2ELdo09agn1EUf2mnearestES2ELbo15k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 15, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 11770350 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.30n1', 'PM2', 'Ldo09agn1', 'Uf2mnearest', 'S2', 'Lbo15k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3505016\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 03:24:49.452311378 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.452330408 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.452543351 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 03:24:49.456928660 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.020    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34812a87da9c4995aefffe8fcf3e1620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:18:14.884987540 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.890383692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.890414255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:18:14.895258127 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e5232755b4f358e3a78dfb71aaf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4363898038864136     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0084519386291504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3988874554634094     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4363898038864136    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0084519386291504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3988874554634094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:19:04.119647041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.128291377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.128333550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:04.137589404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c86aa43ff44cb8e25a8a307b4a1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4341442584991455     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9872403740882874     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.37467679381370544    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4341442584991455    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9872403740882874    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.37467679381370544   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9872403740882874, 'test_mse': 0.37467679381370544, 'test_iou': 0.4341442584991455}]\n",
      "MSE value is 0.37467679381370544\n",
      "IoU value is 0.4341442584991455\n",
      "num_param value is 3505016\n",
      "Training time: 3204.7224490642548\n",
      "Fitness: 8.110863779975622\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 8.110863779975622, IoU: 0.4341442584991455, FPS: 46.09833061401471, Model Size: 3505016\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 3, the best fitness of the population is 16.986772139056093.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_3.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 4 ***\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELme5arn1EUf2mnearestES0ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 155516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:19:48.092781775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.098118291 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.099285855 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:19:48.104663904 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 155 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.622     Total estimated model params size (MB)\n",
      "50        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa31090c3dd4d63aeee0089026f678f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:20.708815029 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.737854026 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.739891460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:20.743492727 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387f3899170d4143b2d7c8e28780797e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6175004243850708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.133171796798706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19043885171413422    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6175004243850708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.133171796798706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19043885171413422   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:28.985816423 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.986802455 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.986905806 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:28.987849525 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f467b185a8d34635b4830bbb2907f061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6111463904380798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.129359245300293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18758484721183777    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6111463904380798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.129359245300293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18758484721183777   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.129359245300293, 'test_mse': 0.18758484721183777, 'test_iou': 0.6111463904380798}]\n",
      "MSE value is 0.18758484721183777\n",
      "IoU value is 0.6111463904380798\n",
      "num_param value is 155516\n",
      "Training time: 271.78137254714966\n",
      "Fitness: 14.376398892348169\n",
      "********\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Lme5arn1', 'Uf2mnearest', 'S0', 'Leo04k3s1p1arn1', 'HSasm'], fitness: 14.376398892348169, IoU: 0.6111463904380798, FPS: 265.5517089014598, Model Size: 155516\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES1ELDd0.40n1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 321780\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:24:36.626655512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.629465242 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.632597848 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:24:36.640667759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 321 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "321 K     Trainable params\n",
      "0         Non-trainable params\n",
      "321 K     Total params\n",
      "1.287     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60708011332247b7a04dd18549614dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:38.863090208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.863219175 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.864382315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:38.869860069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367bb6d4f0464aeb8ded3f47931e671a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.601272702217102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3283042907714844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.292317658662796     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.601272702217102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3283042907714844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.292317658662796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:46.348024624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.353437633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.353694655 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:46.357434681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e017320527ca460487e09ab9c25a7f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6023015975952148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3244633674621582     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2903972268104553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6023015975952148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3244633674621582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2903972268104553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.3244633674621582, 'test_mse': 0.2903972268104553, 'test_iou': 0.6023015975952148}]\n",
      "MSE value is 0.2903972268104553\n",
      "IoU value is 0.6023015975952148\n",
      "num_param value is 321780\n",
      "Training time: 302.2469789981842\n",
      "Fitness: 13.450787658357372\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'LDd0.40n1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: 13.450787658357372, IoU: 0.6023015975952148, FPS: 260.35047001988954, Model Size: 321780\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELme4arn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 50467\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:29:54.102735349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.111041249 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.113094697 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:29:54.122484691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 50.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "50.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.5 K    Total params\n",
      "0.202     Total estimated model params size (MB)\n",
      "39        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316e998f720b41e2afe1f933295551e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:17.095836858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.098329709 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.115232333 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:17.120214120 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccd30c26ef465abaf7d2b5d028868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6906546950340271     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.964706540107727     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10612887889146805    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6906546950340271    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.964706540107727    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10612887889146805   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:23.808125069 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.808126573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.810844536 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:23.815908137 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e1b56501934f60b4a33c2f58ef504a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6790745258331299     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9789044857025146     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11318682134151459    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6790745258331299    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9789044857025146    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11318682134151459   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9789044857025146, 'test_mse': 0.11318682134151459, 'test_iou': 0.6790745258331299}]\n",
      "MSE value is 0.11318682134151459\n",
      "IoU value is 0.6790745258331299\n",
      "num_param value is 50467\n",
      "Training time: 202.97309684753418\n",
      "Fitness: 15.723496356394014\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: 15.723496356394014, IoU: 0.6790745258331299, FPS: 376.58654427383703, Model Size: 50467\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:33:28.211591686 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.212609680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.213619593 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:33:28.221742865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb1d8d3e6c94859b19110e2d6e8e0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:38:46.331257867 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.351821128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.352158646 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:46.361608196 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39741271e6b4d9db4e8d135de3e51eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6475337147712708     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8990762829780579     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0742703229188919     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6475337147712708    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8990762829780579    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0742703229188919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:38:54.221483304 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.229355131 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.230113035 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:38:54.236406280 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4cf5c82d274f39b43bad91c2b9a10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6350592970848083     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9012433290481567     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07496412098407745    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6350592970848083    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9012433290481567    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07496412098407745   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9012433290481567, 'test_mse': 0.07496412098407745, 'test_iou': 0.6350592970848083}]\n",
      "MSE value is 0.07496412098407745\n",
      "IoU value is 0.6350592970848083\n",
      "num_param value is 47394\n",
      "Training time: 318.1243939399719\n",
      "Fitness: 15.605835035431788\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 15.605835035431788, IoU: 0.6350592970848083, FPS: 277.60163088734316, Model Size: 47394\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELme4arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:39:02.515035466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.518134464 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.521071945 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:39:02.522017605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f46de3e0ed840da86095272eb72e7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:40:51.963522560 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.964459441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.966895208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:51.970378393 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22d4315386b40728c52c9275454c693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6498749852180481     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.916018545627594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0806988850235939     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6498749852180481    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.916018545627594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0806988850235939    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:40:56.171118158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.173093893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.175861240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:40:56.177200917 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535b13736a424e22915202404de4c7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6553024053573608     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.906862735748291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07563789933919907    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6553024053573608    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.906862735748291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07563789933919907   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.906862735748291, 'test_mse': 0.07563789933919907, 'test_iou': 0.6553024053573608}]\n",
      "MSE value is 0.07563789933919907\n",
      "IoU value is 0.6553024053573608\n",
      "num_param value is 2573\n",
      "Training time: 109.43885493278503\n",
      "Fitness: 15.847259957521063\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.847259957521063, IoU: 0.6553024053573608, FPS: 405.761374558758, Model Size: 2573\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:41:01.202030693 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.204430937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.208177209 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:41:01.216130513 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab7ccc2417f4e6abfc23df7df3b3886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:55:41.436454858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.436454597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.440632807 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:41.440726031 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd73cb059af9410382d166c9f7552dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7620817422866821     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.896282434463501     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1342364102602005     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7620817422866821    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.896282434463501    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1342364102602005    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:55:59.181416123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.189089629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.190140194 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:55:59.191233177 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f088626d7946a19cb437e0a8b20caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7587275505065918     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8839991688728333     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13036616146564484    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7587275505065918    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8839991688728333    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13036616146564484   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8839991688728333, 'test_mse': 0.13036616146564484, 'test_iou': 0.7587275505065918}]\n",
      "MSE value is 0.13036616146564484\n",
      "IoU value is 0.7587275505065918\n",
      "num_param value is 876202\n",
      "Training time: 880.2447843551636\n",
      "Fitness: 15.557764374716417\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.557764374716417, IoU: 0.7587275505065918, FPS: 127.42829734608182, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:56:15.987005853 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.994112010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.994158735 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:56:15.002484796 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef55fd7a9b6c44a29cac74359a7707c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:43.017431101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.020331839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.023171568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:43.025648222 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0750abde3a7436085394c48fec3dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6436501145362854     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9415942430496216     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08751361072063446    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6436501145362854    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9415942430496216    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08751361072063446   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:49.057994167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.060401554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.060909288 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:49.063389124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7417d08355c4627bbe0bdcb43b8b9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6219373941421509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9371283054351807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08504777401685715    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6219373941421509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9371283054351807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08504777401685715   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9371283054351807, 'test_mse': 0.08504777401685715, 'test_iou': 0.6219373941421509}]\n",
      "MSE value is 0.08504777401685715\n",
      "IoU value is 0.6219373941421509\n",
      "num_param value is 91054\n",
      "Training time: 148.04842376708984\n",
      "Fitness: 15.34450400212872\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.34450400212872, IoU: 0.6219373941421509, FPS: 352.9902265655968, Model Size: 91054\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4543231\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 04:58:55.845939023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.846896148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.846949281 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 04:58:55.856029451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "18.173    Total estimated model params size (MB)\n",
      "67        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a0b18c8cd04cb6be2ac091c07c3add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:05:52.356491216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.377810453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.432427252 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:05:52.432447353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c6ff735f964eb0ae5f6b81a44073a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5579782128334045     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9120903611183167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14606435596942902    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5579782128334045    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9120903611183167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14606435596942902   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:06:37.972698240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.987547531 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.036398891 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:06:37.036437947 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5498ede13ac04b28b918889d39f54b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5482544898986816     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9067445993423462     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13763146102428436    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5482544898986816    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9067445993423462    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13763146102428436   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9067445993423462, 'test_mse': 0.13763146102428436, 'test_iou': 0.5482544898986816}]\n",
      "MSE value is 0.13763146102428436\n",
      "IoU value is 0.5482544898986816\n",
      "num_param value is 3196099\n",
      "Training time: 1601.644122838974\n",
      "Fitness: 11.076638806447676\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Lne6arn1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 11.076638806447676, IoU: 0.5482544898986816, FPS: 51.75045407762942, Model Size: 3196099\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELne5arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 6205920 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELco16k3s1p1arn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 40533248 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPa2ELdo08agn1EUf2mnearestES1ELne4agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPM2ELbo09k5s1p2arn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 13888077 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo09k3s1p1arn1EPa2ELdo08agn1EPM2ELco04k5s1p2arn1EUf2mnearestES2ELdo08agn1EUf2mnearestES0ELdo12agn1EHSasmEE\n",
      "Chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo12agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32446134 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo09k3s1p1arn1', 'Pa2', 'Ldo08agn1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S2', 'Ldo08agn1', 'Uf2mnearest', 'S0', 'Ldo12agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1280062\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:07:17.372022627 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.376750966 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.378572485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:07:17.379814753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.3 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.120     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a01745870474921a8ef278648386844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:21:22.013974754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:22.017723263 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:22.048381677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:22.058516908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fda495994da47168896571a7c263986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4276241362094879     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2003282308578491     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.510887086391449     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4276241362094879    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2003282308578491    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.510887086391449    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:21:44.454659861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:45.462008384 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:45.500415546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:21:45.500447499 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c7dc2726e04e7fbdc35ebf9ccdf0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4044674336910248     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2120970487594604     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5104751586914062     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4044674336910248    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2120970487594604    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5104751586914062    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.2120970487594604, 'test_mse': 0.5104751586914062, 'test_iou': 0.4044674336910248}]\n",
      "MSE value is 0.5104751586914062\n",
      "IoU value is 0.4044674336910248\n",
      "num_param value is 1280062\n",
      "Training time: 844.9460391998291\n",
      "Fitness: 9.385045610810266\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'Pa2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: 9.385045610810266, IoU: 0.4044674336910248, FPS: 102.28328568140958, Model Size: 1280062\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 8623751 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 44328\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:22:04.245638421 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:22:04.247613050 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:22:04.256902082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:22:04.262090923 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 44.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "44.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.3 K    Total params\n",
      "0.177     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49830ed41a5d4c4dbd63d4ad89c39651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:25:32.944393398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:32.946533108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:32.000397101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:32.000427800 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f62541e8674329a861424cd2b25287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5931624174118042     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8503093719482422     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07990358024835587    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5931624174118042    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8503093719482422    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07990358024835587   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:25:39.201258063 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:39.223216398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:39.272401360 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:39.272454629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa487429146417283048928bc0def43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5928252935409546     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8480120301246643     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07676894962787628    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5928252935409546    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8480120301246643    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07676894962787628   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8480120301246643, 'test_mse': 0.07676894962787628, 'test_iou': 0.5928252935409546}]\n",
      "MSE value is 0.07676894962787628\n",
      "IoU value is 0.5928252935409546\n",
      "num_param value is 44328\n",
      "Training time: 207.7038414478302\n",
      "Fitness: 15.1709683660879\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 15.1709683660879, IoU: 0.5928252935409546, FPS: 300.0543692876479, Model Size: 44328\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 113597946 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 12830160 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 4, the best fitness of the population is 15.847259957521063.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_4.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 5 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: Lne3agn1EPM2ELme4arn1EUf2mnearestES0ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:25:47.359965142 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:47.365272854 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:47.370549320 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:25:47.374323148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf132e1e98d4827908fd1675f9a153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:27:26.953583809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:26.955291621 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:26.024439625 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:26.024451519 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a542364da83f4dcc84787462ef1014a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6212360858917236     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9311441779136658     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08304701745510101    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6212360858917236    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9311441779136658    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08304701745510101   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:27:31.016628381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:31.016784999 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:31.080451537 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:31.080449210 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f14387833af4d9e8a78e889c1955aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6268590092658997     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9214279055595398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07710559666156769    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6268590092658997    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9214279055595398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07710559666156769   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9214279055595398, 'test_mse': 0.07710559666156769, 'test_iou': 0.6268590092658997}]\n",
      "MSE value is 0.07710559666156769\n",
      "IoU value is 0.6268590092658997\n",
      "num_param value is 2573\n",
      "Training time: 98.84354567527771\n",
      "Fitness: 15.550157877921345\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne3agn1', 'HSasm'], fitness: 15.550157877921345, IoU: 0.6268590092658997, FPS: 421.3279981042619, Model Size: 2573\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELme4arn1EUf2mnearestES1ELeo10k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 12711444 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:27:36.054759470 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:36.078754777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:36.079714738 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:27:36.089032766 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f12c5b1d6a4bf2a1aeeb894c48066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:32:54.112471913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:32:54.113150982 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:32:54.168411590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:32:54.168456778 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6252f84b87f4f9c8560d1181d4403dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6793659925460815     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8703804612159729     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05926204100251198    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6793659925460815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8703804612159729    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05926204100251198   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:33:02.834348007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:02.840900670 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:02.916413994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:02.916451445 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efb60315ed54a47a40bdb3999082835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6768401861190796     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8659997582435608     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.056744061410427094    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6768401861190796    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8659997582435608    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.056744061410427094   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8659997582435608, 'test_mse': 0.056744061410427094, 'test_iou': 0.6768401861190796}]\n",
      "MSE value is 0.056744061410427094\n",
      "IoU value is 0.6768401861190796\n",
      "num_param value is 47394\n",
      "Training time: 318.1113600730896\n",
      "Fitness: 16.184037146307464\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.184037146307464, IoU: 0.6768401861190796, FPS: 282.63230743018084, Model Size: 47394\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPa2ELRr2arn1EPa2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:33:09.025832885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:09.032398344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:09.064378916 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:33:09.064426777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b39004cfdd54a56912d7549165d28e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:45:45.952948869 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:45:45.957588466 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:45:45.971295604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:45:45.972257206 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70faf51927344a0b9bf47f15581a65ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7457504868507385     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9001950621604919     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17630429565906525    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7457504868507385    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9001950621604919    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17630429565906525   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:46:03.492825582 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:03.498273887 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:03.508764398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:03.518307845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df23b696ef4358b24169f7798118ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.732955813407898     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9008893370628357     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18714021146297455    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.732955813407898    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9008893370628357    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18714021146297455   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9008893370628357, 'test_mse': 0.18714021146297455, 'test_iou': 0.732955813407898}]\n",
      "MSE value is 0.18714021146297455\n",
      "IoU value is 0.732955813407898\n",
      "num_param value is 876202\n",
      "Training time: 755.9277400970459\n",
      "Fitness: 14.876960947933679\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 14.876960947933679, IoU: 0.732955813407898, FPS: 129.3948686282235, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES1ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:46:18.038698410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:18.055967199 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:18.069051831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:46:18.076365008 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea7e7af00874a0caf027156f679fc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:48:46.992735617 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:46.994744616 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:46.996788099 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:46.005405978 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e622b7d28042f592304c3c301c891b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6476353406906128     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9377949237823486     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0850132629275322     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6476353406906128    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9377949237823486    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0850132629275322    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:48:52.770816698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:52.777440568 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:52.778606679 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:52.785207181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37044d0c3a4b42bea1d4f5505420ccab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6214554309844971     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9340677857398987     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08278970420360565    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6214554309844971    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9340677857398987    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08278970420360565   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9340677857398987, 'test_mse': 0.08278970420360565, 'test_iou': 0.6214554309844971}]\n",
      "MSE value is 0.08278970420360565\n",
      "IoU value is 0.6214554309844971\n",
      "num_param value is 91054\n",
      "Training time: 147.9345781803131\n",
      "Fitness: 15.358903972419526\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.358903972419526, IoU: 0.6214554309844971, FPS: 370.9277075030477, Model Size: 91054\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 44328\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:48:57.274386340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:57.291712706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:57.300307082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:48:57.300381256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 44.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "44.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.3 K    Total params\n",
      "0.177     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c635ba5150482dba6dcda44394f939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:52:51.715039850 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:51.716424080 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:51.740475055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:51.740474509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4343b10c98ba4cbbbca7cd0de418808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5718855261802673     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8936533331871033     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09346336126327515    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5718855261802673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8936533331871033    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09346336126327515   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:52:58.100342158 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:58.103592030 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:58.148396693 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:52:58.148446675 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987ee4d40804fe59b6c961c31649f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5667672157287598     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8967103362083435     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0933857262134552     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5667672157287598    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8967103362083435    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0933857262134552    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8967103362083435, 'test_mse': 0.0933857262134552, 'test_iou': 0.5667672157287598}]\n",
      "MSE value is 0.0933857262134552\n",
      "IoU value is 0.5667672157287598\n",
      "num_param value is 44328\n",
      "Training time: 233.4526059627533\n",
      "Fitness: 14.769247346120483\n",
      "********\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 14.769247346120483, IoU: 0.5667672157287598, FPS: 300.3623278699137, Model Size: 44328\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELDd0.40n1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1516\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:53:05.858566344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:05.861587581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:05.896412340 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:05.896469837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.5 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3da8d16d414b56b26edd68f5df27f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:53:59.955283243 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:59.969152723 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:59.997016913 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:53:59.003459502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ace97275a044156baf1bc31baf4ba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6724233031272888     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9537245035171509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09616521000862122    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6724233031272888    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9537245035171509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09616521000862122   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:54:04.916411534 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:04.930254972 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:04.949581740 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:04.956236469 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce288f325c14920b6014418fc845428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.663729727268219     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9549667835235596     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09761691093444824    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.663729727268219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9549667835235596    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09761691093444824   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9549667835235596, 'test_mse': 0.09761691093444824, 'test_iou': 0.663729727268219}]\n",
      "MSE value is 0.09761691093444824\n",
      "IoU value is 0.663729727268219\n",
      "num_param value is 1516\n",
      "Training time: 54.096516370773315\n",
      "Fitness: 15.746428075205095\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm'], fitness: 15.746428075205095, IoU: 0.663729727268219, FPS: 431.57631702652503, Model Size: 1516\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELDd0.43n1EPa2ELme6agn1EPM2ELRr4agn1EUf2mnearestES1ELeo04k3s1p1arn1EUf2mnearestES1ELDd0.39n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.39}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.39}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 23209967 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lme6agn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'Uf2mnearest', 'S1', 'LDd0.39n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELne6arn1EPa2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Lne6arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3196099\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 06:54:09.898580435 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:09.899508684 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:09.910300541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 06:54:09.912417256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.2 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.784    Total estimated model params size (MB)\n",
      "60        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe45d022630479ba806c3b8e224727d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:20:40.367669353 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:20:40.385260231 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:20:40.420394098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:20:40.420439823 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcae04b4b07f4bc1a10987d57623e8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5446169972419739     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.91621333360672      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13762949407100677    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5446169972419739    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.91621333360672     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13762949407100677   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:21:25.033654507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:21:25.034980859 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:21:25.104513819 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:21:25.104513821 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c07a790bfa4dfcb6ef98e4b9b455e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5359526872634888     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9168931245803833     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13183291256427765    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5359526872634888    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9168931245803833    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13183291256427765   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9168931245803833, 'test_mse': 0.13183291256427765, 'test_iou': 0.5359526872634888}]\n",
      "MSE value is 0.13183291256427765\n",
      "IoU value is 0.5359526872634888\n",
      "num_param value is 3196099\n",
      "Training time: 1591.4920556545258\n",
      "Fitness: 10.99865424659147\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Lne6arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 10.99865424659147, IoU: 0.5359526872634888, FPS: 51.61449806465198, Model Size: 3196099\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k3s1p1arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 1280062\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:22:04.899794713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:22:04.916979460 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:22:04.976392450 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:22:04.976434559 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 1.3 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.120     Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac646ccdc1914696a133b1b6f178875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:36:06.955828381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:06.961185031 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:06.983438070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:06.988422669 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc14af3e62e4842b8ee3224cf9c8aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5075142979621887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1957621574401855     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5197687149047852     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5075142979621887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1957621574401855    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5197687149047852    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:36:28.436505109 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:29.460110267 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:29.464911732 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:29.469067088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7747958f0a7a473a928e5b859d536b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5093404054641724     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.188856840133667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5028164386749268     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5093404054641724    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.188856840133667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5028164386749268    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.188856840133667, 'test_mse': 0.5028164386749268, 'test_iou': 0.5093404054641724}]\n",
      "MSE value is 0.5028164386749268\n",
      "IoU value is 0.5093404054641724\n",
      "num_param value is 1280062\n",
      "Training time: 842.1403603553772\n",
      "Fitness: 10.467514675229548\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: 10.467514675229548, IoU: 0.5093404054641724, FPS: 101.58781951991512, Model Size: 1280062\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELco04k5s1p2arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 72562879 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELne5arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 6204934 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELco16k3s1p1arn1EUf2mnearestES2ELme6arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 281796\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:36:49.060662825 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:49.067685592 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:49.100449067 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:36:49.100476230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 281 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.127     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c43de7530d407ebadea4c2bfa77c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:52:16.504237992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:16.510363134 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:16.516229230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:16.516334207 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff11a7870b84e1fbba45da7eed58420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6526042222976685     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9344794154167175     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08891632407903671    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6526042222976685    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9344794154167175    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08891632407903671   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:52:31.478087791 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:31.478265507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:31.502579715 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:31.512479969 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885ad16f75144e87a8c835baeb7094c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6444868445396423     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.946419358253479     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09433625638484955    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6444868445396423    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.946419358253479    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09433625638484955   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.946419358253479, 'test_mse': 0.09433625638484955, 'test_iou': 0.6444868445396423}]\n",
      "MSE value is 0.09433625638484955\n",
      "IoU value is 0.6444868445396423\n",
      "num_param value is 281796\n",
      "Training time: 926.5914461612701\n",
      "Fitness: 15.30103158880916\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S2', 'Lme6arn1', 'HSasm'], fitness: 15.30103158880916, IoU: 0.6444868445396423, FPS: 150.50600837512047, Model Size: 281796\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELbo07k3s1p1arn1EPM2ELdo08agn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'PM2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 29760094 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Lbo07k3s1p1arn1', 'PM2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPa2ELdo09agn1EUf2mnearestES1ELne4agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 159289\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:52:44.403854451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:44.431777278 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:44.433917695 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:52:44.434316829 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 159 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "159 K     Trainable params\n",
      "0         Non-trainable params\n",
      "159 K     Total params\n",
      "0.637     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54e8fe8933c4f62a48d1a171f00a2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 07:59:55.095714336 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:59:55.096215843 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:59:55.098645765 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 07:59:55.106760453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c56cdc811e43f7b4ae0c812ef0835f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6553885340690613     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8744659423828125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08038929849863052    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6553885340690613    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8744659423828125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08038929849863052   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:00:08.785387680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:08.794083436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:08.796538814 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:08.800890260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85cb34b7a714e069650f7802a10b042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6424223184585571     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8788888454437256     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08308255672454834    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6424223184585571    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8788888454437256    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08308255672454834   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8788888454437256, 'test_mse': 0.08308255672454834, 'test_iou': 0.6424223184585571}]\n",
      "MSE value is 0.08308255672454834\n",
      "IoU value is 0.6424223184585571\n",
      "num_param value is 159289\n",
      "Training time: 430.6671938896179\n",
      "Fitness: 15.4978407048807\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 15.4978407048807, IoU: 0.6424223184585571, FPS: 176.53977488727358, Model Size: 159289\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo14k5s1p2arn1EPM2ELne5arn1EPa2ELco15k3s1p1arn1EUf2mnearestES1ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Leo14k5s1p2arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 23146914 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo14k5s1p2arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lco15k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 5, the best fitness of the population is 16.184037146307464.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_5.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 6 ***\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:00:20.064431230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:20.068446480 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:20.089626253 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:00:20.093554942 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51c4dd247db4f60b117b12aa306fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:06:13.226714553 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:13.228771019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:13.229753656 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:13.233240414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1b2a02996d4d17a77eff8d294e88f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7118455767631531     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8521466851234436     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.050949711352586746    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7118455767631531    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8521466851234436    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.050949711352586746   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:06:21.988187398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:21.990140471 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:21.992405005 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:21.993881010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1474c92847684e83aab58689b5416b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7128183245658875     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8577268123626709     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05326675623655319    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7128183245658875    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8577268123626709    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05326675623655319   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8577268123626709, 'test_mse': 0.05326675623655319, 'test_iou': 0.7128183245658875}]\n",
      "MSE value is 0.05326675623655319\n",
      "IoU value is 0.7128183245658875\n",
      "num_param value is 47394\n",
      "Training time: 353.27505016326904\n",
      "Fitness: 16.575060227619023\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.575060227619023, IoU: 0.7128183245658875, FPS: 282.40052810592226, Model Size: 47394\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EUf2mnearestES0ELDd0.40n1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 133172\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:06:28.156084729 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:28.161585635 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:28.161608795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:06:28.164499813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 133 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "133 K     Trainable params\n",
      "0         Non-trainable params\n",
      "133 K     Total params\n",
      "0.533     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c80c9772284c1691532dc3254fe31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:09:57.320691123 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:09:57.321169055 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:09:57.321858507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:09:57.330907753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ce38662c024c4d894636f404f3185d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6593981981277466     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0273655652999878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13998787105083466    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6593981981277466    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0273655652999878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13998787105083466   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:10:04.690642605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:04.697901495 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:04.698930489 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:04.700556009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59f1de4fe444749bf291377048b96e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6502556204795837     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0260628461837769     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13919205963611603    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6502556204795837    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0260628461837769    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13919205963611603   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0260628461837769, 'test_mse': 0.13919205963611603, 'test_iou': 0.6502556204795837}]\n",
      "MSE value is 0.13919205963611603\n",
      "IoU value is 0.6502556204795837\n",
      "num_param value is 133172\n",
      "Training time: 209.14525413513184\n",
      "Fitness: 15.147535277227144\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'LDd0.40n1', 'HSasm'], fitness: 15.147535277227144, IoU: 0.6502556204795837, FPS: 340.45320582983453, Model Size: 133172\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELme4arn1EUf2mnearestES1ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:10:10.633072657 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:10.645889024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:10.656067578 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:10:10.665462308 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5864a652624963895a2ed865ebd30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:11:49.700235952 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:49.708049087 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:49.710470858 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:49.711663441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82e024a175243c5a2eb9d0f0af62a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6358245015144348     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9041216969490051     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07131913304328918    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6358245015144348    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9041216969490051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07131913304328918   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:11:54.818841550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:54.842854593 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:54.842995352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:54.847215812 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2101f15d4ec5436fa5c908cc3c06713c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6331868171691895     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.902570903301239     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0705648809671402     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6331868171691895    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.902570903301239    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0705648809671402    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.902570903301239, 'test_mse': 0.0705648809671402, 'test_iou': 0.6331868171691895}]\n",
      "MSE value is 0.0705648809671402\n",
      "IoU value is 0.6331868171691895\n",
      "num_param value is 2573\n",
      "Training time: 99.0443525314331\n",
      "Fitness: 15.670158278434267\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm'], fitness: 15.670158278434267, IoU: 0.6331868171691895, FPS: 411.2308072496286, Model Size: 2573\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELne3arn1EPa2ELdo09agn1EUf2mnearestES0ELne4agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 159289\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:11:59.796929034 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:59.799826842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:59.801152710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:11:59.805202463 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 159 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "159 K     Trainable params\n",
      "0         Non-trainable params\n",
      "159 K     Total params\n",
      "0.637     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf2d34a258b4f9e849ae631e544955e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:22:43.826447098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:43.830708988 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:43.833686544 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:43.841260780 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bfd03c4aad49bf90676f7db6ebdb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6919667720794678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8402559757232666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.056959040462970734    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6919667720794678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8402559757232666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.056959040462970734   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:22:56.649200577 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:56.652674865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:56.655296911 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:22:56.659020159 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2cc0e05f754f3a83c20598bc38f610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6963998079299927     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.838077187538147     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.057364411652088165    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6963998079299927    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.838077187538147    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.057364411652088165   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.838077187538147, 'test_mse': 0.057364411652088165, 'test_iou': 0.6963998079299927}]\n",
      "MSE value is 0.057364411652088165\n",
      "IoU value is 0.6963998079299927\n",
      "num_param value is 159289\n",
      "Training time: 644.0240092277527\n",
      "Fitness: 16.262186453988008\n",
      "********\n",
      "chromosome: ['Lne6arn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.262186453988008, IoU: 0.6963998079299927, FPS: 175.41949206354386, Model Size: 159289\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES2ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:23:07.155404046 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:23:07.157371629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:23:07.160707252 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:23:07.161318237 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d802a805be14c8abf6e39cf900c6853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:25:35.167679689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:35.176650132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:35.179125748 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:35.184706992 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fb45dd5fa74971aaecbc3fd96a47bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6368299722671509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9588452577590942     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09715218096971512    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6368299722671509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9588452577590942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09715218096971512   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:25:41.096626245 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:41.103810843 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:41.107362682 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:41.115123528 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47930046bcfe47b898abc94452d68068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6202445030212402     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9613885283470154     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09790101647377014    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6202445030212402    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9613885283470154    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09790101647377014   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9613885283470154, 'test_mse': 0.09790101647377014, 'test_iou': 0.6202445030212402}]\n",
      "MSE value is 0.09790101647377014\n",
      "IoU value is 0.6202445030212402\n",
      "num_param value is 91054\n",
      "Training time: 148.01452326774597\n",
      "Fitness: 15.2196802566109\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.2196802566109, IoU: 0.6202445030212402, FPS: 360.1151031278504, Model Size: 91054\n",
      "\n",
      "Architecture: LDd0.30n1EPa2ELco16k3s1p1arn1EUf2mnearestES1ELme6arn1EHSasmEE\n",
      "Chromosome: ['LDd0.30n1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lme6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.3}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.3}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 16, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 281796\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:25:47.703131417 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:47.703239086 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:47.706167238 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:25:47.715013544 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 281 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.127     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecb722db9c24e88b19d52582581e522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:39:40.418743283 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:40.424063018 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:40.426008338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:40.434061829 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9212cd0f5c14d149181f29560b2e8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6081700325012207     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.05417799949646      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15118719637393951    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6081700325012207    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.05417799949646     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15118719637393951   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:39:56.516495920 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:56.529819541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:56.529818745 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:39:56.532406476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bf0caf35bb43d8b83ffd6442ba64bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5994589924812317     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0571538209915161     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15239492058753967    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5994589924812317    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0571538209915161    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15239492058753967   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0571538209915161, 'test_mse': 0.15239492058753967, 'test_iou': 0.5994589924812317}]\n",
      "MSE value is 0.15239492058753967\n",
      "IoU value is 0.5994589924812317\n",
      "num_param value is 281796\n",
      "Training time: 833.6853504180908\n",
      "Fitness: 14.390374692785137\n",
      "********\n",
      "chromosome: ['LDd0.30n1', 'Pa2', 'Lco16k3s1p1arn1', 'Uf2mnearest', 'S1', 'Lme6arn1', 'HSasm'], fitness: 14.390374692785137, IoU: 0.5994589924812317, FPS: 150.3021960680477, Model Size: 281796\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPM2ELRr2arn1EPM2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 08:40:09.938999186 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:40:09.950621103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:40:09.950620682 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 08:40:09.951117382 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8348a20acfbc4cd1bf020fa9f1202e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:03:07.531085956 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:07.537359795 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:07.539378700 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:07.548990626 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a53bbdf3631406e8a90ad162e6ebe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7624715566635132     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9276238083839417     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1373608261346817     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7624715566635132    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9276238083839417    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1373608261346817    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:03:24.191661179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:24.198321987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:24.200060796 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:24.202859184 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557f1bfb84e8420d9c21d2135a452d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7645413279533386     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9268012642860413     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14356611669063568    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7645413279533386    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9268012642860413    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14356611669063568   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9268012642860413, 'test_mse': 0.14356611669063568, 'test_iou': 0.7645413279533386}]\n",
      "MSE value is 0.14356611669063568\n",
      "IoU value is 0.7645413279533386\n",
      "num_param value is 876202\n",
      "Training time: 1377.5969688892365\n",
      "Fitness: 15.513786563854495\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 15.513786563854495, IoU: 0.7645413279533386, FPS: 128.7084582056021, Model Size: 876202\n",
      "\n",
      "Architecture: LDd0.43n1EPa2ELne5arn1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['LDd0.43n1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3812\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:03:40.848346998 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:40.856287199 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:40.862373556 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:03:40.863717587 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.8 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 K     Total params\n",
      "0.015     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb13019b15f944e4a0a574119ad63e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:05:45.718084148 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:45.719650113 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:45.720551520 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:45.727924827 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c593ee84253249779a91cb374282bee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3495238721370697     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1640570163726807     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.279236376285553     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3495238721370697    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1640570163726807    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.279236376285553    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:05:50.203290041 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:50.206702615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:50.206739351 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:50.207411973 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8579ea54c2ee4d2ca3c110f7461a96d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33789825439453125    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1863104104995728     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.29316842555999756    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.33789825439453125   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1863104104995728    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.29316842555999756   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1863104104995728, 'test_mse': 0.29316842555999756, 'test_iou': 0.33789825439453125}]\n",
      "MSE value is 0.29316842555999756\n",
      "IoU value is 0.33789825439453125\n",
      "num_param value is 3812\n",
      "Training time: 124.92315196990967\n",
      "Fitness: 11.10811530376619\n",
      "********\n",
      "chromosome: ['LDd0.43n1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 11.10811530376619, IoU: 0.33789825439453125, FPS: 390.1824775554356, Model Size: 3812\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELbo05k3s1p1arn1EPa2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 7438760 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELne6arn1EPa2ELRr2arn1EUf2mnearestES0ELco09k5s1p2arn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lne6arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 52787\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:05:56.544356509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:56.555848965 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:56.555881098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:05:56.560612255 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 52.8 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "52.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.8 K    Total params\n",
      "0.211     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ed59767f70477fbafaa5b1260bccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:07:57.031970010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:07:57.039614122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:07:57.040234870 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:07:57.045203070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3437cd357a2d4f1db2c735d11a3ac2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4962947368621826     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9502925276756287     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23813951015472412    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4962947368621826    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9502925276756287    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23813951015472412   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:08:04.623675276 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:04.625622122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:04.625829740 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:04.634446888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17ba71583b49c795914bb4427ae1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49278417229652405    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9360346794128418     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2386859804391861     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49278417229652405   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9360346794128418    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2386859804391861    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9360346794128418, 'test_mse': 0.2386859804391861, 'test_iou': 0.49278417229652405}]\n",
      "MSE value is 0.2386859804391861\n",
      "IoU value is 0.49278417229652405\n",
      "num_param value is 52787\n",
      "Training time: 121.46323943138123\n",
      "Fitness: 12.948125830506493\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'Pa2', 'Lne6arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: 12.948125830506493, IoU: 0.49278417229652405, FPS: 324.86142109522257, Model Size: 52787\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 8907584 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELDd0.43n1EPa2ELco04k5s1p2arn1EPM2ELRr4agn1EUf2mnearestES1ELeo10k3s1p1agn1EUf2mnearestES1ELRr2agn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lco04k5s1p2arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvAct without error\n",
      "Skipping architecture, total parameters: 410415992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lco04k5s1p2arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S1', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELdo06arn1EPa2ELco04k5s1p2arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 72562879 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Ldo13arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELne5arn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 6204934 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LRr2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 32954992 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo13k5s1p2arn1EPM2ELdo12agn1EPM2ELdo08agn1EUf2mnearestES1ELbo16k5s1p2agn1EUf2mnearestES1ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Ldo12agn1', 'PM2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 101686676 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo13k5s1p2arn1', 'PM2', 'Ldo12agn1', 'PM2', 'Ldo08agn1', 'Uf2mnearest', 'S1', 'Lbo16k5s1p2agn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3505016\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:08:15.295771669 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:15.297183598 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:15.302350030 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:08:15.306518838 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.020    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5228502e2865447c8e6e59c66ea2b337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:37:29.053132271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:37:29.061321826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:37:29.068511702 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:37:29.075274106 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54110066621249a0926496a4cca481d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48031261563301086    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0178678035736084     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8590039014816284     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48031261563301086   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0178678035736084    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8590039014816284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:38:19.448176195 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:38:20.458446122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:38:20.458496365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:38:20.465293895 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc7f5662d27497e93be0fc02d9476f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4875318706035614     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.000228762626648     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7676987051963806     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4875318706035614    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.000228762626648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7676987051963806    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.000228762626648, 'test_mse': 0.7676987051963806, 'test_iou': 0.4875318706035614}]\n",
      "MSE value is 0.7676987051963806\n",
      "IoU value is 0.4875318706035614\n",
      "num_param value is 3505016\n",
      "Training time: 1754.0155069828033\n",
      "Fitness: 7.027375356823725\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 7.027375356823725, IoU: 0.4875318706035614, FPS: 46.03513288498247, Model Size: 3505016\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 6, the best fitness of the population is 16.575060227619023.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_6.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 7 ***\n",
      "Architecture: Lco05k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 47394\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:39:03.426756727 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:39:03.430443211 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:39:03.443909690 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:39:03.448429977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 47.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "47.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.4 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b7b5ed204a45a4895e8b95dadf3bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:44:22.842944162 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:22.849544088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:22.853418347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:22.862258204 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cf2e364cc54156a9c0d05e6e0f3526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6789789199829102     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8781252503395081     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06317485868930817    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6789789199829102    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8781252503395081    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06317485868930817   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:44:30.796096154 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:30.798880909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:30.799155310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:30.803508321 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440ec608d3ab4079af850fa2e524ff2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6778137683868408     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8724532723426819     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05994011089205742    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6778137683868408    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8724532723426819    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05994011089205742   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8724532723426819, 'test_mse': 0.05994011089205742, 'test_iou': 0.6778137683868408}]\n",
      "MSE value is 0.05994011089205742\n",
      "IoU value is 0.6778137683868408\n",
      "num_param value is 47394\n",
      "Training time: 318.5503830909729\n",
      "Fitness: 16.165238989064367\n",
      "********\n",
      "chromosome: ['Lco05k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.165238989064367, IoU: 0.6778137683868408, FPS: 276.44249567562633, Model Size: 47394\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELne3arn1EPa2ELdo09agn1EUf2mnearestES0ELne4agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 11223408 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lne3arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne3agn1EPM2ELme4arn1EUf2mnearestES1ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:44:37.224700962 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:37.231142256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:37.233855070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:44:37.240946053 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdec677f5784c4684919e6298b7357c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:46:16.525150563 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:16.533730196 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:16.534209349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:16.541123554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17914ce18b3d4181a2c1fde885e36b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6416998505592346     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.924859344959259     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08259706944227219    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6416998505592346    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.924859344959259    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08259706944227219   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:46:21.632480624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:21.638881300 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:21.639582280 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:21.641629344 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e361d7d4c8404aa884cc3f89dedf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6394168138504028     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9110358357429504     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07546326518058777    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6394168138504028    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9110358357429504    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07546326518058777   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9110358357429504, 'test_mse': 0.07546326518058777, 'test_iou': 0.6394168138504028}]\n",
      "MSE value is 0.07546326518058777\n",
      "IoU value is 0.6394168138504028\n",
      "num_param value is 2573\n",
      "Training time: 98.32953453063965\n",
      "Fitness: 15.689913662029644\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm'], fitness: 15.689913662029644, IoU: 0.6394168138504028, FPS: 409.31266171203936, Model Size: 2573\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPM2ELRr2arn1EPM2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 09:46:26.668863377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:26.670366652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:26.671310468 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 09:46:26.675451236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1008c8ec3e5d40b29719e4e281637acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:09:21.390621767 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:21.397602248 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:21.398596809 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:21.407344228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066f67ea4b034c0ebe6ef8aa0e2eb089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7151987552642822     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9663347005844116     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16423186659812927    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7151987552642822    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9663347005844116    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16423186659812927   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:09:39.129270808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:39.137807581 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:39.138784073 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:39.140586692 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da633d8dd54cfb9d0f5654b82cc2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7075368762016296     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9617180824279785     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1637209951877594     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7075368762016296    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9617180824279785    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1637209951877594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9617180824279785, 'test_mse': 0.1637209951877594, 'test_iou': 0.7075368762016296}]\n",
      "MSE value is 0.1637209951877594\n",
      "IoU value is 0.7075368762016296\n",
      "num_param value is 876202\n",
      "Training time: 1375.7166185379028\n",
      "Fitness: 14.792291781975706\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 14.792291781975706, IoU: 0.7075368762016296, FPS: 128.73554440913955, Model Size: 876202\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 91054\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:09:55.757815009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:55.757822441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:55.760949512 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:09:55.769419111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 91.1 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "91.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 K    Total params\n",
      "0.364     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6fe22465004d9d8e620754853f52a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:12:23.680667713 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:23.687381922 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:23.689365548 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:23.690554343 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d34f3235544493d8871a42b27afdeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6450456976890564     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9390113353729248     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08546212315559387    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6450456976890564    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9390113353729248    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08546212315559387   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:12:29.595863330 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:29.596835824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:29.599910300 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:29.602653637 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd778bf2344e44aebe30869e09dbca62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.62786865234375      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9336282014846802     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08242946118116379    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.62786865234375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9336282014846802    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08242946118116379   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9336282014846802, 'test_mse': 0.08242946118116379, 'test_iou': 0.62786865234375}]\n",
      "MSE value is 0.08242946118116379\n",
      "IoU value is 0.62786865234375\n",
      "num_param value is 91054\n",
      "Training time: 147.96709537506104\n",
      "Fitness: 15.426109817918976\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.426109817918976, IoU: 0.62786865234375, FPS: 360.81531986166306, Model Size: 91054\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EUf2mnearestES2ELDd0.40n1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.4}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.4}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 133172\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:12:34.217298429 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:34.217946301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:34.223513539 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:12:34.230178905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 133 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "133 K     Trainable params\n",
      "0         Non-trainable params\n",
      "133 K     Total params\n",
      "0.533     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13727cf7a6194554b53cee81eb3c8dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:16:03.070795778 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:03.078972299 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:03.079771875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:03.088168132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b2bebe0bc146769f93043b27e401f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6555686593055725     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0276941061019897     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14018522202968597    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6555686593055725    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0276941061019897    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14018522202968597   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:16:10.597799583 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:10.602197911 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:10.605215179 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:10.609376970 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05383a91d2a4f65a6aabc8a5a24a030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6482062935829163     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0263179540634155     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13927029073238373    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6482062935829163    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0263179540634155    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13927029073238373   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0263179540634155, 'test_mse': 0.13927029073238373, 'test_iou': 0.6482062935829163}]\n",
      "MSE value is 0.13927029073238373\n",
      "IoU value is 0.6482062935829163\n",
      "num_param value is 133172\n",
      "Training time: 208.86456060409546\n",
      "Fitness: 15.126439232617862\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'LDd0.40n1', 'HSasm'], fitness: 15.126439232617862, IoU: 0.6482062935829163, FPS: 338.8835428781037, Model Size: 133172\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES1ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:16:16.634573682 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:16.642968689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:16.646900398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:16:16.653729797 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 48.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "48.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.3 K    Total params\n",
      "0.193     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795bc32fa5494274bb92e813d9ba641c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:19:32.120856281 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:32.131448872 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:32.133590381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:32.136534526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaca3417a1745ac9b7e70900f6cc248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6710097193717957     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9233819842338562     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08673204481601715    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6710097193717957    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9233819842338562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08673204481601715   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:19:38.880728857 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:38.881084862 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:38.881272428 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:38.883167109 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7950c1770ab84f3c8f5aecc7c63ff2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6564339995384216     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9273046255111694     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08863387256860733    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6564339995384216    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9273046255111694    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08863387256860733   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9273046255111694, 'test_mse': 0.08863387256860733, 'test_iou': 0.6564339995384216}]\n",
      "MSE value is 0.08863387256860733\n",
      "IoU value is 0.6564339995384216\n",
      "num_param value is 48290\n",
      "Training time: 196.45846486091614\n",
      "Fitness: 15.701874772639423\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm'], fitness: 15.701874772639423, IoU: 0.6564339995384216, FPS: 363.93980625471215, Model Size: 48290\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELne6arn1EPa2ELRr2arn1EUf2mnearestES0ELme6arn1EUf2mnearestES0ELRr3agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lne6arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3108\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:19:44.509425289 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:44.511804505 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:44.514155440 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:19:44.523123813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.1 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "87        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9cf8df11924033a0dad3ffdb682cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:21:36.301247785 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:36.302438505 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:36.303426216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:36.303901251 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec72f890e404015a96005c9dc91b67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5481066703796387     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.073240876197815     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23373034596443176    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5481066703796387    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.073240876197815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23373034596443176   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:21:42.786578810 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:42.789769612 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:42.790735187 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:42.792676519 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc29a43686a7429986833a8bc1f7cc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5480290055274963     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0571662187576294     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22555024921894073    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5480290055274963    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0571662187576294    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22555024921894073   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0571662187576294, 'test_mse': 0.22555024921894073, 'test_iou': 0.5480290055274963}]\n",
      "MSE value is 0.22555024921894073\n",
      "IoU value is 0.5480290055274963\n",
      "num_param value is 3108\n",
      "Training time: 112.85859370231628\n",
      "Fitness: 13.636782207429581\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'Pa2', 'Lne6arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'Uf2mnearest', 'S0', 'LRr3agn1', 'HSasm'], fitness: 13.636782207429581, IoU: 0.5480290055274963, FPS: 382.64803261413823, Model Size: 3108\n",
      "\n",
      "Architecture: LDd0.43n1EPa2ELne5arn1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['LDd0.43n1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 42340\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:21:47.100736458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:47.104017538 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:47.105962362 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:21:47.110398230 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 42.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "42.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.3 K    Total params\n",
      "0.169     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9586cd626e304525911453cfbed522f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:24:39.940024038 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:39.940049624 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:39.942258143 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:39.946868845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b31cc518f7441538db35f44838203c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4473598897457123     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.101733684539795     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43902984261512756    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4473598897457123    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.101733684539795    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43902984261512756   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:24:45.030404111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:45.032315266 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:45.033304062 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:45.040129550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e2d6baa54b4312aeeedb60dc25297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4422028660774231     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1297507286071777     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4672650694847107     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4422028660774231    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1297507286071777    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4672650694847107    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1297507286071777, 'test_mse': 0.4672650694847107, 'test_iou': 0.4422028660774231}]\n",
      "MSE value is 0.4672650694847107\n",
      "IoU value is 0.4422028660774231\n",
      "num_param value is 42340\n",
      "Training time: 171.83498573303223\n",
      "Fitness: 11.19508978220344\n",
      "********\n",
      "chromosome: ['LDd0.43n1', 'Pa2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 11.19508978220344, IoU: 0.4422028660774231, FPS: 354.05901475995773, Model Size: 42340\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 14530\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:24:51.821335516 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:51.841122877 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:51.852396203 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:24:51.853957612 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 14.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "14.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.5 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7246d219cb34af68b030354819674b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:26:45.368362948 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:45.369283051 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:45.370371204 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:45.370672511 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e1d4dc82bb425dafd6ace02ca5b12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5364986062049866     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8706352114677429     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08485540002584457    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5364986062049866    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8706352114677429    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08485540002584457   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:26:51.276967813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:51.278197443 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:51.282338842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:51.291949508 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c9563fc10d4567824f62fb935d4138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5406476259231567     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8745012283325195     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08748774975538254    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5406476259231567    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8745012283325195    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08748774975538254   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8745012283325195, 'test_mse': 0.08748774975538254, 'test_iou': 0.5406476259231567}]\n",
      "MSE value is 0.08748774975538254\n",
      "IoU value is 0.5406476259231567\n",
      "num_param value is 14530\n",
      "Training time: 114.5993173122406\n",
      "Fitness: 14.587452141711054\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 14.587452141711054, IoU: 0.5406476259231567, FPS: 367.7613789192869, Model Size: 14530\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELbo05k3s1p1arn1EPa2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 7438760 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lbo05k3s1p1arn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Ldo06agn1EPa2ELco04k5s1p2agn1EUf2mnearestES1ELeo04k3s1p1arn1EHSasmEE\n",
      "Chromosome: ['Ldo06agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7241378 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Ldo06agn1', 'Pa2', 'Lco04k5s1p2agn1', 'Uf2mnearest', 'S1', 'Leo04k3s1p1arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo04k3s1p1arn1EPa2ELdo06arn1EPa2ELco04k5s1p2arn1EPM2ELRr4agn1EUf2mnearestES1ELne3arn1EUf2mnearestES0ELRr2agn1EUf2mnearestES0ELeo05k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 8270584 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Leo04k3s1p1arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lco04k5s1p2arn1', 'PM2', 'LRr4agn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'LRr2agn1', 'Uf2mnearest', 'S0', 'Leo05k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELDd0.43n1EPa2ELco04k5s1p2arn1EUf2mnearestES1ELeo10k3s1p1agn1EUf2mnearestES1ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'LDd0.43n1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S1', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 9263534 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lme3arn1', 'PM2', 'LDd0.43n1', 'Pa2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Leo10k3s1p1agn1', 'Uf2mnearest', 'S1', 'Ldo13arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELne5arn1EPa2ELDd0.35n1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 99291360 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lne5arn1', 'Pa2', 'LDd0.35n1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 306234\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:26:58.238730813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:58.244654007 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:58.258567077 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:26:58.266193470 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 306 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "306 K     Trainable params\n",
      "0         Non-trainable params\n",
      "306 K     Total params\n",
      "1.225     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab68f37a4d5467cbf15931a828fb4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:36:25.814010441 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:25.815099119 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:25.816790861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:25.826304387 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d7f837fec4dbbb11bbc3dfe317d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7439695596694946     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8975003361701965     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0726621150970459     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7439695596694946    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8975003361701965    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0726621150970459    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:36:35.731943994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:35.732024182 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:35.733838356 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:35.743239063 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8000df5306524fc9ad9d3c39fff31cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7446409463882446     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8794897198677063     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06384318321943283    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7446409463882446    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8794897198677063    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06384318321943283   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8794897198677063, 'test_mse': 0.06384318321943283, 'test_iou': 0.7446409463882446}]\n",
      "MSE value is 0.06384318321943283\n",
      "IoU value is 0.7446409463882446\n",
      "num_param value is 306234\n",
      "Training time: 566.8447694778442\n",
      "Fitness: 16.540057098446024\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: 16.540057098446024, IoU: 0.7446409463882446, FPS: 223.71243397621282, Model Size: 306234\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3505016\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 10:36:44.870585051 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:44.875924457 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:44.880751360 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 10:36:44.881423580 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.020    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a241430fa44150ba37fa52511b0231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:20:11.923628010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:20:11.925643476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:20:11.925856167 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:20:11.932196335 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd58f86896c64226b836025e6df65e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4917060136795044     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.044158697128296     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0067696571350098     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4917060136795044    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.044158697128296    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0067696571350098    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:21:01.984508614 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:01.984511128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:01.985594397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:01.992973981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d48ec7c4484d73ac575754c0e3a202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4964136481285095     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0664767026901245     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8711367249488831     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4964136481285095    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0664767026901245    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8711367249488831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0664767026901245, 'test_mse': 0.8711367249488831, 'test_iou': 0.4964136481285095}]\n",
      "MSE value is 0.8711367249488831\n",
      "IoU value is 0.4964136481285095\n",
      "num_param value is 3505016\n",
      "Training time: 2607.068632364273\n",
      "Fitness: 6.803465374239503\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 6.803465374239503, IoU: 0.4964136481285095, FPS: 46.254076499833424, Model Size: 3505016\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 7, the best fitness of the population is 16.540057098446024.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_7.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 8 ***\n",
      "Architecture: LRr2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 306234\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:21:45.826094502 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:45.827406365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:45.830397564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:21:45.832458420 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 306 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "306 K     Trainable params\n",
      "0         Non-trainable params\n",
      "306 K     Total params\n",
      "1.225     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde3ded486db498b9edfb154036fde03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:32:14.996119516 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:14.004335454 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:14.009446510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:14.015306436 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f7f2430b4448d8b258a1384a7f6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7281693816184998     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8905282020568848     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06980011612176895    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7281693816184998    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8905282020568848    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06980011612176895   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:32:24.934826193 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:24.940957813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:24.945282199 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:24.950554206 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9164b4cf35d4e3a9c590d7563faba4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7243363857269287     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8960502743721008     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07218743115663528    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7243363857269287    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8960502743721008    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07218743115663528   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8960502743721008, 'test_mse': 0.07218743115663528, 'test_iou': 0.7243363857269287}]\n",
      "MSE value is 0.07218743115663528\n",
      "IoU value is 0.7243363857269287\n",
      "num_param value is 306234\n",
      "Training time: 629.3746728897095\n",
      "Fitness: 16.263857357900758\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: 16.263857357900758, IoU: 0.7243363857269287, FPS: 224.06936949852138, Model Size: 306234\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 401524\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:32:33.964948238 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:33.975868663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:33.975868271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:32:33.983916754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 401 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "401 K     Trainable params\n",
      "0         Non-trainable params\n",
      "401 K     Total params\n",
      "1.606     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3060a94658f4bc5a7401bc20afe83d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:48:51.873779419 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:48:51.882368527 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:48:51.885128450 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:48:51.887228414 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01906e86c5d84599a567dcc127e39b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7829618453979492     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8842569589614868     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06393223255872726    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7829618453979492    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8842569589614868    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06393223255872726   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:49:08.094405679 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:08.096391831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:08.096431377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:08.105484100 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42655127c944bf5afdf353e16bf4f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7893264293670654     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8725520968437195     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05841769650578499    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7893264293670654    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8725520968437195    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05841769650578499   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8725520968437195, 'test_mse': 0.05841769650578499, 'test_iou': 0.7893264293670654}]\n",
      "MSE value is 0.05841769650578499\n",
      "IoU value is 0.7893264293670654\n",
      "num_param value is 401524\n",
      "Training time: 977.9261445999146\n",
      "Fitness: 16.93980605543331\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.93980605543331, IoU: 0.7893264293670654, FPS: 131.72016612370842, Model Size: 401524\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.43n1EUf2mnearestES1ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:49:23.370884425 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:23.373632019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:23.374279070 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:49:23.382520554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 48.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "48.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.3 K    Total params\n",
      "0.193     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602364121792484e9e0bf2c8acecf9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:52:40.810554929 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:40.811406524 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:40.812696776 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:40.821974753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09b6281b15a4a0a8e27b63aff38054a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.635732889175415     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9128173589706421     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08177021145820618    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.635732889175415    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9128173589706421    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08177021145820618   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:52:46.557948812 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:46.557948829 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:46.559148476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:46.561849159 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2306470372e4fea873b135a51b9b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6336135268211365     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9101021885871887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08027340471744537    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6336135268211365    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9101021885871887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08027340471744537   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9101021885871887, 'test_mse': 0.08027340471744537, 'test_iou': 0.6336135268211365}]\n",
      "MSE value is 0.08027340471744537\n",
      "IoU value is 0.6336135268211365\n",
      "num_param value is 48290\n",
      "Training time: 196.44676542282104\n",
      "Fitness: 15.544761115931957\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm'], fitness: 15.544761115931957, IoU: 0.6336135268211365, FPS: 366.28792003799896, Model Size: 48290\n",
      "\n",
      "Architecture: Lne3agn1EPa2ELme4arn1EUf2mnearestES1ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:52:51.126819106 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:51.131755550 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:51.136914422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:52:51.146143018 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae3f6d49fff43acad6825df81497cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:54:41.707823739 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:41.716096446 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:41.716152379 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:41.717067562 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305b74e0db4045e0be59333e5a9b60e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6487352848052979     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8803895711898804     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05980159714818001    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6487352848052979    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8803895711898804    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05980159714818001   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:54:46.937797730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:46.939766907 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:46.942163111 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:46.952254210 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d050ccd4f6f642a69770bdcef6f55670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6319898962974548     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8844572901725769     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06193473935127258    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6319898962974548    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8844572901725769    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06193473935127258   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8844572901725769, 'test_mse': 0.06193473935127258, 'test_iou': 0.6319898962974548}]\n",
      "MSE value is 0.06193473935127258\n",
      "IoU value is 0.6319898962974548\n",
      "num_param value is 2573\n",
      "Training time: 109.59613060951233\n",
      "Fitness: 15.734100487281871\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm'], fitness: 15.734100487281871, IoU: 0.6319898962974548, FPS: 403.1496837993825, Model Size: 2573\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES2ELco14k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lco14k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 104424\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:54:51.989161868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:51.992968707 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:51.992968631 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:54:51.999604543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 104 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "104 K     Trainable params\n",
      "0         Non-trainable params\n",
      "104 K     Total params\n",
      "0.418     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffca570ee39d4af69b399e56beff5d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:57:25.724583632 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:25.725461169 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:25.728323865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:25.734064771 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e13598248d4cb4afcff133abba6f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45239436626434326    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2242028713226318     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.229287788271904     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45239436626434326   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2242028713226318    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.229287788271904    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:57:31.326910301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:31.345122977 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:31.355372951 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:31.363541006 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0072b07d1fcc43fb9df163dd2e9175be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43685293197631836    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.230879783630371     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23253121972084045    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43685293197631836   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.230879783630371    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23253121972084045   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.230879783630371, 'test_mse': 0.23253121972084045, 'test_iou': 0.43685293197631836}]\n",
      "MSE value is 0.23253121972084045\n",
      "IoU value is 0.43685293197631836\n",
      "num_param value is 104424\n",
      "Training time: 153.73278903961182\n",
      "Fitness: 12.377490068155138\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lco14k5s1p2agn1', 'HSasm'], fitness: 12.377490068155138, IoU: 0.43685293197631836, FPS: 325.43110580093213, Model Size: 104424\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 23184676 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Leo06k5s1p2arn1EPM2ELRr2arn1EPM2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 876202\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 11:57:38.780979124 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:38.792523652 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:38.792640818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 11:57:38.797024503 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 876 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "876 K     Trainable params\n",
      "0         Non-trainable params\n",
      "876 K     Total params\n",
      "3.505     Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24192b6b1b294f6aab3574cfc1b7a3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:14:19.665415644 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:19.666294489 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:19.667297104 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:19.668776839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd8b240cc914182a8b7eb24fcbdc7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8092585206031799     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8534830808639526     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09335536509752274    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8092585206031799    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8534830808639526    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09335536509752274   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:14:36.357997201 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:36.359978329 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:36.362357593 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:36.367770108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab9c1c46ccd459e91e8693c9ec254f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8089861273765564     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8416067361831665     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09052103012800217    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8089861273765564    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8416067361831665    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09052103012800217   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8416067361831665, 'test_mse': 0.09052103012800217, 'test_iou': 0.8089861273765564}]\n",
      "MSE value is 0.09052103012800217\n",
      "IoU value is 0.8089861273765564\n",
      "num_param value is 876202\n",
      "Training time: 1000.895192861557\n",
      "Fitness: 16.38358788928821\n",
      "********\n",
      "chromosome: ['Leo06k5s1p2arn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: 16.38358788928821, IoU: 0.8089861273765564, FPS: 127.06417360228028, Model Size: 876202\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 14530\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:14:52.174950236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:52.178633197 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:52.182387633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:14:52.184451003 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 14.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "14.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.5 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3674c7cc064a04a2ff60df08e02b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:16:46.074917507 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:46.075831967 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:46.075879893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:46.077640629 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02757df19404e7aa8c8e2d8525bcb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5591850876808167     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.856324315071106     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07870396971702576    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5591850876808167    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.856324315071106    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07870396971702576   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:16:52.941690573 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:52.943591068 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:52.944598320 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:52.948770504 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ad6078293a468e81b350d3d6744898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5700867772102356     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8596734404563904     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07892286032438278    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5700867772102356    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8596734404563904    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07892286032438278   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8596734404563904, 'test_mse': 0.07892286032438278, 'test_iou': 0.5700867772102356}]\n",
      "MSE value is 0.07892286032438278\n",
      "IoU value is 0.5700867772102356\n",
      "num_param value is 14530\n",
      "Training time: 113.88848662376404\n",
      "Fitness: 14.954840987423475\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 14.954840987423475, IoU: 0.5700867772102356, FPS: 361.50115878408064, Model Size: 14530\n",
      "\n",
      "Architecture: LRr2agn1EPa2ELne6arn1EPa2ELRr2arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'Pa2', 'Lne6arn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 42013\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:16:58.590943128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:58.590943193 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:58.593738926 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:16:58.601062601 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 42.0 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "42.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.0 K    Total params\n",
      "0.168     Total estimated model params size (MB)\n",
      "77        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49db552c453948a0961ccc7b547a4710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:50:05.698456219 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:05.699482754 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:05.701004030 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:05.706819075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a70aeb25d645a8b499c06a996ae54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5226453542709351     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.927460253238678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.15538686513900757    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5226453542709351    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.927460253238678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.15538686513900757   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:50:32.601287677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:32.605055128 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:32.606991126 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:32.607802017 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc5d641908046d7978946c9c7de027a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5031487345695496     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9524561762809753     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16334250569343567    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5031487345695496    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9524561762809753    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16334250569343567   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9524561762809753, 'test_mse': 0.16334250569343567, 'test_iou': 0.5031487345695496}]\n",
      "MSE value is 0.16334250569343567\n",
      "IoU value is 0.5031487345695496\n",
      "num_param value is 1488750\n",
      "Training time: 1621.8385894298553\n",
      "Fitness: 12.1386581094084\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'LDd0.43n1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Ldo13arn1', 'HSasm'], fitness: 12.1386581094084, IoU: 0.5031487345695496, FPS: 85.37201318456245, Model Size: 1488750\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPM2ELne5arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELne5arn1EUf2mnearestES1ELdo06arn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 249177355 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'Lne5arn1', 'Uf2mnearest', 'S1', 'Ldo06arn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 61397\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:50:57.327329203 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:57.333170301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:57.340419879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:50:57.346516545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 61.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "61.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.4 K    Total params\n",
      "0.246     Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ca7f1b5db94122b980cfa31b70bde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:54:08.849996824 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:08.860616985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:08.861024827 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:08.867209907 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bed6ac15bc411f8ecc7f81e707051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5015895366668701     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9016067385673523     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12832142412662506    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5015895366668701    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9016067385673523    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12832142412662506   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:54:16.927915467 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:16.929376435 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:16.931906129 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:16.933547719 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8829790762466fae02136cd6fbd60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5008652806282043     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8946090936660767     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13067878782749176    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5008652806282043    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8946090936660767    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13067878782749176   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8946090936660767, 'test_mse': 0.13067878782749176, 'test_iou': 0.5008652806282043}]\n",
      "MSE value is 0.13067878782749176\n",
      "IoU value is 0.5008652806282043\n",
      "num_param value is 61397\n",
      "Training time: 190.83100271224976\n",
      "Fitness: 13.791500615379592\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 13.791500615379592, IoU: 0.5008652806282043, FPS: 271.6162166182431, Model Size: 61397\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELco15k3s1p1arn1EPM2ELdo15arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'Lco15k3s1p1arn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 15, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 255564526 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne5arn1', 'PM2', 'Lco15k3s1p1arn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4300342\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 12:54:26.840043753 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:26.846426818 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:26.860729477 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 12:54:26.868719745 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.3 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.201    Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714277639bdc4affa22d01f1088f922d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:11:25.919235611 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:11:25.921254082 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:11:25.926380062 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:11:25.930846203 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31d7726dbfe440583b41b409e0403da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6521451473236084     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0767532587051392     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19215182960033417    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6521451473236084    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0767532587051392    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19215182960033417   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:12:50.335213572 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:12:50.357937233 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:12:50.358820405 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:12:50.359246016 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9818a9e0ebb6474ab4a88f9f1837b7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.658428966999054     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0722582340240479     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18898332118988037    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.658428966999054    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0722582340240479    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18898332118988037   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0722582340240479, 'test_mse': 0.18898332118988037, 'test_iou': 0.658428966999054}]\n",
      "MSE value is 0.18898332118988037\n",
      "IoU value is 0.658428966999054\n",
      "num_param value is 4300342\n",
      "Training time: 4619.489930391312\n",
      "Fitness: 10.694494581609497\n",
      "********\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: 10.694494581609497, IoU: 0.658428966999054, FPS: 27.124214735638702, Model Size: 4300342\n",
      "\n",
      "For generation 8, the best fitness of the population is 16.93980605543331.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_8.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 9 ***\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELme4arn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 401524\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:14:04.324192994 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:14:04.331194755 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:14:04.333472906 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:14:04.335646896 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 401 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "401 K     Trainable params\n",
      "0         Non-trainable params\n",
      "401 K     Total params\n",
      "1.606     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c4faea3cae4dba8fb3d7fd0a2191c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:30:23.523946304 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:23.533258597 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:23.534232799 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:23.535937813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510422bfa68f4eed89d2772450de2b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7342961430549622     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9051541686058044     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07760247588157654    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7342961430549622    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9051541686058044    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07760247588157654   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:30:40.750030489 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:40.750593564 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:40.750984051 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:40.757133410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641593dcdb57443b9d532167f56d5334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7308208346366882     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9038076400756836     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07639085501432419    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7308208346366882    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9038076400756836    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07639085501432419   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9038076400756836, 'test_mse': 0.07639085501432419, 'test_iou': 0.7308208346366882}]\n",
      "MSE value is 0.07639085501432419\n",
      "IoU value is 0.7308208346366882\n",
      "num_param value is 401524\n",
      "Training time: 978.7648031711578\n",
      "Fitness: 16.196989957395996\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: 16.196989957395996, IoU: 0.7308208346366882, FPS: 131.12838725540087, Model Size: 401524\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELRr2arn1EPM2ELDd0.38n1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELeo06k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 6175404 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'LRr2arn1', 'PM2', 'LDd0.38n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Leo06k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LRr2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 306234\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:30:55.195510937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:55.196423808 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:55.197014842 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:30:55.202030371 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 306 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "306 K     Trainable params\n",
      "0         Non-trainable params\n",
      "306 K     Total params\n",
      "1.225     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b4439b81a649e2a533d6731e67d04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:40:22.818135661 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:22.820275122 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:22.824304243 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:22.827011461 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04274708d2d470fb0a64b46c1f5d1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7397606372833252     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8949124217033386     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07280623912811279    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7397606372833252    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8949124217033386    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07280623912811279   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:40:32.826488403 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:32.827481382 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:32.829487024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:32.834631865 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637493d1f2644c639703881401fd4193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7393520474433899     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8853061199188232     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06806669384241104    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7393520474433899    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8853061199188232    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06806669384241104   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8853061199188232, 'test_mse': 0.06806669384241104, 'test_iou': 0.7393520474433899}]\n",
      "MSE value is 0.06806669384241104\n",
      "IoU value is 0.7393520474433899\n",
      "num_param value is 306234\n",
      "Training time: 566.645968914032\n",
      "Fitness: 16.44999767744372\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: 16.44999767744372, IoU: 0.7393520474433899, FPS: 220.85723201958695, Model Size: 306234\n",
      "\n",
      "Architecture: Lne3agn1EPa2ELme4arn1EUf2mnearestES1ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lne3agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 2573\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:40:41.979657469 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:41.989935864 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:41.989986951 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:40:41.996694632 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 2.6 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02af52d41d84477bd0d5c7e8405b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:42:30.441005398 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:30.443987615 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:30.448043099 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:31.456411172 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b445a84627e4467bd1bb5141b0d4af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6764699220657349     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8620941638946533     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05252663046121597    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6764699220657349    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8620941638946533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05252663046121597   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:42:36.715605760 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:36.716892832 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:36.720749884 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:36.726550749 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f6fc1e7d3e4153811a8a33eb406735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6729873418807983     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8631317019462585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05319644510746002    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6729873418807983    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8631317019462585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05319644510746002   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8631317019462585, 'test_mse': 0.05319644510746002, 'test_iou': 0.6729873418807983}]\n",
      "MSE value is 0.05319644510746002\n",
      "IoU value is 0.6729873418807983\n",
      "num_param value is 2573\n",
      "Training time: 109.46320104598999\n",
      "Fitness: 16.222205235904735\n",
      "********\n",
      "chromosome: ['Lne3agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm'], fitness: 16.222205235904735, IoU: 0.6729873418807983, FPS: 403.3714174650242, Model Size: 2573\n",
      "\n",
      "Architecture: Lne5arn1EPM2ELDd0.43n1EUf2mnearestES1ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'PM2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:42:41.751419959 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:41.759757939 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:41.760730153 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:42:41.764137872 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 48.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "48.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.3 K    Total params\n",
      "0.193     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b41cf143354cb88d9d9072dbde2c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:45:57.246480458 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:45:57.247352901 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:45:57.249336485 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:45:57.252201534 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58939c51d37241a6a3ce18ce167f3d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6760429739952087     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8954306840896606     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0721205547451973     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6760429739952087    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8954306840896606    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0721205547451973    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:46:03.079796610 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:03.090921816 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:03.092852823 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:03.101607430 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089f2b3c03454250b94e6a2bb884cf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6716681122779846     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8980798125267029     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0738682895898819     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6716681122779846    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8980798125267029    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0738682895898819    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8980798125267029, 'test_mse': 0.0738682895898819, 'test_iou': 0.6716681122779846}]\n",
      "MSE value is 0.0738682895898819\n",
      "IoU value is 0.6716681122779846\n",
      "num_param value is 48290\n",
      "Training time: 196.4866726398468\n",
      "Fitness: 15.980520083975891\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'PM2', 'LDd0.43n1', 'Uf2mnearest', 'S1', 'Lco09k5s1p2arn1', 'HSasm'], fitness: 15.980520083975891, IoU: 0.6716681122779846, FPS: 365.50042806374495, Model Size: 48290\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 14530\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:46:09.657659079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:09.660147759 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:09.665757247 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:46:09.675729216 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 14.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "14.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.5 K    Total params\n",
      "0.058     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3574f8db4ed04ad78f5a39b6c2688546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:48:04.944229377 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:04.947383582 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:04.951920498 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:04.958589093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264af79f467c40ad84cbf745b775c8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6025940775871277     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8747633099555969     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08923150599002838    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6025940775871277    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8747633099555969    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08923150599002838   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:48:10.912634739 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:10.914000960 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:10.916107964 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:10.920838380 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2419ae930b44721a2bf18f68a455290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5903450846672058     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8801061511039734     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09193950146436691    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5903450846672058    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8801061511039734    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09193950146436691   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8801061511039734, 'test_mse': 0.09193950146436691, 'test_iou': 0.5903450846672058}]\n",
      "MSE value is 0.09193950146436691\n",
      "IoU value is 0.5903450846672058\n",
      "num_param value is 14530\n",
      "Training time: 115.2987220287323\n",
      "Fitness: 15.046937372852588\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 15.046937372852588, IoU: 0.5903450846672058, FPS: 355.87515440078073, Model Size: 14530\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27262\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:48:16.629739885 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:16.633662565 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:16.634721541 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:48:16.640633590 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.3 K    Total params\n",
      "0.109     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c1c271ac614195803d3d6a5f7439e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:49:58.548513589 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:49:58.557232614 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:49:58.559484722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:49:58.568726583 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e047ae466d694246b05a1a9cecb524d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6008387804031372     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.944335401058197     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20743481814861298    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6008387804031372    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.944335401058197    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20743481814861298   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:50:04.794238331 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:04.794386668 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:04.795000545 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:04.795942742 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc37bd5fe392457c8f9cbe8209de7ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.576181173324585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9286420941352844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23038938641548157    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.576181173324585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9286420941352844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23038938641548157   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9286420941352844, 'test_mse': 0.23038938641548157, 'test_iou': 0.576181173324585}]\n",
      "MSE value is 0.23038938641548157\n",
      "IoU value is 0.576181173324585\n",
      "num_param value is 27262\n",
      "Training time: 101.91997838020325\n",
      "Fitness: 13.862058073620275\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 13.862058073620275, IoU: 0.576181173324585, FPS: 345.1452673184288, Model Size: 27262\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELRr3agn1EPa2ELRr2arn1EUf2mnearestES0ELne4agn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'LRr3agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 92567\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:50:10.679874620 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:10.688219905 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:10.688704229 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:50:10.696164826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 92.6 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "92.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.6 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fb986ee1a2477cb1baeb76b51ebc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:52:53.250592228 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:52:53.252534836 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:52:53.252720421 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:52:53.259651526 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4990734b71154be8b225a63ff5eeb211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6419451236724854     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8894965648651123     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08244114369153976    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6419451236724854    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8894965648651123    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08244114369153976   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:53:00.136331831 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:00.137282305 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:00.142159104 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:00.143151190 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5582aa6d1b1443ca772b39789ccc0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6217772364616394     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9011090993881226     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08490325510501862    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6217772364616394    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9011090993881226    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08490325510501862   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9011090993881226, 'test_mse': 0.08490325510501862, 'test_iou': 0.6217772364616394}]\n",
      "MSE value is 0.08490325510501862\n",
      "IoU value is 0.6217772364616394\n",
      "num_param value is 92567\n",
      "Training time: 163.55666041374207\n",
      "Fitness: 15.342617104276075\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'LRr3agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 15.342617104276075, IoU: 0.6217772364616394, FPS: 313.3326801684538, Model Size: 92567\n",
      "\n",
      "Architecture: Lme3arn1EPa2ELdo06arn1EPa2ELne3arn1EUf2mnearestES1ELRr2arn1EUf2mnearestES0ELme3arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 61397\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:53:07.640200437 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:07.643011854 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:07.643740543 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:53:07.645874888 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 61.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "61.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.4 K    Total params\n",
      "0.246     Total estimated model params size (MB)\n",
      "75        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c46c5ad28874349a91a2c04215b956e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:56:17.051655857 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:17.054731352 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:17.056797909 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:17.062920586 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1f10c8c21b45c882de999ee57d35b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49682319164276123    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8978629112243652     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12866881489753723    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49682319164276123   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8978629112243652    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12866881489753723   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:56:25.187759884 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:25.194135745 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:25.202804048 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:25.205170546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d4fd628444b30ac20415e51054b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4880477786064148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.892478883266449     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12688162922859192    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4880477786064148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.892478883266449    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12688162922859192   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.892478883266449, 'test_mse': 0.12688162922859192, 'test_iou': 0.4880477786064148}]\n",
      "MSE value is 0.12688162922859192\n",
      "IoU value is 0.4880477786064148\n",
      "num_param value is 61397\n",
      "Training time: 190.44250917434692\n",
      "Fitness: 13.693127305790902\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lme3arn1', 'HSasm'], fitness: 13.693127305790902, IoU: 0.4880477786064148, FPS: 270.37115775574426, Model Size: 61397\n",
      "\n",
      "Architecture: LDd0.43n1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES0ELme6arn1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['LDd0.43n1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 42543\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:56:33.698466097 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:33.703684706 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:33.713924837 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:56:33.715083726 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 42.5 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "42.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.5 K    Total params\n",
      "0.170     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4550f0f444494697b67819798bbb3955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:58:25.658539024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:25.660258217 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:25.662908451 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:25.666328845 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8105445ac3b041b9936a6b1fd7bd8e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27893081307411194    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8821821212768555     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.8679261207580566     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27893081307411194   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8821821212768555    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.8679261207580566    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:58:31.826191846 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:31.826191827 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:31.829687482 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:31.838821960 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5fc01b0ab6438295894eacec207779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2664400339126587     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.0164520740509033     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.187445640563965     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2664400339126587    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.0164520740509033    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.187445640563965    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 2.0164520740509033, 'test_mse': 3.187445640563965, 'test_iou': 0.2664400339126587}]\n",
      "MSE value is 3.187445640563965\n",
      "IoU value is 0.2664400339126587\n",
      "num_param value is 42543\n",
      "Training time: 111.9685230255127\n",
      "Fitness: 5.009948041279129\n",
      "********\n",
      "chromosome: ['LDd0.43n1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lme6arn1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: 5.009948041279129, IoU: 0.2664400339126587, FPS: 342.98402770298884, Model Size: 42543\n",
      "\n",
      "Architecture: LRr3arn1EPa2ELDd0.43n1EUf2mnearestES2ELco14k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lco14k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 14, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 104424\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 14:58:37.728161006 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:37.738206176 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:37.739471108 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 14:58:37.748422893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 104 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "104 K     Trainable params\n",
      "0         Non-trainable params\n",
      "104 K     Total params\n",
      "0.418     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40db1eefe1124e0896fec37ac7e5b283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 15:01:11.007358350 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:11.023862720 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:11.028284310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:11.037033266 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9a45833868479ba56f34bf1db3b1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49893999099731445    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.154830813407898     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19335250556468964    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49893999099731445   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.154830813407898    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19335250556468964   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 15:01:18.755614684 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:18.765909074 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:18.766830619 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:18.773959594 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ff7202f7fb45a798b7784ce5153ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.47868630290031433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1623858213424683     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19670777022838593    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.47868630290031433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1623858213424683    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19670777022838593   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.1623858213424683, 'test_mse': 0.19670777022838593, 'test_iou': 0.47868630290031433}]\n",
      "MSE value is 0.19670777022838593\n",
      "IoU value is 0.47868630290031433\n",
      "num_param value is 104424\n",
      "Training time: 154.27384209632874\n",
      "Fitness: 13.038697966046351\n",
      "********\n",
      "chromosome: ['LRr3arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S2', 'Lco14k5s1p2agn1', 'HSasm'], fitness: 13.038697966046351, IoU: 0.47868630290031433, FPS: 319.9970459257082, Model Size: 104424\n",
      "\n",
      "Architecture: Lbo05k3s1p1arn1EPM2ELDd0.43n1EPM2ELco04k5s1p2arn1EUf2mnearestES1ELne3arn1EUf2mnearestES1ELdo13arn1EHSasmEE\n",
      "Chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LDd0.43n1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Ldo13arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 13, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 37128984 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo05k3s1p1arn1', 'PM2', 'LDd0.43n1', 'PM2', 'Lco04k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Ldo13arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 4300342\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 15:01:24.445817437 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:24.449365440 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:24.451347554 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 15:01:24.454330386 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 4.3 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.201    Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bfe3c7cc07407c91dc2a18780004cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 16:18:29.584118465 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:18:29.584988310 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:18:29.585973603 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:18:29.596088187 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6662c4a6d4418b92a504035cf47499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6757092475891113     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.1028953790664673     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20713260769844055    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6757092475891113    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.1028953790664673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20713260769844055   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 16:19:54.444748510 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:19:54.448833182 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:19:54.448888640 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:19:54.454652964 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ae2e801d7f43f8a7b267cfd54e983e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6822306513786316     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0972431898117065     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20344559848308563    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6822306513786316    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0972431898117065    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20344559848308563   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 1.0972431898117065, 'test_mse': 0.20344559848308563, 'test_iou': 0.6822306513786316}]\n",
      "MSE value is 0.20344559848308563\n",
      "IoU value is 0.6822306513786316\n",
      "num_param value is 4300342\n",
      "Training time: 4624.122945070267\n",
      "Fitness: 10.831438587732627\n",
      "********\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: 10.831438587732627, IoU: 0.6822306513786316, FPS: 27.055573157318257, Model Size: 4300342\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELDd0.43n1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 23184676 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELne5arn1EPa2ELdo09agn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 159265904 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lne5arn1', 'Pa2', 'Ldo09agn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: LDd0.35n1EPM2ELdo12agn1EPa2ELeo09k5s1p2arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELdo08agn1EHSasmEE\n",
      "Chromosome: ['LDd0.35n1', 'PM2', 'Ldo12agn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 50257592 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['LDd0.35n1', 'PM2', 'Ldo12agn1', 'Pa2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Ldo08agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lco04k5s1p2agn1EPa2ELdo06arn1EPa2ELRr2arn1EPa2ELdo07arn1EUf2mnearestES2ELRr2arn1EUf2mnearestES1ELme3arn1EUf2mnearestES0ELRr3arn1EHSasmEE\n",
      "Chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Skipping architecture, total parameters: 5130559 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco04k5s1p2agn1', 'Pa2', 'Ldo06arn1', 'Pa2', 'LRr2arn1', 'Pa2', 'Ldo07arn1', 'Uf2mnearest', 'S2', 'LRr2arn1', 'Uf2mnearest', 'S1', 'Lme3arn1', 'Uf2mnearest', 'S0', 'LRr3arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELeo12k3s1p1agn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 3505016\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 16:21:11.514390561 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:21:11.517412912 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:21:11.531717019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 16:21:11.532828542 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 3.5 M  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.020    Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ad0fbaa7544ea9a16ccf8abbb8aaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:00:06.560713328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:06.562861649 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:06.564712024 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:06.566608311 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156f9fee77a64270b8427d1751d2ee4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5196375250816345     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9794400334358215     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5553550720214844     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5196375250816345    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9794400334358215    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5553550720214844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:00:56.306439621 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:56.308554345 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:56.309419282 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:00:56.311472009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d888d6975d3544f0904d7c613999e7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5117543339729309     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9773966670036316     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4966267943382263     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5117543339729309    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9773966670036316    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4966267943382263    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9773966670036316, 'test_mse': 0.4966267943382263, 'test_iou': 0.5117543339729309}]\n",
      "MSE value is 0.4966267943382263\n",
      "IoU value is 0.5117543339729309\n",
      "num_param value is 3505016\n",
      "Training time: 2335.611457824707\n",
      "Fitness: 8.294219821669516\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'Leo12k3s1p1agn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm'], fitness: 8.294219821669516, IoU: 0.5117543339729309, FPS: 45.73181774637943, Model Size: 3505016\n",
      "\n",
      "Architecture: Lco07k3s1p1agn1EPM2ELco10k3s1p1agn1EPM2ELdo15arn1EUf2mnearestES1ELDd0.35n1EUf2mnearestES0ELco07k3s1p1agn1EHSasmEE\n",
      "Chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 15, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 32642624 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lco07k3s1p1agn1', 'PM2', 'Lco10k3s1p1agn1', 'PM2', 'Ldo15arn1', 'Uf2mnearest', 'S1', 'LDd0.35n1', 'Uf2mnearest', 'S0', 'Lco07k3s1p1agn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "Architecture: Lne6arn1EPM2ELDd0.35n1EPM2ELeo09k5s1p2arn1EUf2mnearestES1ELco10k3s1p1agn1EUf2mnearestES0ELne5arn1EHSasmEE\n",
      "Chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Skipping architecture, total parameters: 7965325 exceed the threshold of 5000000\n",
      "Skipping architecture due to error: The architecture is invalid due to exceeding the parameter limit.\n",
      "chromosome: ['Lne6arn1', 'PM2', 'LDd0.35n1', 'PM2', 'Leo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lco10k3s1p1agn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'HSasm'], fitness: -inf, IoU: None, FPS: None, Model Size: None\n",
      "\n",
      "For generation 9, the best fitness of the population is 16.44999767744372.\n",
      "The best historical fitness is 17.38408774559595,with the most fit individual having the following genes: ['Lne6arn1', 'PM2', 'Lne3arn1', 'PM2', 'Lbo09k5s1p2arn1', 'Uf2mnearest', 'S1', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne6arn1', 'HSasm'].\n",
      "Text file saved: ./logs/GA_logs/GA_generation_9.txt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** GENERATION 10 ***\n",
      "Architecture: LRr2agn1EPM2ELbo05k5s1p2agn1EUf2mnearestES0ELco04k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 306234\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:01:41.624752327 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:01:41.625862131 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:01:41.628674599 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:01:41.631935413 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 306 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "306 K     Trainable params\n",
      "0         Non-trainable params\n",
      "306 K     Total params\n",
      "1.225     Total estimated model params size (MB)\n",
      "35        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a84c075d72a41c8b6fd6c07e16efc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:11:08.852810490 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:08.864717462 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:08.865728189 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:08.866918317 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4290e400bae3431b90cd80ccc2d91170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.738410472869873     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8951371312141418     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07243002206087112    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.738410472869873    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8951371312141418    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07243002206087112   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:11:18.932066879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:18.932781208 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:18.934919384 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:18.938963369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ff3dbf35df4d948b279b674267f4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7381663918495178     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8808402419090271     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06536585837602615    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7381663918495178    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8808402419090271    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06536585837602615   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8808402419090271, 'test_mse': 0.06536585837602615, 'test_iou': 0.7381663918495178}]\n",
      "MSE value is 0.06536585837602615\n",
      "IoU value is 0.7381663918495178\n",
      "num_param value is 306234\n",
      "Training time: 567.4197082519531\n",
      "Fitness: 16.46187676337844\n",
      "********\n",
      "chromosome: ['LRr2agn1', 'PM2', 'Lbo05k5s1p2agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2arn1', 'HSasm'], fitness: 16.46187676337844, IoU: 0.7381663918495178, FPS: 217.53594347172367, Model Size: 306234\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPa2ELme4arn1EUf2mnearestES1ELne3agn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 321220\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:11:27.224697574 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:27.229678185 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:27.231724968 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:11:27.236569985 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 321 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "321 K     Trainable params\n",
      "0         Non-trainable params\n",
      "321 K     Total params\n",
      "1.285     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f41939410524343bfdd28863fa9b61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:22:50.059476712 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:22:50.069133195 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:22:50.070093221 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:22:50.073577714 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85747de5a52b44da8015be41df7ff8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7881747484207153     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8667656183242798     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05737844854593277    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7881747484207153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8667656183242798    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05737844854593277   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:23:03.323870297 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:03.326854339 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:03.329849548 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:03.339930293 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69325dc79ee4dc289b0c5ff7def667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7926361560821533     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8536776900291443     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.050683505833148956    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7926361560821533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8536776900291443    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.050683505833148956   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8536776900291443, 'test_mse': 0.050683505833148956, 'test_iou': 0.7926361560821533}]\n",
      "MSE value is 0.050683505833148956\n",
      "IoU value is 0.7926361560821533\n",
      "num_param value is 321220\n",
      "Training time: 682.8232455253601\n",
      "Fitness: 17.122755518290496\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'Pa2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne3agn1', 'HSasm'], fitness: 17.122755518290496, IoU: 0.7926361560821533, FPS: 167.69821514901219, Model Size: 321220\n",
      "\n",
      "Architecture: Lbo16k5s1p2agn1EPM2ELme4arn1EUf2mnearestES1ELne6arn1EHSasmEE\n",
      "Chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne6arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 16, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 401524\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:23:15.329352961 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:15.334650680 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:15.334691170 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:23:15.341498064 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 401 K  | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "401 K     Trainable params\n",
      "0         Non-trainable params\n",
      "401 K     Total params\n",
      "1.606     Total estimated model params size (MB)\n",
      "42        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c3735adbc44482932fd572b860b365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:39:36.538357076 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:36.543643978 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:36.549063218 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:36.556743295 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c127ee1ab44a4f09afb8adbaa0b2238f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7612974643707275     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8832884430885315     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06523247808218002    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7612974643707275    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8832884430885315    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06523247808218002   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:39:53.914219756 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:53.915613363 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:53.917529775 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:39:53.926494052 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdae359d6584f9b9f01a22dbd4e76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7586570978164673     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8736872673034668     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.060796987265348434    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7586570978164673    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8736872673034668    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.060796987265348434   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8736872673034668, 'test_mse': 0.060796987265348434, 'test_iou': 0.7586570978164673}]\n",
      "MSE value is 0.060796987265348434\n",
      "IoU value is 0.7586570978164673\n",
      "num_param value is 401524\n",
      "Training time: 980.2013168334961\n",
      "Fitness: 16.611921413186607\n",
      "********\n",
      "chromosome: ['Lbo16k5s1p2agn1', 'PM2', 'Lme4arn1', 'Uf2mnearest', 'S1', 'Lne6arn1', 'HSasm'], fitness: 16.611921413186607, IoU: 0.7586570978164673, FPS: 129.78312379756636, Model Size: 401524\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EUf2mnearestES0ELco09k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:40:08.437645410 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:40:08.445555839 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:40:08.446626522 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:40:08.454892891 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 48.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "48.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.3 K    Total params\n",
      "0.193     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdd5017354d44aea209a5c3ea6502ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:43:26.031541800 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:26.031606349 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:26.032501432 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:26.034255551 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf16b7b001c4eee811e64aeba1180d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6064647436141968     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9311707615852356     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08977244794368744    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6064647436141968    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9311707615852356    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08977244794368744   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:43:32.115629857 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:32.116590840 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:32.118350306 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:32.119011588 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ac035abbba4f84872616356f3a1ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5966086387634277     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9360173940658569     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.09218829870223999    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5966086387634277    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9360173940658569    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.09218829870223999   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9360173940658569, 'test_mse': 0.09218829870223999, 'test_iou': 0.5966086387634277}]\n",
      "MSE value is 0.09218829870223999\n",
      "IoU value is 0.5966086387634277\n",
      "num_param value is 48290\n",
      "Training time: 197.59616088867188\n",
      "Fitness: 15.073726744956547\n",
      "********\n",
      "chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Uf2mnearest', 'S0', 'Lco09k5s1p2arn1', 'HSasm'], fitness: 15.073726744956547, IoU: 0.5966086387634277, FPS: 353.3125940787703, Model Size: 48290\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELRr3agn1EPa2ELRr2arn1EUf2mnearestES0ELne4agn1EUf2mnearestES0ELco04k5s1p2agn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'LRr3agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 13747\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:43:38.908773010 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:38.912420861 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:38.915009777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:43:38.922062980 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 13.7 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "13.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.7 K    Total params\n",
      "0.055     Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8e6f31ef024b0ba700d2724b280255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:46:00.165488236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:00.167459373 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:00.169765347 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:00.173066987 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bd21df576e49b4b62644f98da1af7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5222529768943787     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8816934823989868     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08912423253059387    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5222529768943787    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8816934823989868    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08912423253059387   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:46:07.486731188 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:07.490693067 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:07.494409258 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:07.499155079 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e610f656b54be98d24b74bd3256b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5215021967887878     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8732750415802002     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08555491268634796    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5215021967887878    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8732750415802002    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08555491268634796   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.8732750415802002, 'test_mse': 0.08555491268634796, 'test_iou': 0.5215021967887878}]\n",
      "MSE value is 0.08555491268634796\n",
      "IoU value is 0.5215021967887878\n",
      "num_param value is 13747\n",
      "Training time: 142.29543113708496\n",
      "Fitness: 14.413153504049342\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'LRr3agn1', 'Pa2', 'LRr2arn1', 'Uf2mnearest', 'S0', 'Lne4agn1', 'Uf2mnearest', 'S0', 'Lco04k5s1p2agn1', 'HSasm'], fitness: 14.413153504049342, IoU: 0.5215021967887878, FPS: 336.0532794127362, Model Size: 13747\n",
      "\n",
      "Architecture: Lme3arn1EPM2ELne5arn1EPa2ELne3arn1EUf2mnearestES1ELRr3agn1EUf2mnearestES0ELbo13k5s1p2arn1EHSasmEE\n",
      "Chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 13, 'kernel_size': '5', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 93350\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:46:13.527489587 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:13.530445009 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:13.531224098 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:46:13.531368816 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 93.4 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "93.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "93.4 K    Total params\n",
      "0.373     Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0f2718d5b645fc8069660cd468b86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:50:32.481247103 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:32.481246875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:32.482738769 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:32.487803279 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c8dd5e5afd4171ade67fb46d172f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.503257691860199     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9155734181404114     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10075964033603668    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.503257691860199    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9155734181404114    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10075964033603668   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:50:39.646586185 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:39.647148892 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:39.647807511 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:39.649064876 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:215: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dad59e850e44b39a9b62779f01ff295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('test_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5002400279045105     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9306731820106506     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10502810776233673    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5002400279045105    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9306731820106506    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10502810776233673   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are: [{'test_loss': 0.9306731820106506, 'test_mse': 0.10502810776233673, 'test_iou': 0.5002400279045105}]\n",
      "MSE value is 0.10502810776233673\n",
      "IoU value is 0.5002400279045105\n",
      "num_param value is 93350\n",
      "Training time: 258.9640119075775\n",
      "Fitness: 13.958593842466158\n",
      "********\n",
      "chromosome: ['Lme3arn1', 'PM2', 'Lne5arn1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S1', 'LRr3agn1', 'Uf2mnearest', 'S0', 'Lbo13k5s1p2arn1', 'HSasm'], fitness: 13.958593842466158, IoU: 0.5002400279045105, FPS: 299.43025279961984, Model Size: 93350\n",
      "\n",
      "Architecture: Lne5arn1EPa2ELDd0.43n1EPa2ELne3arn1EUf2mnearestES0ELne5arn1EUf2mnearestES0ELdo06arn1EHSasmEE\n",
      "Chromosome: ['Lne5arn1', 'Pa2', 'LDd0.43n1', 'Pa2', 'Lne3arn1', 'Uf2mnearest', 'S0', 'Lne5arn1', 'Uf2mnearest', 'S0', 'Ldo06arn1', 'HSasm']\n",
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "Task type in fitness is: segmentation\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "[{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "***\n",
      "\n",
      "\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.43}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'Upsample', 'mode': 'n'}, {'layer_type': 'SkipConnection'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'SegmentationHead'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.43}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: Upsample, Full Layer: {'layer_type': 'Upsample', 'mode': 'n'}\n",
      "Parsing Upsample\n",
      "Parsed Upsample without error\n",
      "Parsing layer type in generic_network: SkipConnection, Full Layer: {'layer_type': 'SkipConnection'}\n",
      "Parsing SkipConnection\n",
      "Parsed Skip Connection withour error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: SegmentationHead, Full Layer: {'layer_type': 'SegmentationHead'}\n",
      "Parsing SegmentationHead\n",
      "Parsed SegmentationHead without error\n",
      "Architecture is valid, total parameters: 27262\n",
      "Running in not final loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[W818 17:50:45.434448517 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:45.437904274 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:45.438894571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "[W818 17:50:45.447749059 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                        | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model   | GenericNetwork              | 27.3 K | train\n",
      "1 | loss_fn | CategoricalCrossEntropyLoss | 0      | train\n",
      "2 | mse     | MeanSquaredError            | 0      | train\n",
      "----------------------------------------------------------------\n",
      "27.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.3 K    Total params\n",
      "0.109     Total estimated model params size (MB)\n",
      "61        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_iou', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e5b621d7ff40e8959281ee0d3b89ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO CONFIG.INI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: most sanity checks are still missing. Be careful please."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the [Mode] section, select the desired mode for pynattas. If both are true, nas will be done first, then ht will be done on the winning architecture of nas. If only ht is true, then tuning will be done on the architecture written in architecture_code under the [NAS] section.\n",
    "- max_layers in [NAS] section refers to the maximum size of the chromosomes (aka, maximum number of convolutions-type layers).\n",
    "- In the [GA] section, change the parameters for NAS search.\n",
    "- In the [Computation] section, be careful about the num_workers value. Currently set to 1 for safety when testing parallelization. In computation, also change the accellerator to either \"cpu\" or \"gpu\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO PARALLELIZATION (currently broken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Mostly untested.\n",
    "- In main.py, change line 54 (\"nas_result = pnas.optimizers.ga.ga_optimizer(\") to:\n",
    "    - nas_result = pnas.optimizers.ga_concurrent.ga_optimizer(\" for nas parallelization using a ThreadPoolExecutor\n",
    "    - nas_result = pnas.optimizers.ga_concurrent_pp.ga_optimizer(\" for nas parallelization using a ProcessPoolExecutor\n",
    "\n",
    "Currently, it looks like there are issues with ProcessPoolExecutor. Regardless, be careful when selecting num_workers in the config.ini when testing these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO ADD NEW BLOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in pynattas.blocks add the new block to the related .py file depending on type.\n",
    "- in config.ini add the new block as a section with all related parameters. Use \"default_\" for default values that are used during NAS, and \"min_\" and \"max_\" for range values to be used during tuning. Also, update the commented vocabulary at the start for clarity purposes.\n",
    "- in pynattas.configuration.vocabulary, update relative vocabularies.\n",
    "- in pynattas.classes.generic_network, add the layer construction to the list making sure that the current_layers, current_height, and current_width is calculated correctly.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO WORK ON NEW DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add dataset to the \"data\" folder\n",
    "- Add compatible datamodule to the \"datasets\" folder\n",
    "- in pynattas.functions.fitness, import the desired datamodule. Also, around line 59, update the datahandling to be compatible with your datamodule. For the ClassificationHead, Make sure the data is resized to 256x256 sized HxW images, that the number of channels passed to the model is correct.\n",
    "- change config.ini in the [Dataset] section. \"data_path\" should point to the dataset, \"csv_path\" is for a .csv for labels if required. If it's not required, imput None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUIDE TO LOGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs are stored in the \"logs\" folder and in the \"lightning_logs\" folder. In \"logs\", you will find:\n",
    "- logs about NAS iterations and results in the GA_logs subfolder\n",
    "- logs about HT iterations and results in either the GWO_logs or PSO_logs subfolder depending on the selected HT algorithm\n",
    "- logs about the final run comprised of the saved checkpoint .ckpt file in the \"tb_logs\" subfolder, together with all the confusion matrixes generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE (Coming soon...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
