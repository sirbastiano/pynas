{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model training with a generic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.models import resnet18\n",
    "from datasets.RawClassifier.loader import RawClassifierDataModule, RawClassifierDataset\n",
    "\n",
    "# Define dataset module\n",
    "root_dir = '/Data_large/marine/PythonProjects/OtherProjects/lpl-PyNas/data/RawClassifier'\n",
    "dm = RawClassifierDataModule(root_dir, batch_size=4, num_workers=2, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch Lightning module\n",
    "class LitModule(pl.LightningModule):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.float())\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train_model(encoder, dm, max_epochs=10):\n",
    "    model = LitModule(encoder, dm.num_classes)\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Train the model\n",
    "    trainer.fit(model, dm)\n",
    "    return trainer \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = resnet18(pretrained=True, )\n",
    "\n",
    "# Initialize a resnet18 encoder from torchvision, use pretrained weights\n",
    "encoder = resnet18(pretrained=True)\n",
    "encoder.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False) # INPUT\n",
    "encoder.fc = nn.Identity() # Out only features, no classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the defined train_model function and the existing data module (dm)\n",
    "trainer = train_model(encoder, dm, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n"
     ]
    }
   ],
   "source": [
    "import pynattas as pnas\n",
    "from pynattas import classes, functions\n",
    "from pynattas.optimizers.ga import single_point_crossover, mutation \n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision.models import resnet18\n",
    "from datasets.RawClassifier.loader import RawClassifierDataModule, RawClassifierDataset\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Define dataset module\n",
    "root_dir = '/Data_large/marine/PythonProjects/OtherProjects/lpl-PyNas/data/RawClassifier'\n",
    "dm = RawClassifierDataModule(root_dir, batch_size=4, num_workers=2, transform=None)\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Model parameters\n",
    "max_layers = int(config.getint('NAS', 'max_layers'))\n",
    "max_iter = int(config['GA']['max_iterations'])\n",
    "# GA parameters\n",
    "n_individuals = int(config['GA']['population_size'])\n",
    "mating_pool_cutoff = float(config['GA']['mating_pool_cutoff'])\n",
    "mutation_probability = float(config['GA']['mutation_probability'])\n",
    "# Logging\n",
    "logs_directory = str(config['GA']['logs_dir_GA'])\n",
    "\n",
    "# Torch stuff\n",
    "seed = config.getint(section='Computation', option='seed')\n",
    "pl.seed_everything(seed=seed, workers=True)  # For reproducibility\n",
    "torch.set_float32_matmul_precision(\"medium\")  # to make lightning happy\n",
    "num_workers = config.getint(section='Computation', option='num_workers')\n",
    "accelerator = config.get(section='Computation', option='accelerator')\n",
    "\n",
    "log_learning_rate=None\n",
    "batch_size=None\n",
    "# Get model parameters\n",
    "log_lr = log_learning_rate if log_learning_rate is not None else config.getfloat(section='Search Space', option='default_log_lr')\n",
    "\n",
    "lr = 10**log_lr\n",
    "bs = batch_size if batch_size is not None else config.getint(section='Search Space', option='default_bs')\n",
    "print(f\"-----------The batch size of the data to be loaded in the model is: {bs}-----------\")\n",
    "def initialize_logging(max_iter):\n",
    "    mean_fitness_vector = np.zeros(shape=(max_iter + 1))\n",
    "    median_fitness_vector = np.zeros_like(mean_fitness_vector)\n",
    "    best_fitness_vector = np.zeros_like(mean_fitness_vector)\n",
    "    iou_vector = np.zeros_like(mean_fitness_vector)\n",
    "    fps_vector = np.zeros_like(mean_fitness_vector)\n",
    "    model_size_vector = np.zeros_like(mean_fitness_vector)\n",
    "\n",
    "    historical_best_fitness = float('-inf')\n",
    "    historical_best_iou = float('-inf')\n",
    "    historical_best_fps = float('-inf')\n",
    "    historical_best_model_size = float('inf')\n",
    "\n",
    "    best_individual = None  # To keep track of the best individual\n",
    "\n",
    "    return {\n",
    "        \"mean_fitness_vector\": mean_fitness_vector,\n",
    "        \"median_fitness_vector\": median_fitness_vector,\n",
    "        \"best_fitness_vector\": best_fitness_vector,\n",
    "        \"iou_vector\": iou_vector,\n",
    "        \"fps_vector\": fps_vector,\n",
    "        \"model_size_vector\": model_size_vector,\n",
    "        \"historical_best_fitness\": historical_best_fitness,\n",
    "        \"historical_best_iou\": historical_best_iou,\n",
    "        \"historical_best_fps\": historical_best_fps,\n",
    "        \"historical_best_model_size\": historical_best_model_size,\n",
    "        \"best_individual\": best_individual,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConstructor:\n",
    "    def __init__(self, encoder, dm):\n",
    "        # Validate that dm has the necessary attributes.\n",
    "        if not hasattr(dm, \"num_classes\") or not hasattr(dm, \"input_shape\"):\n",
    "            raise ValueError(\"dm must have 'num_classes' and 'input_shape' attributes.\")\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.num_classes = dm.num_classes\n",
    "        self.input_shape = dm.input_shape\n",
    "        print(f\"Input shape: {self.input_shape}\")\n",
    "        \n",
    "        # Verify that encoder has parameters.\n",
    "        try:\n",
    "            next(self.encoder.parameters())\n",
    "        except StopIteration:\n",
    "            raise ValueError(\"Encoder appears to have no parameters.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Provided encoder does not follow expected API.\") from e\n",
    "\n",
    "        # Validate input_shape is a tuple and properly dimensioned.\n",
    "        if not isinstance(self.input_shape, tuple):\n",
    "            raise TypeError(\"input_shape must be a tuple.\")\n",
    "        if len(self.input_shape) == 3:\n",
    "            print(\"Adding channel dimension to input shape.\")\n",
    "            print(f\"Original input shape: {self.input_shape}\")\n",
    "            self.input_shape = (1,) + self.input_shape\n",
    "            print(f\"Updated input shape: {self.input_shape}\")\n",
    "        elif len(self.input_shape) != 4:\n",
    "            raise ValueError(\"input_shape must be of length 3 or 4.\")\n",
    "\n",
    "        self.head_layer = self.build_head(input_shape=self.input_shape)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.encoder,\n",
    "            self.head_layer\n",
    "        )\n",
    "        \n",
    "        self.valid_model = self.dummy_test()\n",
    "\n",
    "    def build_head(self, input_shape=(1, 2, 256, 256)):\n",
    "        # Get the device from the encoder's parameters.\n",
    "        try:\n",
    "            device = next(self.encoder.parameters()).device\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to determine device from encoder parameters.\") from e\n",
    "        \n",
    "        # Run a dummy input through the encoder to get the feature shape.\n",
    "        dummy = torch.randn(*input_shape).float().to(device)\n",
    "        try:\n",
    "            features = self.encoder(dummy)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error when running dummy input through encoder.\") from e\n",
    "        \n",
    "        if not isinstance(features, torch.Tensor):\n",
    "            raise TypeError(\"Encoder output should be a torch.Tensor.\")\n",
    "\n",
    "        print(\"Feature map shape from the feature extractor:\", features.shape)\n",
    "\n",
    "        # Check that the features tensor has at least 2 dimensions.\n",
    "        if features.dim() < 2:\n",
    "            raise ValueError(\"Encoded features should have at least 2 dimensions.\")\n",
    "        \n",
    "        # Determine the number of channels from the dummy output.\n",
    "        feature_channels = features.shape[1]\n",
    "\n",
    "        # Build the head layer.\n",
    "        head_layer = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_channels, self.num_classes)\n",
    "        )\n",
    "        print(\"Constructed head layer:\", head_layer)\n",
    "        return head_layer\n",
    "    \n",
    "    \n",
    "    def dummy_test(self):\n",
    "        try:\n",
    "            device = next(self.encoder.parameters()).device\n",
    "            dummy = torch.randn(*self.input_shape).float().to(device)\n",
    "            output = self.model(dummy)\n",
    "            print(\"Network test passed. Output shape from the model:\", output.shape)\n",
    "            \n",
    "            if not isinstance(output, torch.Tensor):\n",
    "                raise TypeError(\"Output of the model should be a torch.Tensor.\")\n",
    "            \n",
    "            if output.shape[0] != dummy.shape[0]:\n",
    "                raise ValueError(\"Batch size mismatch between input and output.\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during dummy_test:\", e)\n",
    "            return False\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            raise TypeError(\"Input must be a torch.Tensor.\")\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    def __init__(self, n_individuals, max_layers, dm, max_parameters=100000):\n",
    "        self.dm = dm # Data module for model creation\n",
    "        \n",
    "        self.n_individuals = n_individuals\n",
    "        self.max_layers = max_layers\n",
    "        self.generation = 0\n",
    "        self.max_parameters = max_parameters\n",
    "        \n",
    "        \n",
    "    def initial_poll(self):\n",
    "        \"\"\"\n",
    "        Generate the initial population of individuals.    \n",
    "        \"\"\"\n",
    "        \n",
    "        self.population = self.create_population()\n",
    "        self._update_df()\n",
    "        self.save_dataframe()\n",
    "        self.save_population()\n",
    "\n",
    "\n",
    "    def create_random_individual(self):\n",
    "        \"\"\"\n",
    "        Create a random individual with a random number of layers.\n",
    "        \"\"\"\n",
    "        return classes.Individual(max_layers=self.max_layers)\n",
    "    \n",
    "\n",
    "    def sort_population(self):\n",
    "        \"\"\"\n",
    "        Sort the population by fitness.\n",
    "        \"\"\"\n",
    "        self.population = sorted(self.population, key=lambda individual: individual.fitness, reverse=True)\n",
    "        self.checkpoint()\n",
    "        \n",
    "\n",
    "    def checkpoint(self):\n",
    "        \"\"\"\n",
    "        Save the current population.\n",
    "        \"\"\"\n",
    "        self._update_df()\n",
    "        self.save_population()\n",
    "        self.save_dataframe()\n",
    "    \n",
    "    \n",
    "    def check_individual(self, individual):\n",
    "        model_representation, is_valid = self.build_model(individual.parsed_layers)\n",
    "        if is_valid:\n",
    "            try:\n",
    "                modelSize = self.evaluate_parameters(model_representation)\n",
    "                individual.model_size = modelSize\n",
    "                \n",
    "                assert modelSize > 0, f\"Model size must be greater then zero: {modelSize} Parameters\"\n",
    "                assert modelSize < self.max_parameters, f\"Model size is too big: {modelSize} Parameters\"\n",
    "                assert modelSize is not None, f\"Model size is None...\"\n",
    "                return True # Individual is valid\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered when checking individual: {e}\")\n",
    "                return False # Individual is invalid\n",
    "        else:\n",
    "            return False        \n",
    "\n",
    "    def create_population(self):\n",
    "        population = []\n",
    "        # Generate individuals until the population reaches n_individuals, removing duplicates along the way\n",
    "        while len(population) < self.n_individuals:\n",
    "            candidate = self.create_random_individual() # Create a random individual\n",
    "            if self.check_individual(candidate) is False:\n",
    "                continue\n",
    "            else:\n",
    "                population.append(candidate)\n",
    "            \n",
    "            population = self.remove_duplicates(population) # Remove duplicates\n",
    "        return population\n",
    "\n",
    "\n",
    "    def elite_models(self, k_best=1):\n",
    "        \"\"\"\n",
    "        Get the k_best models from the current population.\n",
    "        \"\"\"\n",
    "        sorted_pop = sorted(self, key=lambda individual: individual.fitness, reverse=True)\n",
    "        topModels = [sorted_pop[i].copy() for i in range(k_best)]\n",
    "        return topModels\n",
    "\n",
    "\n",
    "    def evolve(self, mating_pool_cutoff=0.5, mutation_probability=0.5, k_best=1, n_random=3):\n",
    "        \"\"\"\n",
    "        Generates a new population ensuring that the total number of individuals equals pop.n_individuals.\n",
    "        \n",
    "        Parameters:\n",
    "            pop                  : List or collection of individuals. Assumed to have attributes: \n",
    "                                .n_individuals and .generation.\n",
    "            mating_pool_cutoff   : Fraction determining the size of the mating pool (top percent of individuals).\n",
    "            mutation_probability : The probability to use during mutation.\n",
    "            k_best               : The number of best individuals from the current population to retain.\n",
    "        \n",
    "        Returns:\n",
    "            new_population: A list representing the new generation of individuals.\n",
    "            \n",
    "        Note:\n",
    "            Assumes that helper functions single_point_crossover(), mutation(), and create_random_individual() exist.\n",
    "        \"\"\"\n",
    "        new_population = []\n",
    "        self.generation += 1\n",
    "        self.topModels = self.elite_models(k_best=k_best)\n",
    "\n",
    "\n",
    "        # 2. Create the mating pool based on the cutoff from the sorted population\n",
    "        sorted_pop = sorted(self, key=lambda individual: individual.fitness, reverse=True)\n",
    "        mating_pool = sorted_pop[:int(np.floor(mating_pool_cutoff * self.n_individuals))].copy()\n",
    "        assert len(mating_pool) > 0, \"Mating pool is empty.\"\n",
    "        \n",
    "        # Generate offspring until reaching the desired population size\n",
    "        while len(new_population) < self.n_individuals - n_random - k_best:\n",
    "            try:\n",
    "                parent1 = np.random.choice(mating_pool)\n",
    "                parent2 = np.random.choice(mating_pool)\n",
    "                assert parent1.parsed_layers != parent2.parsed_layers, \"Parents are the same individual.\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error selecting parents: {e}\")\n",
    "                continue\n",
    "            # a) Crossover\n",
    "            children = single_point_crossover([parent1, parent2])\n",
    "            # b) Mutation\n",
    "            for child in children:\n",
    "                mutated_children = mutation(children, mutation_probability)\n",
    "            # c) Random choice of one of the mutated children\n",
    "            one_of_springs = children[0]\n",
    "            one_of_springs.reset() # Reset the individual attributes (fps, metric, model size)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # 3. Add random individuals to the new population\n",
    "        while len(new_population) < self.n_individuals - k_best:\n",
    "            try:\n",
    "                individual = self.create_random_individual()\n",
    "                model_representation, is_valid = self.build_model(individual.parsed_layers)\n",
    "                if is_valid:\n",
    "                    individual.model_size = int(self.evaluate_parameters(model_representation))\n",
    "                    assert individual.model_size > 0, f\"Model size is {individual.model_size}\"\n",
    "                    assert individual.model_size < self.max_parameters, f\"Model size is {individual.model_size}\"\n",
    "                    assert individual.model_size is not None, f\"Model size is None\"\n",
    "                    new_population.append(individual)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered when evolving population: {e}\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        # 4. Add the best individuals from the previous generation\n",
    "        new_population.extend(self.topModels)\n",
    "       \n",
    "\n",
    "        assert len(new_population) == self.n_individuals, f\"Population size is {len(new_population)}, expected {self.n_individuals}\"\n",
    "        self.population = new_population\n",
    "        self._update_df()\n",
    "        self.save_dataframe()\n",
    "        self.save_population()    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.population[index]\n",
    "\n",
    "\n",
    "    def remove_duplicates(self, population):\n",
    "        \"\"\"\n",
    "        Remove duplicates from the given population by replacing duplicates with newly generated unique individuals.\n",
    "\n",
    "        Parameters:\n",
    "            population (list): A list of individuals in the population.\n",
    "\n",
    "        Returns:\n",
    "            list: The updated population with duplicates removed.\n",
    "        \"\"\"\n",
    "        unique_architectures = set()\n",
    "        updated_population = []\n",
    "\n",
    "        for individual in population:\n",
    "            # Use the 'architecture' attribute if available, otherwise fallback to a default representation.\n",
    "            arch = getattr(individual, 'architecture', None)\n",
    "            if arch is None:\n",
    "                # If no architecture attribute, use parsed_layers as unique identifier.\n",
    "                arch = str(individual.parsed_layers)\n",
    "\n",
    "            if arch not in unique_architectures:\n",
    "                unique_architectures.add(arch)\n",
    "                updated_population.append(individual)\n",
    "            else:\n",
    "                # Try to generate a unique individual up to 50 times\n",
    "                for _ in range(50):\n",
    "                    new_individual = classes.Individual(max_layers=self.max_layers)\n",
    "                    new_arch = getattr(new_individual, 'architecture', None)\n",
    "                    if new_arch is None:\n",
    "                        new_arch = str(new_individual.parsed_layers)\n",
    "\n",
    "                    if new_arch not in unique_architectures:\n",
    "                        unique_architectures.add(new_arch)\n",
    "                        updated_population.append(new_individual)\n",
    "                        break\n",
    "                else:\n",
    "                    # After 50 attempts, keep the original duplicate as a fallback.\n",
    "                    updated_population.append(individual)\n",
    "        return updated_population\n",
    "        \n",
    "    \n",
    "    def build_model(self, parsed_layers):\n",
    "        \"\"\"\n",
    "        Build a model based on the provided parsed layers.\n",
    "\n",
    "        This function creates an encoder using the parsed layers and constructs a model by combining\n",
    "        the encoder with a head layer via the ModelConstructor. The constructed model is built to\n",
    "        process inputs defined by the data module (dm).\n",
    "\n",
    "        Parameters:\n",
    "            parsed_layers: The parsed architecture configuration used by the encoder to build the network.\n",
    "\n",
    "        Returns:\n",
    "            A PyTorch model constructed with the encoder and head layer.\n",
    "        \"\"\"\n",
    "        encoder = classes.generic_network.GenericNetwork(\n",
    "                parsed_layers, \n",
    "                input_channels=self.dm.input_shape[0], \n",
    "                input_height=self.dm.input_shape[1], \n",
    "                input_width=self.dm.input_shape[2], \n",
    "                num_classes=self.dm.num_classes,\n",
    "        )\n",
    "        constructed_model = ModelConstructor(encoder, dm).model\n",
    "        valid = ModelConstructor(encoder, dm).valid_model\n",
    "        return constructed_model, valid\n",
    "    \n",
    "    \n",
    "    def evaluate_parameters(self, model):\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "        return num_params\n",
    "    \n",
    "    \n",
    "    def _update_df(self):\n",
    "            \"\"\"\n",
    "            Create a DataFrame from the population.\n",
    "\n",
    "            Returns:\n",
    "                pd.DataFrame: A DataFrame containing the population.\n",
    "            \"\"\"\n",
    "            columns = [\"Generation\", \"Layers\", \"Fitness\", \"Metric\", \"FPS\", \"Params\"]\n",
    "            data = []\n",
    "            for individual in self.population:\n",
    "                generation = self.generation\n",
    "                parsed_layers = individual.parsed_layers\n",
    "                fitness = individual.fitness\n",
    "                iou = individual.iou\n",
    "                fps = individual.fps\n",
    "                model_size = individual.model_size\n",
    "                data.append([generation, parsed_layers, fitness, iou, fps, model_size])\n",
    "            \n",
    "            df = pd.DataFrame(data, columns=columns).sort_values(by=\"Fitness\", ascending=False)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            self.df = df\n",
    "    \n",
    "    \n",
    "    def save_dataframe(self):\n",
    "        path = f'./models_traced/src/df_population_{self.generation}.pkl'\n",
    "        try:\n",
    "            self.df.to_pickle(path)\n",
    "            print(f\"DataFrame saved to {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving DataFrame to {path}: {e}\")\n",
    "    \n",
    "    \n",
    "    def load_dataframe(self, generation):\n",
    "        path = f'./models_traced/src/df_population_{generation}.pkl'\n",
    "        try:\n",
    "            df = pd.read_pickle(path)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading DataFrame from {path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def save_population(self):\n",
    "        path = f'./models_traced/src/population_{self.generation}.pkl'\n",
    "        try:\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(self.population, f)\n",
    "            print(f\"Population saved to {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving population to {path}: {e}\")\n",
    "    \n",
    "    \n",
    "    def load_population(self, generation):\n",
    "        path = f'./models_traced/src/population_{generation}.pkl'\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                population = pickle.load(f)\n",
    "            return population\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading population from {path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.population)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "pop = Population(15, max_layers, dm=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 249812568 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 35166138\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 4410, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=4410, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 4410, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=4410, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 35179371 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 791910\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 448, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=448, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 448, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=448, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 793257 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 1777635830 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.15}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.2}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 257430\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 126, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=126, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 126, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=126, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 257811 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.29}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.29}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 25191260\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 5760, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=5760, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 5760, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=5760, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 25208543 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 29975\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Skipping architecture, total parameters: 308284614 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 295722462 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 1546\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 104175482 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 29578\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 12566\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 20, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 20, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.42}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 14728\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 112, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=112, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 112, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=112, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.34}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.27}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.34}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.27}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 246\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 8, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 8, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.37}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.37}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.35}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 194\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 12, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=12, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 12, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=12, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.46}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.13}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.46}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.2}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.13}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 1071362\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1080, 7, 7])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1080, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1080, 7, 7])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1080, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 1074605 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.1}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.19}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 296\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 77834580\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 9600, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=9600, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 9600, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=9600, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 77863383 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 1257534\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1344, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1344, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1344, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1344, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 1261569 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 427575\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 648, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=648, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 648, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=648, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 429522 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.14}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.2}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7392\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.36}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.42}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 242, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=242, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 242, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=242, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 60796\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 220, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=220, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 220, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=220, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 466987166 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when creating population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.15}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.22}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 16216\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 156, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=156, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 156, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=156, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 40688970\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6300, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6300, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6300, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6300, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when creating population: Model size is too big: 40707873 Parameters\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7456\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.28}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.31}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 1682\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.24}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 182\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "DataFrame saved to ./models_traced/src/df_population_0.pkl\n",
      "Population saved to ./models_traced/src/population_0.pkl\n"
     ]
    }
   ],
   "source": [
    "pop.initial_poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Metric</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>49019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.374540</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>15067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.34}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.27}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.37}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>61459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Generation  \\\n",
       "0            0   \n",
       "1            0   \n",
       "2            0   \n",
       "3            0   \n",
       "4            0   \n",
       "5            0   \n",
       "6            0   \n",
       "7            0   \n",
       "8            0   \n",
       "9            0   \n",
       "10           0   \n",
       "11           0   \n",
       "12           0   \n",
       "13           0   \n",
       "14           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Layers  \\\n",
       "0                                                                                                                                                                                                             [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                  [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "5                                                                                                                                                                                                                                                                                                                          [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]   \n",
       "6                                                                                                                                                                                                                                                   [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [{'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]   \n",
       "9                                                                                                                                                                                                                                                                                                                                   [{'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.31}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'layer_type': 'Dropout', 'dropout_rate': 0.24}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]   \n",
       "11  [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.28}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                       [{'layer_type': 'Dropout', 'dropout_rate': 0.34}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.27}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.37}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.35}, {'layer_type': 'MaxPool'}]   \n",
       "14                                                                                                                                                                                                                                                                                                            [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]   \n",
       "\n",
       "     Fitness Metric   FPS  Params  \n",
       "0   0.969910   None  None   16687  \n",
       "1   0.950714   None  None    1579  \n",
       "2   0.866176   None  None     305  \n",
       "3   0.832443   None  None    7627  \n",
       "4   0.731994   None  None   30121  \n",
       "5   0.708073   None  None   49019  \n",
       "6   0.601115   None  None    7467  \n",
       "7   0.598658   None  None   12629  \n",
       "8   0.374540   None  None   30518  \n",
       "9   0.212339   None  None    1715  \n",
       "10  0.181825   None  None     191  \n",
       "11  0.156019   None  None   15067  \n",
       "12  0.155995   None  None     273  \n",
       "13  0.058084   None  None     233  \n",
       "14  0.020584   None  None   61459  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for individual in pop:\n",
    "    individual.fitness = np.random.rand() # simulate training\n",
    "pop._update_df()\n",
    "pop.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9699098521619943\n",
      "0.9507143064099162\n",
      "0.8661761457749352\n"
     ]
    }
   ],
   "source": [
    "for individual in pop.elite_models(k_best=3):\n",
    "    print(individual.fitness)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population saved to ./models_traced/src/population_0.pkl\n",
      "DataFrame saved to ./models_traced/src/df_population_0.pkl\n"
     ]
    }
   ],
   "source": [
    "pop.sort_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699098521619943"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop[0].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699098521619943"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pop = sorted(pop, key=lambda individual: individual.fitness, reverse=True)\n",
    "sorted_pop[0].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 29578\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 180, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=180, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7456\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.36}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.42}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 48290\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 242, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=242, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 242, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=242, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7456\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.15}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.22}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 16216\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 156, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=156, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 156, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=156, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.1}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.19}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 296\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 1546\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 10, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7456\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 56, 125, 125])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=56, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error selecting parents: Parents are the same individual.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.14}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.2}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7392\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.1}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.19}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 296\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2, 62, 62])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.14}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.2}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 7392\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 24, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=24, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.46}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.46}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Skipping architecture, total parameters: 457976260 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when evolving population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 286776\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 144, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=144, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 144, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=144, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 287211\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 6838121670 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when evolving population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 149838\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 336, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=336, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 336, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=336, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 150849\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Skipping architecture, total parameters: 174762014 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when evolving population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.12}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.48}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.12}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.48}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 8546\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 22, 7, 7])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=22, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 22, 7, 7])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=22, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.18}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.18}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 30395052\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6336, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6336, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6336, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6336, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 30414063\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 5, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 11, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Skipping architecture, total parameters: 122736734 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when evolving population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 71454154\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2574, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2574, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 2574, 31, 31])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=2574, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 71461879\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 59674718\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6804, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6804, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6804, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6804, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 59695133\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 90202\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 100, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 100, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing GELU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.38}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 73878141\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 7560, 8, 8])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=7560, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 7560, 8, 8])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=7560, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 73900824\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.21}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.45}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 9, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.21}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvAct\n",
      "Parsing ReLU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing GELU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ResNetBlock, Full Layer: {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}\n",
      "Parsing ResNetBlock\n",
      "Parsing ReLU\n",
      "Parsed ResNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.45}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 4549416\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1386, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1386, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 1386, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=1386, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 4553577\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}\n",
      "Parsing ConvSE\n",
      "Parsing GELU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'GELU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing GELU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Skipping architecture, total parameters: 129692136 exceed the threshold of 100000000\n",
      "Input shape: (2, 1000, 1000)\n",
      "Error encountered when evolving population: Encoder appears to have no parameters.\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}]\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'ReLU'}\n",
      "Parsing MBConv\n",
      "Parsing ReLU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 7, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: DenseNetBlock, Full Layer: {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 4, 'activation': 'ReLU'}\n",
      "Parsing DenseNetBlock\n",
      "Parsing ReLU\n",
      "Parsed DenseNetBlock without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing ReLU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConv, Full Layer: {'layer_type': 'MBConv', 'expansion_factor': '5', 'activation': 'GELU'}\n",
      "Parsing MBConv\n",
      "Parsing GELU\n",
      "Parsed MBConv without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: ConvBnAct, Full Layer: {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvBnAct\n",
      "Parsing ReLU\n",
      "Parsed ConvBnAct without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Architecture is valid, total parameters: 68158252\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6720, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6720, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 6720, 3, 3])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=6720, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Error encountered when evolving population: Model size is 68178415\n",
      "In the init function of Generic Network.py, here the value of parsed layers is: [{'layer_type': 'Dropout', 'dropout_rate': 0.17}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.46}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.21}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.17}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvAct, Full Layer: {'layer_type': 'ConvAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}\n",
      "Parsing ConvAct\n",
      "Parsing GELU\n",
      "Parsed ConvAct without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.46}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: Dropout, Full Layer: {'layer_type': 'Dropout', 'dropout_rate': 0.21}\n",
      "Parsing Dropout\n",
      "Parsed Dropout without error\n",
      "Parsing layer type in generic_network: AvgPool, Full Layer: {'layer_type': 'AvgPool'}\n",
      "Parsing AvgPool\n",
      "Parsed AvgPool without error\n",
      "Parsing layer type in generic_network: MBConvNoRes, Full Layer: {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}\n",
      "Parsing MBConvNoRes\n",
      "Parsing GELU\n",
      "Parsed MBConvNoRes without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Parsing layer type in generic_network: ConvSE, Full Layer: {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}\n",
      "Parsing ConvSE\n",
      "Parsing ReLU\n",
      "Parsed ConvSE without error\n",
      "Parsing layer type in generic_network: MaxPool, Full Layer: {'layer_type': 'MaxPool'}\n",
      "Parsing MaxPool\n",
      "Parsed MaxPool without error\n",
      "Architecture is valid, total parameters: 3696\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 32, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "Input shape: (2, 1000, 1000)\n",
      "Adding channel dimension to input shape.\n",
      "Original input shape: (2, 1000, 1000)\n",
      "Updated input shape: (1, 2, 1000, 1000)\n",
      "Feature map shape from the feature extractor: torch.Size([1, 32, 15, 15])\n",
      "Constructed head layer: Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (2): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n",
      "Network test passed. Output shape from the model: torch.Size([1, 3])\n",
      "DataFrame saved to ./models_traced/src/df_population_1.pkl\n",
      "Population saved to ./models_traced/src/population_1.pkl\n"
     ]
    }
   ],
   "source": [
    "pop.evolve(mating_pool_cutoff=0.5, mutation_probability=0.5, k_best=1, n_random=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Metric</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.96991</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>49019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.12}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.48}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>90505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'layer_type': 'Dropout', 'dropout_rate': 0.17}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.46}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.21}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Generation  \\\n",
       "0            1   \n",
       "1            1   \n",
       "2            1   \n",
       "3            1   \n",
       "4            1   \n",
       "5            1   \n",
       "6            1   \n",
       "7            1   \n",
       "8            1   \n",
       "9            1   \n",
       "10           1   \n",
       "11           1   \n",
       "12           1   \n",
       "13           1   \n",
       "14           1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Layers  \\\n",
       "0   [{'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 7, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 8, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 10, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 8, 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [{'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 10, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.36}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.42}, {'layer_type': 'AvgPool'}]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                             [{'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.15}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 6, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 12, 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.22}, {'layer_type': 'MaxPool'}]   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [{'layer_type': 'MBConv', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [{'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 6, 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvBnAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}]   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                   [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [{'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.1}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.19}, {'layer_type': 'MaxPool'}]   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                  [{'layer_type': 'Dropout', 'dropout_rate': 0.14}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.38}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 12, 'kernel_size': '3', 'stride': '1', 'padding': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.2}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "12                                                                                                                                                                                                                                                                                                           [{'layer_type': 'ResNetBlock', 'reduction_factor': '2', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.12}, {'layer_type': 'MaxPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '3', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 11, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.48}, {'layer_type': 'MaxPool'}]   \n",
       "13                                                                                                                                                                                                                                                                                                                                                            [{'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'ResNetBlock', 'reduction_factor': '4', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'DenseNetBlock', 'out_channels_coefficient': 9, 'activation': 'ReLU'}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConv', 'expansion_factor': '6', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 5, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '3', 'activation': 'GELU'}, {'layer_type': 'AvgPool'}]   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                             [{'layer_type': 'Dropout', 'dropout_rate': 0.17}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvAct', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.46}, {'layer_type': 'AvgPool'}, {'layer_type': 'Dropout', 'dropout_rate': 0.21}, {'layer_type': 'AvgPool'}, {'layer_type': 'MBConvNoRes', 'expansion_factor': '4', 'activation': 'GELU'}, {'layer_type': 'MaxPool'}, {'layer_type': 'ConvSE', 'out_channels_coefficient': 4, 'kernel_size': '3', 'stride': '1', 'padding': '1', 'activation': 'ReLU'}, {'layer_type': 'MaxPool'}]   \n",
       "\n",
       "    Fitness Metric   FPS  Params  \n",
       "0   0.96991   None  None   16687  \n",
       "1   0.00000   None  None   30121  \n",
       "2   0.00000   None  None    7627  \n",
       "3   0.00000   None  None   49019  \n",
       "4   0.00000   None  None    7627  \n",
       "5   0.00000   None  None   16687  \n",
       "6   0.00000   None  None     305  \n",
       "7   0.00000   None  None    1579  \n",
       "8   0.00000   None  None    7627  \n",
       "9   0.00000   None  None    7467  \n",
       "10  0.00000   None  None     305  \n",
       "11  0.00000   None  None    7467  \n",
       "12  0.00000   None  None    8615  \n",
       "13  0.00000   None  None   90505  \n",
       "14  0.00000   None  None    3795  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.topModels[0].fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation and Crossover to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.topModels[0].fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for individual in pop:\n",
    "    print(individual.model_size)\n",
    "    \n",
    "m, _ = pop.build_model(pop[2].parsed_layers)\n",
    "\n",
    "\n",
    "pop.evaluate_parameters(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.build_model(pop[0].parsed_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model fresh created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASTrainer:\n",
    "    def __init__(self, population, idx, dm, lr, max_epochs=10):\n",
    "        self.population = population\n",
    "        self.idx = idx\n",
    "        self.dm = dm\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        # Build the model from the selected individual.\n",
    "        layers = self.population[self.idx].parsed_layers\n",
    "        self.constructed_model, is_valid = self.population.build_model(layers)\n",
    "        if not is_valid:\n",
    "            raise ValueError(\"Constructed model is not valid.\")\n",
    "        \n",
    "        self.LM = classes.GenericLightningNetwork(\n",
    "            model=self.constructed_model,\n",
    "            num_classes=self.dm.num_classes,\n",
    "            learning_rate=self.lr,\n",
    "        )\n",
    "    \n",
    "    def train(self):\n",
    "        self.trainer = pl.Trainer(\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        # Train the lightning model\n",
    "        self.trainer.fit(self.LM, self.dm)\n",
    "        self.results = self.trainer.test(self.LM, self.dm)\n",
    "\n",
    "    \n",
    "    \n",
    "    def save_model(self, save_torchscript=True, \n",
    "                   ts_save_path=None,\n",
    "                   save_standard=True, \n",
    "                   std_save_path=None):\n",
    "        # Use generation attribute from the Population object.\n",
    "        gen = self.population.generation\n",
    "        \n",
    "        if ts_save_path is None:\n",
    "            ts_save_path = f\"models_traced/generation_{gen}/model_and_architecture_{self.idx}.pt\"\n",
    "        if std_save_path is None:\n",
    "            std_save_path = f\"models_traced/generation_{gen}/model_{self.idx}.pth\"\n",
    "        \n",
    "        # Save the results to a text file.\n",
    "        with open(f\"models_traced/generation_{gen}/results_model_{self.idx}.txt\", \"w\") as f:\n",
    "            f.write(\"Test Results:\\n\")\n",
    "            for key, value in self.results[0].items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        # Prepare dummy input from dm.input_shape\n",
    "        input_shape = self.dm.input_shape\n",
    "        if len(input_shape) == 3:\n",
    "            input_shape = (1,) + input_shape\n",
    "        device = next(self.LM.parameters()).device\n",
    "        example_input = torch.randn(*input_shape).to(device)\n",
    "        \n",
    "        self.LM.eval()  # set the model to evaluation mode\n",
    "        \n",
    "        if save_torchscript:\n",
    "            traced_model = torch.jit.trace(self.LM.model, example_input)\n",
    "            traced_model.save(ts_save_path)\n",
    "            print(f\"Scripted (TorchScript) model saved at {ts_save_path}\")\n",
    "        \n",
    "        if save_standard:\n",
    "            # Retrieve architecture code from the individual.\n",
    "            arch_code = self.population[self.idx].architecture\n",
    "            save_dict = {\"state_dict\": self.LM.model.state_dict()}\n",
    "            if arch_code is not None:\n",
    "                save_dict[\"architecture_code\"] = arch_code\n",
    "            torch.save(save_dict, std_save_path)\n",
    "            print(f\"Standard model saved at {std_save_path}\")\n",
    "\n",
    "\n",
    "from myFit import FitnessEvaluator\n",
    "evaluator = FitnessEvaluator()\n",
    "\n",
    "# Train the models in the population           \n",
    "for idx in range(len(pop)): \n",
    "    nt = NASTrainer(population=pop, idx=idx, dm=dm, lr=1e-3, max_epochs=2)\n",
    "    nt.train()\n",
    "    nt.save_model()\n",
    "    \n",
    "    \n",
    "    # Update the population with the results from the model training\n",
    "    fps = nt.results[0]['fps']\n",
    "    metric = nt.results[0]['test_mcc']\n",
    "    ####\n",
    "    pop[idx].iou = nt.results[0]['test_mcc']\n",
    "    pop[idx].fps = nt.results[0]['fps']\n",
    "    \n",
    "    pop[idx].fitness = evaluator.weighted_sum_exponential(fps, metric)\n",
    "    \n",
    "    pop.df.loc[idx, 'Fitness'] = pop[idx].fitness\n",
    "    pop.df.loc[idx, 'Metric'] = pop[idx].iou\n",
    "    pop.df.loc[idx, 'FPS'] = pop[idx].fps\n",
    "    \n",
    "    pop.save_dataframe()\n",
    "    pop.save_population()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making new generation, some important things:\n",
    "\n",
    "- check model size below the thresh when creating new child, otherwise go for another tentative.\n",
    "- retain best K model at each generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "# new_pop = generate_new_population(pop, mating_pool_cutoff, mutation_probability, k_best=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_population[2].parsed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop[2].parsed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" * 20)\n",
    "print(f\"*** GENERATION {t} ***\")\n",
    "new_population = []\n",
    "\n",
    "# Create a mating pool\n",
    "mating_pool = population[:int(np.floor(mating_pool_cutoff * len(population)))].copy()\n",
    "for i in range(int(np.ceil((1 - mating_pool_cutoff) * len(population)))):\n",
    "    temp_individual = classes.Individual(max_layers=max_layers)\n",
    "    mating_pool.append(temp_individual)\n",
    "\n",
    "# Coupling and mating\n",
    "couple_i = 0\n",
    "while couple_i < len(mating_pool):\n",
    "    parents = [mating_pool[couple_i], mating_pool[couple_i + 1]]\n",
    "    children = single_point_crossover(parents=parents)\n",
    "    children = mutation(children=children, mutation_probability=mutation_probability )\n",
    "    new_population = new_population + children\n",
    "    couple_i += 2\n",
    "\n",
    "# Update the population\n",
    "population = new_population.copy()\n",
    "for i in population:\n",
    "    i.architecture = i.chromosome2architecture(i.chromosome)\n",
    "population = remove_duplicates(population=population, max_layers=max_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TorchScript model and test with a dummy input.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_path = \"model_and_architecture.pt\"\n",
    "loaded_model = torch.jit.load(save_path, map_location=device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Ensure input is moved to the correct device\n",
    "example_input = torch.randn(1, *dm.input_shape).to(device)\n",
    "example_input = example_input.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(example_input)\n",
    "print(\"Output from the loaded model:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
