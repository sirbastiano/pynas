{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyNAS\n",
    "\n",
    "This notebook describes how to use NAS for generating and evolving neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† PyTorch Lightning Setup Script\n",
    "\n",
    "This script initializes a training environment for a neural network using PyTorch Lightning and a custom NAS framework.\n",
    "\n",
    "üîç **Explanation**\n",
    "\n",
    "- **Dataset Loader:** Uses RawClassifierDataModule to load data with batch_size=4, num_workers=2, and no transforms.\n",
    "- **Config Parsing:** Reads logs_dir_GA and seed from config.ini.\n",
    "- **Environment Setup:**  \n",
    "\t- Enables full column display in pandas.  \n",
    "\t- Ensures reproducibility with pl.seed_everything().  \n",
    "\t- Sets matrix multiplication precision to \"medium\" for optimized performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pynas.core.population import Population\n",
    "from datasets.RawClassifier.loader import RawClassifierDataModule\n",
    "\n",
    "# Define dataset module\n",
    "root_dir = '/Data_large/marine/PythonProjects/OtherProjects/lpl-PyNas/data/RawClassifier'\n",
    "dm = RawClassifierDataModule(root_dir, batch_size=4, num_workers=2, transform=None)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "def setting():\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    # Logging\n",
    "    logs_directory = str(config['GA']['logs_dir_GA'])\n",
    "    # Torch stuff\n",
    "    seed = config.getint(section='Computation', option='seed')\n",
    "    pl.seed_everything(seed=seed, workers=True)  # For reproducibility\n",
    "    torch.set_float32_matmul_precision(\"medium\")  # to make lightning happy\n",
    "setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Genetic Algorithm Model Setup\n",
    "\n",
    "This section of code configures parameters for a Genetic Algorithm (GA)-based Neural Architecture Search (NAS) using the Population class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "max_layers = 3 # Maximum number of layers in the model: composed of normal cell (Conv Block) and reduction cell (i.e. Pooling layer)\n",
    "max_iter = int(config['GA']['max_iterations'])\n",
    "# GA parameters\n",
    "n_individuals = int(config['GA']['population_size'])\n",
    "mating_pool_cutoff = float(config['GA']['mating_pool_cutoff'])\n",
    "mutation_probability = float(config['GA']['mutation_probability'])\n",
    "\n",
    "pop = Population(n_individuals=20, max_layers=max_layers, dm=dm, max_parameters=400_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß¨ Initial Population (`Population` Object)\n",
    "\n",
    "The initial population defines the starting point for the Genetic Algorithm (GA)-based search. It consists of a set of randomly generated neural architectures (individuals), each encoded with:\n",
    "\n",
    "- A **variable number of layers** (up to `max_layers`)\n",
    "- **Random hyperparameters and layer types** within predefined search constraints\n",
    "- A **bounded total parameter count** (`max_parameters`) to limit model complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.initial_poll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ `train()` vs `evolve()` in a GA-based NAS Framework\n",
    "\n",
    "In the context of the `Population` class within a Genetic Algorithm (GA)-driven Neural Architecture Search (NAS), the methods `train()` and `evolve()` serve distinct purposes in the evolutionary pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è `train()`\n",
    "\n",
    "Trains all individuals (i.e., neural architectures) in the current population.\n",
    "\n",
    "#### üìå Responsibilities:\n",
    "- Performs forward and backward passes on the dataset (`dm`).\n",
    "- Optimizes model weights using a standard training loop.\n",
    "- Evaluates performance (fitness), typically via validation accuracy or loss.\n",
    "- Stores fitness scores used for selection in the GA.\n",
    "\n",
    "#### ‚úÖ Outcome:\n",
    "Each individual's **fitness value** is updated and can now be ranked for survival and reproduction.\n",
    "\n",
    "---\n",
    "\n",
    "### üß¨ `evolve()`\n",
    "\n",
    "Applies evolutionary operations to produce the **next generation** of architectures.\n",
    "\n",
    "#### üìå Responsibilities:\n",
    "- **Selection**: Ranks individuals by fitness and selects top performers (according to `mating_pool_cutoff`).\n",
    "- **Crossover**: Combines architecture components (e.g., layer types, connections) from parent individuals.\n",
    "- **Mutation**: Applies random changes (with `mutation_probability`) to maintain diversity.\n",
    "- **Population Replacement**: Creates a new generation of individuals.\n",
    "\n",
    "#### ‚úÖ Outcome:\n",
    "A **new population** is generated with architectural variations derived from the most promising candidates of the previous generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(max_iter):\n",
    "    pop.train_generation(task='classification', lr=0.001, epochs=15, batch_size=32) \n",
    "    pop.evolve(mating_pool_cutoff=mating_pool_cutoff, mutation_probability=0.85, k_best=1, n_random=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÑ `load_dataframe()` Method ‚Äì What It Does\n",
    "\n",
    "The `load_dataframe` method in the `Population` class is used to retrieve üì¶ **stored results or evaluation metrics** from the training and evolution process of the models.\n",
    "\n",
    "When calling `pop.load_dataframe(9)`, it loads data such as:\n",
    "- üìä **Performance metrics**\n",
    "- üìâ **Loss values**\n",
    "- üß† **Architectural configurations**\n",
    "\n",
    "These were saved during the evolutionary search.\n",
    "\n",
    "You can use this data for:\n",
    "- üîç **Analysis** of model performance\n",
    "- üìà **Visualization** of evolutionary dynamics\n",
    "- üõ†Ô∏è **Further processing** like re-training or model selection\n",
    "\n",
    "‚ö†Ô∏è **Note**: The index passed (e.g., `9`) must correspond to the specific generation or result set you want to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.load_dataframe(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Using the evaluated and saved model. We use the traced pytroch model (.pt) to load and execute inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TorchScript model and test with a dummy input.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_path = \"model_and_architecture.pt\"\n",
    "loaded_model = torch.jit.load(save_path, map_location=device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Ensure input is moved to the correct device\n",
    "example_input = torch.randn(1, *dm.input_shape).to(device)\n",
    "example_input = example_input.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(example_input)\n",
    "print(\"Output from the loaded model:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
