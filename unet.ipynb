{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pynas.core.population import Population\n",
    "from datasets.RawClassifier.loader import RawClassifierDataModule\n",
    "\n",
    "# Define dataset module\n",
    "root_dir = '/Data_large/marine/PythonProjects/OtherProjects/lpl-PyNas/data/RawClassifier'\n",
    "dm = RawClassifierDataModule(root_dir, batch_size=4, num_workers=2, transform=None)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "def setting():\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    # Logging\n",
    "    logs_directory = str(config['GA']['logs_dir_GA'])\n",
    "    # Torch stuff\n",
    "    seed = config.getint(section='Computation', option='seed')\n",
    "    pl.seed_everything(seed=seed, workers=True)  # For reproducibility\n",
    "    torch.set_float32_matmul_precision(\"medium\")  # to make lightning happy\n",
    "    num_workers = config.getint(section='Computation', option='num_workers')\n",
    "    accelerator = config.get(section='Computation', option='accelerator')\n",
    "    log_learning_rate=None\n",
    "    batch_size=None\n",
    "    # Get model parameters\n",
    "    log_lr = log_learning_rate if log_learning_rate is not None else config.getfloat(section='Search Space', option='default_log_lr')\n",
    "    lr = 10**log_lr\n",
    "    bs = batch_size if batch_size is not None else config.getint(section='Search Space', option='default_bs')\n",
    "    print(f\"-----------The batch size of the data to be loaded in the model is: {bs}-----------\")\n",
    "    print(f\"-----------The learning rate of the data to be loaded in the model is: {lr}-----------\")\n",
    "    \n",
    "setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "max_layers = 3\n",
    "max_iter = int(config['GA']['max_iterations'])\n",
    "# GA parameters\n",
    "n_individuals = int(config['GA']['population_size'])\n",
    "mating_pool_cutoff = float(config['GA']['mating_pool_cutoff'])\n",
    "mutation_probability = float(config['GA']['mutation_probability'])\n",
    "\n",
    "pop = Population(n_individuals=20, max_layers=max_layers, dm=dm, max_parameters=400_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.initial_poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.train_individual(idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model fresh created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myFit import FitnessEvaluator\n",
    "from handler.generic_lightning_module import GenericLightningSegmentationNetwork\n",
    "\n",
    "evaluator = FitnessEvaluator()\n",
    "\n",
    "class NASTrainer:\n",
    "    def __init__(self, population, idx, dm, lr, max_epochs=25):\n",
    "        self.population = population\n",
    "        self.idx = idx\n",
    "        self.dm = dm\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        # Build the model from the selected individual.\n",
    "        layers = self.population[self.idx].parsed_layers\n",
    "        self.constructed_model, is_valid = self.population.build_model(layers)\n",
    "        if not is_valid:\n",
    "            raise ValueError(\"Constructed model is not valid.\")\n",
    "        \n",
    "        self.LM = GenericLightningSegmentationNetwork(\n",
    "            model=self.constructed_model,\n",
    "            learning_rate=self.lr,\n",
    "        )\n",
    "    \n",
    "    def train(self):\n",
    "        self.trainer = pl.Trainer(\n",
    "            max_epochs=self.max_epochs,\n",
    "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        # Train the lightning model\n",
    "        self.trainer.fit(self.LM, self.dm)\n",
    "        self.results = self.trainer.test(self.LM, self.dm)\n",
    "\n",
    "    \n",
    "    \n",
    "    def save_model(self, save_torchscript=True, \n",
    "                   ts_save_path=None,\n",
    "                   save_standard=True, \n",
    "                   std_save_path=None):\n",
    "        # Use generation attribute from the Population object.\n",
    "        gen = self.population.generation\n",
    "        \n",
    "        if ts_save_path is None:\n",
    "            ts_save_path = f\"models_traced/generation_{gen}/model_and_architecture_{self.idx}.pt\"\n",
    "        if std_save_path is None:\n",
    "            std_save_path = f\"models_traced/generation_{gen}/model_{self.idx}.pth\"\n",
    "        \n",
    "        # Save the results to a text file.\n",
    "        with open(f\"models_traced/generation_{gen}/results_model_{self.idx}.txt\", \"w\") as f:\n",
    "            f.write(\"Test Results:\\n\")\n",
    "            for key, value in self.results[0].items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        # Prepare dummy input from dm.input_shape\n",
    "        input_shape = self.dm.input_shape\n",
    "        if len(input_shape) == 3:\n",
    "            input_shape = (1,) + input_shape\n",
    "        device = next(self.LM.parameters()).device\n",
    "        example_input = torch.randn(*input_shape).to(device)\n",
    "        \n",
    "        self.LM.eval()  # set the model to evaluation mode\n",
    "        \n",
    "        if save_torchscript:\n",
    "            traced_model = torch.jit.trace(self.LM.model, example_input)\n",
    "            traced_model.save(ts_save_path)\n",
    "            print(f\"Scripted (TorchScript) model saved at {ts_save_path}\")\n",
    "        \n",
    "        if save_standard:\n",
    "            # Retrieve architecture code from the individual.\n",
    "            arch_code = self.population[self.idx].architecture\n",
    "            save_dict = {\"state_dict\": self.LM.model.state_dict()}\n",
    "            if arch_code is not None:\n",
    "                save_dict[\"architecture_code\"] = arch_code\n",
    "            torch.save(save_dict, std_save_path)\n",
    "            print(f\"Standard model saved at {std_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Be Rewritten with Bash Logic:\n",
    "\n",
    "This part of the code train the whole population one individual at the time and can be performed on single individuals in parallel. Using bash we can run parallel training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import api_call\n",
    "\n",
    "\n",
    "# TODO: Implement the API call to evaluate the model and return the results.\n",
    "\n",
    "# population loading from saved files\n",
    "pop.load_dataframe(0)\n",
    "pop.load_population(0)\n",
    "\n",
    "# Train the models in the population           \n",
    "idx = 0 # This must be input argument\n",
    "\n",
    "nt = NASTrainer(population=pop, idx=idx, dm=dm, lr=1e-3, max_epochs=30)\n",
    "nt.train()\n",
    "nt.save_model()\n",
    "\n",
    "\n",
    "# API to update the population with the results from the model training\n",
    "result = api_call() # caller_api(nt.model)\n",
    "\n",
    "# 1) Update the population with the results from the model training\n",
    "fps = nt.results[0]['fps']\n",
    "metric = nt.results[0]['test_mcc']\n",
    "pop[idx].iou = nt.results[0]['test_mcc']\n",
    "pop[idx].fps = nt.results[0]['fps']\n",
    "\n",
    "# TODO> Implement the fitness function with more rigurous evaluation parameters (rn the fitness is not the best)\n",
    "pop[idx].fitness = evaluator.weighted_sum_exponential(fps, metric)\n",
    "\n",
    "# 2) Update the df. TODO: insert this logic in _update_df method.\n",
    "pop.df.loc[idx, 'Fitness'] = pop[idx].fitness\n",
    "pop.df.loc[idx, 'Metric'] = pop[idx].iou\n",
    "pop.df.loc[idx, 'FPS'] = pop[idx].fps\n",
    "\n",
    "\n",
    "pop.save_dataframe()\n",
    "pop.save_population()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx == len(pop) - 1:\n",
    "    # Evolve the population\n",
    "    pop.evolve(mating_pool_cutoff=mating_pool_cutoff, mutation_probability=0.85, k_best=1, n_random=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Using the evaluated and saved model. We use the traced pytroch model (.pt) to load and execute inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TorchScript model and test with a dummy input.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_path = \"model_and_architecture.pt\"\n",
    "loaded_model = torch.jit.load(save_path, map_location=device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Ensure input is moved to the correct device\n",
    "example_input = torch.randn(1, *dm.input_shape).to(device)\n",
    "example_input = example_input.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(example_input)\n",
    "print(\"Output from the loaded model:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
