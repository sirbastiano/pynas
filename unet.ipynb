{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------The batch size of the data to be loaded in the model is: 4-----------\n",
      "-----------The learning rate of the data to be loaded in the model is: 0.001-----------\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pynas.core.population import Population\n",
    "from datasets.RawClassifier.loader import RawClassifierDataModule\n",
    "\n",
    "# Define dataset module\n",
    "root_dir = '/Data_large/marine/PythonProjects/OtherProjects/lpl-PyNas/data/RawClassifier'\n",
    "dm = RawClassifierDataModule(root_dir, batch_size=4, num_workers=2, transform=None)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "def setting():\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    # Logging\n",
    "    logs_directory = str(config['GA']['logs_dir_GA'])\n",
    "    # Torch stuff\n",
    "    seed = config.getint(section='Computation', option='seed')\n",
    "    pl.seed_everything(seed=seed, workers=True)  # For reproducibility\n",
    "    torch.set_float32_matmul_precision(\"medium\")  # to make lightning happy\n",
    "    num_workers = config.getint(section='Computation', option='num_workers')\n",
    "    accelerator = config.get(section='Computation', option='accelerator')\n",
    "    log_learning_rate=None\n",
    "    batch_size=None\n",
    "    # Get model parameters\n",
    "    log_lr = log_learning_rate if log_learning_rate is not None else config.getfloat(section='Search Space', option='default_log_lr')\n",
    "    lr = 10**log_lr\n",
    "    bs = batch_size if batch_size is not None else config.getint(section='Search Space', option='default_bs')\n",
    "    print(f\"-----------The batch size of the data to be loaded in the model is: {bs}-----------\")\n",
    "    print(f\"-----------The learning rate of the data to be loaded in the model is: {lr}-----------\")\n",
    "    \n",
    "setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "max_layers = 3\n",
    "max_iter = int(config['GA']['max_iterations'])\n",
    "# GA parameters\n",
    "n_individuals = int(config['GA']['population_size'])\n",
    "mating_pool_cutoff = float(config['GA']['mating_pool_cutoff'])\n",
    "mutation_probability = float(config['GA']['mutation_probability'])\n",
    "\n",
    "pop = Population(n_individuals=20, max_layers=max_layers, dm=dm, max_parameters=400_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Population:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Population: 100%|██████████| 20/20 [00:06<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "pop.initial_poll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training individual 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                       | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model            | Sequential                 | 4.2 M  | train\n",
      "1 | loss_fn          | CrossEntropyLoss           | 0      | train\n",
      "2 | accuracy         | MulticlassAccuracy         | 0      | train\n",
      "3 | f1_score         | MulticlassF1Score          | 0      | train\n",
      "4 | mcc              | MulticlassMatthewsCorrCoef | 0      | train\n",
      "5 | conf_matrix      | MulticlassConfusionMatrix  | 0      | train\n",
      "6 | conf_matrix_pred | MulticlassConfusionMatrix  | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "4.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 M     Total params\n",
      "16.793    Total estimated model params size (MB)\n",
      "56        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vessel/anaconda3/envs/pynas/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  12%|█▎        | 1/8 [00:01<00:07,  0.92it/s, v_num=43, train_loss=0.452, train_accuracy=0.730, train_f1_score=0.706, train_mcc=0.646]"
     ]
    }
   ],
   "source": [
    "pop.train_generation(task='classification', lr=0.001, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.evolve(mating_pool_cutoff=mating_pool_cutoff, mutation_probability=0.85, k_best=1, n_random=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model fresh created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Be Rewritten with Bash Logic:\n",
    "\n",
    "This part of the code train the whole population one individual at the time and can be performed on single individuals in parallel. Using bash we can run parallel training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import api_call\n",
    "\n",
    "\n",
    "# TODO: Implement the API call to evaluate the model and return the results.\n",
    "\n",
    "# population loading from saved files\n",
    "pop.load_dataframe(0)\n",
    "pop.load_population(0)\n",
    "\n",
    "# Train the models in the population           \n",
    "idx = 0 # This must be input argument\n",
    "\n",
    "nt = NASTrainer(population=pop, idx=idx, dm=dm, lr=1e-3, max_epochs=30)\n",
    "nt.train()\n",
    "nt.save_model()\n",
    "\n",
    "\n",
    "# API to update the population with the results from the model training\n",
    "result = api_call() # caller_api(nt.model)\n",
    "\n",
    "# 1) Update the population with the results from the model training\n",
    "fps = nt.results[0]['fps']\n",
    "metric = nt.results[0]['test_mcc']\n",
    "pop[idx].iou = nt.results[0]['test_mcc']\n",
    "pop[idx].fps = nt.results[0]['fps']\n",
    "\n",
    "# TODO> Implement the fitness function with more rigurous evaluation parameters (rn the fitness is not the best)\n",
    "pop[idx].fitness = evaluator.weighted_sum_exponential(fps, metric)\n",
    "\n",
    "# 2) Update the df. TODO: insert this logic in _update_df method.\n",
    "pop.df.loc[idx, 'Fitness'] = pop[idx].fitness\n",
    "pop.df.loc[idx, 'Metric'] = pop[idx].iou\n",
    "pop.df.loc[idx, 'FPS'] = pop[idx].fps\n",
    "\n",
    "\n",
    "pop.save_dataframe()\n",
    "pop.save_population()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx == len(pop) - 1:\n",
    "    # Evolve the population\n",
    "    pop.evolve(mating_pool_cutoff=mating_pool_cutoff, mutation_probability=0.85, k_best=1, n_random=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Using the evaluated and saved model. We use the traced pytroch model (.pt) to load and execute inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TorchScript model and test with a dummy input.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "save_path = \"model_and_architecture.pt\"\n",
    "loaded_model = torch.jit.load(save_path, map_location=device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Ensure input is moved to the correct device\n",
    "example_input = torch.randn(1, *dm.input_shape).to(device)\n",
    "example_input = example_input.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = loaded_model(example_input)\n",
    "print(\"Output from the loaded model:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
